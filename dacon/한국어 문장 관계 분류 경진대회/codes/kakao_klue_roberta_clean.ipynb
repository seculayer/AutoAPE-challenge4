{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  6 10:48:09 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   35C    P0    41W / 300W |      3MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   44C    P0    71W / 300W |  21743MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      8898      C   .../envs/test_env/bin/python      585MiB |\r\n",
      "|    1   N/A  N/A     94250      C   .../envs/test_env/bin/python    21155MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/centos/psw/KSRC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_bVw3BzS66Gp"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159486</th>\n",
       "      <td>159486</td>\n",
       "      <td>같은 방향으로 보이는 숲이 우거진 지역에 의상을 입은 사람들이 모여 있다.</td>\n",
       "      <td>사람들은 의상을 입는다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159487</th>\n",
       "      <td>159487</td>\n",
       "      <td>검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.</td>\n",
       "      <td>하이힐을 신은 남자</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159488</th>\n",
       "      <td>159488</td>\n",
       "      <td>검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.</td>\n",
       "      <td>서 있는 소녀</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159489</th>\n",
       "      <td>159489</td>\n",
       "      <td>검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.</td>\n",
       "      <td>사진 촬영 준비를 하고 있는 소녀</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159490</th>\n",
       "      <td>159490</td>\n",
       "      <td>한 남자가 유람선을 배경으로 부두에서 포즈를 취하고 있다.</td>\n",
       "      <td>포즈를 취하는 인간.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159491 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                            premise  \\\n",
       "0            0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...   \n",
       "1            1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...   \n",
       "2            2                    이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.   \n",
       "3            3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4            4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...   \n",
       "...        ...                                                ...   \n",
       "159486  159486          같은 방향으로 보이는 숲이 우거진 지역에 의상을 입은 사람들이 모여 있다.   \n",
       "159487  159487              검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.   \n",
       "159488  159488              검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.   \n",
       "159489  159489              검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.   \n",
       "159490  159490                   한 남자가 유람선을 배경으로 부두에서 포즈를 취하고 있다.   \n",
       "\n",
       "                                     hypothesis          label  \n",
       "0                                씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                              자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2       예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                             원주민들은 종합대책에 만족했다.        neutral  \n",
       "4            이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  \n",
       "...                                         ...            ...  \n",
       "159486                             사람들은 의상을 입는다     entailment  \n",
       "159487                               하이힐을 신은 남자  contradiction  \n",
       "159488                                  서 있는 소녀     entailment  \n",
       "159489                       사진 촬영 준비를 하고 있는 소녀        neutral  \n",
       "159490                              포즈를 취하는 인간.     entailment  \n",
       "\n",
       "[159491 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 데이콘 데이터셋\n",
    "train = pd.read_csv('data/train_data.csv', encoding='utf-8')\n",
    "test = pd.read_csv('data/test_data.csv', encoding='utf-8')\n",
    "\n",
    "# 카카오 데이터셋\n",
    "kakao_snli = pd.read_csv('data/snli_1.0_train.ko.tsv', sep='\\t', encoding='utf-8')\n",
    "kakao_snli = kakao_snli[:100000]\n",
    "kakao_dev = pd.read_csv('data/xnli.dev.ko.tsv', sep='\\t', encoding='utf-8')\n",
    "kakao_test = pd.read_csv('data/xnli.test.ko.tsv', sep='\\t', encoding='utf-8')\n",
    "kakao_dev = pd.concat([kakao_dev,kakao_test, kakao_snli])\n",
    "kakao_dev.rename(columns = {'sentence1':'premise','sentence2':'hypothesis','gold_label':'label'},inplace=True)\n",
    "\n",
    "# KLUE 데이터셋\n",
    "klue_dev = pd.read_json('data/klue-nli-v1.1_dev.json')\n",
    "klue_dev = klue_dev[['premise', 'hypothesis', 'gold_label']]\n",
    "klue_train = pd.read_json('data/klue-nli-v1.1_train.json')\n",
    "klue_train = klue_train[['premise', 'hypothesis', 'gold_label']]\n",
    "klue_dev = pd.concat([klue_dev,klue_train])\n",
    "klue_dev.rename(columns = {'gold_label':'label'}, inplace=True)\n",
    "\n",
    "# 데이콘, 카카오, KLUE 데이터셋 병합\n",
    "train = pd.concat([train, klue_dev, kakao_dev], axis=0)\n",
    "train = train.reset_index(drop=True)\n",
    "train['index'] = train.index\n",
    "train = train.dropna()\n",
    "drop_list = list(train.premise.str.len().sort_values().tail(26).index)\n",
    "train = train.drop(drop_list,axis=0)\n",
    "train = train.reset_index(drop=True)\n",
    "train['index'] = train.index\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6FpW8SM7lwW",
    "outputId": "e779fb75-c660-4224-8296-fb17f2facfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159491 entries, 0 to 159490\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   index       159491 non-null  int64 \n",
      " 1   premise     159491 non-null  object\n",
      " 2   hypothesis  159491 non-null  object\n",
      " 3   label       159491 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1666 entries, 0 to 1665\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       1666 non-null   int64 \n",
      " 1   premise     1666 non-null   object\n",
      " 2   hypothesis  1666 non-null   object\n",
      " 3   label       1666 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 52.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 결측치는 없음\n",
    "\n",
    "print(train.info(), end='\\n\\n')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4L1jeCl72DF",
    "outputId": "b5c8ce74-4bce-4603-a0f6-e8cbcd527b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label: \n",
      "entailment       53629\n",
      "contradiction    53486\n",
      "neutral          52402\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Label: ', train['label'].value_counts(), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9SAoqqNmAU3x",
    "outputId": "cbe32eff-2df0-4a4f-9d17-50537c24cd33"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data imbalance는 사실상 존재하지 않음 \n",
    "\n",
    "sns.countplot(data=train,x='label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T6hQolMqAkji"
   },
   "outputs": [],
   "source": [
    "max_premise = np.max(train['premise'].str.len())\n",
    "\n",
    "max_hypothesis = np.max(train['hypothesis'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AApuxsJBcYi",
    "outputId": "744f3bd4-e74b-40cf-defb-abfd64225d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max premise = 5610 \n",
      "max hypothesis = 104\n"
     ]
    }
   ],
   "source": [
    "print('max premise =',max_premise,\"\\nmax hypothesis =\",max_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "CxFj3gc2B2YB",
    "outputId": "b9605aef-724a-408b-ef18-9b3bd3be21e7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['premise'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "5xFFliUaCiwR",
    "outputId": "b7132a6d-24cb-4773-edaa-13d9d7e75af2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['hypothesis'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "yv3YDRoOHPoX",
    "outputId": "0883bafc-6b61-4dd4-c270-51516ed832f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2      2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불 용어 처리 \n",
    "\n",
    "train['premise'] = train['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['premise'] = test['premise'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "hCfxgISsHvZl",
    "outputId": "43f42d44-7632-48bd-d175-3c42d7029276"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2      2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                               hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다        neutral  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hypothesis'] = train['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['hypothesis'] = test['hypothesis'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qg83MpRKHv-7",
    "outputId": "fb73b171-9390-40f7-f97c-2166594f99aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 2023):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1c5b91e6ae4d46d0b2f099cd1d4c15cf",
      "0bbfd5f0ec2d4436a06bb502f8131f49",
      "2613deb06698404396c37a2cc26f5dc4",
      "daa90c709c4b46439770068ba936d25f",
      "d66d726b5a104734a7bcfa4d5bfd53b2",
      "0cde98b9a09144b6b25b121ab70b4ff4",
      "21f45f4a718446cea0a2ae70c743ba61",
      "3882a8be8ec44b9fb9595d4239c46930",
      "f6e6cbbc9d0e443ca58cdcfe2c44f49e",
      "4cdf8336d32747629b01a6550240c6fe",
      "8242b29066ed4717b957c897adba8533",
      "8437c6dcd988498fb32f3d0557bb2385",
      "accc4b1e20d149aab8385df3109eb92f",
      "9579ee57512f4bfbae9eeaac961ef7cb",
      "a3591cd1d9f04511b42b45cde368fbc7",
      "1d38cc6507084d34a2d41ada6a37b83e",
      "4c07c3365e984f3596c00edb9cd2c184",
      "b18b9e54b8bb47a7ac0d5d4db9cc0946",
      "094f33ed2071450d91c60f15b0331e8c",
      "7cb35513245c4927858d1ad05062340d",
      "45f4bd07499745d09d398568221a49aa",
      "e03141fe0ca24aa888dc4ce1734ef897",
      "1ced7dcc914c47788ca51353a2245f6e",
      "25ef02ee9d634d79b632eb0a5ad0f6fa",
      "095be4a6f89d4603b8a0b314727bd7a4",
      "c3e047157c734a5fbf6a6c8dc27c5913",
      "16cd5a8125f64e618585d262ed0dcc39",
      "3560910251ab4451ba5df9bf0953e999",
      "c0ef75dc157d4b2a9c881661aa39347c",
      "b1e6ccdaaa224d05be7928a5aafaab64",
      "c5a393fdf1044e6298a258d4bb8fcd84",
      "4a046ee54d1d485e84835c858f31be0c",
      "57d26fc2e49c4bfaa89415d44a0606ec",
      "14c3fbc303704c62957bd8c329b8024e",
      "5fe9d0f2a6924eba82b3502d43030b61",
      "8902ff1c00df45c78d5b02464ee50756",
      "8fdfe2b3e6e64012ac265a462fbcf328",
      "ddd8542cdb7c4844b19cb62fa5e5e146",
      "f3f1a17e1bd642e9b17fa94aff662eda",
      "6c7eed7e50f34a1584a9639f26c277fe",
      "28c17f7168c24bcfbfb6cacf9d8a2b24",
      "1809bf6050194337a8a1efd347bf1f88",
      "c40ba97a8a66488cb7b62cf85aead2b5",
      "e8da32862f9049ceb6796662fcd4444f",
      "6860bf24436f4e098c668a285fd06f59",
      "5b541face9d74d2eae19066c55320567",
      "fbabe1a9a00a419b8c5f54375e80d952",
      "f207ba49d03d4d11abd8a50c624eb7c8",
      "3aa68625b6364fdcb47c203b43277941",
      "afd8616825be40a8a52b1df11d73c64d",
      "341d1f2f2ec34446bcc1049dafda1c82",
      "27848cf6c21243f99f6421c294e2844f",
      "7af67cc2ae4b4c3abb9e7a208ecc9fd5",
      "3bebe6d4ba11479c8d6b952c786d5393",
      "683388a3551c4cfc922c56cba867d04c",
      "86daa3417a4147c4acc5b2cb0aff4935",
      "6be5e8971a294d58b173245f74bf1975",
      "ebdfb09f0319470db6ef22d68916b111",
      "c0c048b2bc734c2a9a05a3195b29b136",
      "f2b21dab53e944a58572bbdd6c9c94b0",
      "2cd3c31a170a431ca04bbeeb641f6590",
      "77abc577d69e4ca69ff1afe8c3a37d43",
      "73c789717a3745a9b431931ce845432b",
      "704b74d3a9a040e9a11e57234af566ea",
      "9251c8da568641daacabf3e198c79290",
      "1a91d489ae164c8ca4243d06894962fa"
     ]
    },
    "id": "-rI1h2a6K9dL",
    "outputId": "30f09f75-ea4d-4986-cc46-67f306e7dba0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (18): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (19): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (20): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (21): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (22): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (23): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'klue/roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "config.num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "print(model)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yca5HgSqLJfa",
    "outputId": "e90f071b-9d99-4443-a1dd-8076ee43532e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  3893,  4421,  2043, 10212,  3771,  1164,  2776,  1376,  2250,\n",
      "         6047,  2299,     2,  4421,  2043, 10212,  2259,  3771,  2138,  1164,\n",
      "         1567,  5322,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1])\n",
      "[CLS] 역시 이동진 평론가 영화 볼줄 아신다니까 [SEP] 이동진 평론가는 영화를 볼 줄 모른다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# train test split 및 tokenizing \n",
    "# token에 들어가는 문장은 premise와 hypothesis를 concat 한 문장\n",
    "\n",
    "train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['label'])\n",
    "\n",
    "tokenized_train = tokenizer(\n",
    "    list(train_dataset['premise']),\n",
    "    list(train_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128, # Max_Length = 190\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "tokenized_eval = tokenizer(\n",
    "    list(eval_dataset['premise']),\n",
    "    list(eval_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(tokenized_train['input_ids'][0])\n",
    "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D5bvDvPaMDkU"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Fuk01B-iMUBI"
   },
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "    \n",
    "    return num_label\n",
    "\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "eval_label = label_to_num(eval_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6-3Soz2McqX",
    "outputId": "66cac98b-3367-4f27-e9a3-f3378302fc39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127592\n",
      "{'input_ids': tensor([    0, 20442,  2609,  4415, 28289,  5174,  1116,  3993,  2439,  3664,\n",
      "         2069,  3894, 19521,  3739, 12293,  3756,  5637,  2200,  6555,  2444,\n",
      "         7935,  4066,  2290,  2425,  3720,  6509,  7615,  4538,     2, 20442,\n",
      "         2609,  4415, 28289,  5174,  1116,  3993,  2439,  3664,  2073,  3894,\n",
      "         2496,  2118,  1380,  2259,  2062,     2,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(1)}\n",
      "[CLS] 의료관광객 유치업체 육성 및 분야별 교육을 제공하고 국내 여행사 대상 공모로 융합형 치유 관광상품 개발에도 착수한다 [SEP] 의료관광객 유치업체 육성 및 분야별 교육은 제공되지 않는다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BERTDataset(tokenized_train, train_label)\n",
    "eval_dataset = BERTDataset(tokenized_eval, eval_label)\n",
    "\n",
    "print(train_dataset.__len__())\n",
    "print(train_dataset.__getitem__(19997))\n",
    "print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Kwczjk_6Mlox"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    probs = pred.predictions\n",
    "    \n",
    "    acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
    "\n",
    "    return {'accuracy': acc,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q1BhVy-0O4oo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_ars = TrainingArguments(\n",
    "    output_dir='result/kakao_klue_roberta_clean/',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_total_limit=5,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 500,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_ars,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2yMmO8p-PHM9",
    "outputId": "28e4936f-20d5-4733-89c1-8c3c9a7dfc9b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127592\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13958\n",
      "  Number of trainable parameters = 336659459\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msangmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230106_105301-2vwqen2k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/2vwqen2k\" target=\"_blank\">result/kakao_klue_roberta_clean</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1112' max='13958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1112/13958 31:08 < 6:00:29, 0.59 it/s, Epoch 0.56/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.113100</td>\n",
       "      <td>1.100653</td>\n",
       "      <td>0.336186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.105600</td>\n",
       "      <td>1.104099</td>\n",
       "      <td>0.336186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31899\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_klue_roberta_clean/checkpoint-500\n",
      "Configuration saved in result/kakao_klue_roberta_clean/checkpoint-500/config.json\n",
      "Model weights saved in result/kakao_klue_roberta_clean/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_klue_roberta_clean/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_klue_roberta_clean/checkpoint-500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31899\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_klue_roberta_clean/checkpoint-1000\n",
      "Configuration saved in result/kakao_klue_roberta_clean/checkpoint-1000/config.json\n",
      "Model weights saved in result/kakao_klue_roberta_clean/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_klue_roberta_clean/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_klue_roberta_clean/checkpoint-1000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/result/kakao_klue_roberta_clean/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMOYxWImPRe3",
    "outputId": "c4fd6536-0c44-4915-a50c-0b441a027609"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/tokenizer_config.json\n",
      "loading configuration file result/Roberta_Large_Concat/checkpoint-3000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"result/Roberta_Large_Concat/checkpoint-3000\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file result/Roberta_Large_Concat/checkpoint-3000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at result/Roberta_Large_Concat/checkpoint-3000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Tokenizer_NAME = \"klue/roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
    "\n",
    "MODEL_NAME = 'result/kakao_klue_roberta_clean/best_model'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(tokenizer.vocab_size)\n",
    "model.to(device)\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5TT-R3XwsIN",
    "outputId": "cf7a3a83-ebea-4aa5-c31d-386b9487620a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n",
      "{'input_ids': tensor([    0,   720,  3994,  2052, 10428,  2775,   647,  3657,  2119,  1085,\n",
      "            3,     2,   720,  3994,  2052,   911,  2075,  3669,  2119,  3926,\n",
      "         2088,  1513,  2359, 13964,     2,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(3)}\n",
      "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다 [SEP] 18일 배를 타고 여행을 떠났습니다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "test_label = label_to_num(test['label'].values)\n",
    "\n",
    "tokenized_test = tokenizer(\n",
    "    list(test['premise']),\n",
    "    list(test['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "test_dataset = BERTDataset(tokenized_test, test_label)\n",
    "\n",
    "print(test_dataset.__len__())\n",
    "print(test_dataset.__getitem__(1665))\n",
    "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "On27w6Ukwohv",
    "outputId": "1b648050-b470-4f92-be09-1515b8d34e9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:07<00:00, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 1, 2, 0, 1, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 0, 2, 1, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 2, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 0, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 0, 0, 0, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2, 0, 2, 2, 1, 1, 0, 1, 2, 0, 2, 2, 0, 1, 0, 0, 1, 0, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 1, 0, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 1, 1, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 2, 2, 1, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 2, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 0, 2, 0, 1, 0, 2, 1, 2, 1, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 0, 0, 2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 2, 0, 1, 0, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 1, 0, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 0, 2, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 2, 2, 2, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 0, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2, 1, 0, 2, 2, 2, 1, 2, 0, 1, 2, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 2, 0, 1, 2, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 1, 0, 2, 0, 2, 0, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 0, 2, 1, 1, 0, 2, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 0, 2, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 2, 1, 1, 1, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 0, 1, 0, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 0, 1, 2, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 2, 0, 1, 2, 2, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 0, 0, 2, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 0, 1, 2, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_pred = []\n",
    "output_prob = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=data['input_ids'].to(device),\n",
    "            attention_mask=data['attention_mask'].to(device),\n",
    "            token_type_ids=data['token_type_ids'].to(device)\n",
    "        )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rR2B__eywvus",
    "outputId": "ba7b7017-fd7f-4120-9b90-5ed18409c339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'contradiction'], [1, 'neutral'], [2, 'entailment'], [3, 'contradiction'], [4, 'contradiction'], [5, 'neutral'], [6, 'neutral'], [7, 'contradiction'], [8, 'entailment'], [9, 'neutral'], [10, 'contradiction'], [11, 'entailment'], [12, 'contradiction'], [13, 'entailment'], [14, 'neutral'], [15, 'neutral'], [16, 'contradiction'], [17, 'neutral'], [18, 'contradiction'], [19, 'neutral'], [20, 'contradiction'], [21, 'neutral'], [22, 'neutral'], [23, 'entailment'], [24, 'contradiction'], [25, 'contradiction'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'entailment'], [30, 'contradiction'], [31, 'contradiction'], [32, 'contradiction'], [33, 'contradiction'], [34, 'neutral'], [35, 'contradiction'], [36, 'contradiction'], [37, 'contradiction'], [38, 'entailment'], [39, 'contradiction'], [40, 'neutral'], [41, 'entailment'], [42, 'entailment'], [43, 'neutral'], [44, 'neutral'], [45, 'contradiction'], [46, 'neutral'], [47, 'entailment'], [48, 'contradiction'], [49, 'entailment'], [50, 'entailment'], [51, 'contradiction'], [52, 'entailment'], [53, 'neutral'], [54, 'neutral'], [55, 'neutral'], [56, 'neutral'], [57, 'neutral'], [58, 'neutral'], [59, 'entailment'], [60, 'entailment'], [61, 'neutral'], [62, 'neutral'], [63, 'neutral'], [64, 'neutral'], [65, 'contradiction'], [66, 'neutral'], [67, 'neutral'], [68, 'neutral'], [69, 'neutral'], [70, 'entailment'], [71, 'neutral'], [72, 'entailment'], [73, 'contradiction'], [74, 'neutral'], [75, 'neutral'], [76, 'entailment'], [77, 'neutral'], [78, 'neutral'], [79, 'contradiction'], [80, 'neutral'], [81, 'contradiction'], [82, 'contradiction'], [83, 'contradiction'], [84, 'entailment'], [85, 'contradiction'], [86, 'neutral'], [87, 'contradiction'], [88, 'entailment'], [89, 'neutral'], [90, 'contradiction'], [91, 'neutral'], [92, 'entailment'], [93, 'contradiction'], [94, 'entailment'], [95, 'neutral'], [96, 'contradiction'], [97, 'contradiction'], [98, 'entailment'], [99, 'neutral'], [100, 'neutral'], [101, 'entailment'], [102, 'neutral'], [103, 'entailment'], [104, 'neutral'], [105, 'entailment'], [106, 'neutral'], [107, 'neutral'], [108, 'contradiction'], [109, 'entailment'], [110, 'contradiction'], [111, 'neutral'], [112, 'contradiction'], [113, 'entailment'], [114, 'neutral'], [115, 'entailment'], [116, 'entailment'], [117, 'contradiction'], [118, 'contradiction'], [119, 'contradiction'], [120, 'contradiction'], [121, 'contradiction'], [122, 'contradiction'], [123, 'neutral'], [124, 'neutral'], [125, 'entailment'], [126, 'entailment'], [127, 'contradiction'], [128, 'contradiction'], [129, 'neutral'], [130, 'contradiction'], [131, 'neutral'], [132, 'contradiction'], [133, 'entailment'], [134, 'neutral'], [135, 'entailment'], [136, 'contradiction'], [137, 'neutral'], [138, 'contradiction'], [139, 'contradiction'], [140, 'neutral'], [141, 'neutral'], [142, 'neutral'], [143, 'entailment'], [144, 'contradiction'], [145, 'contradiction'], [146, 'entailment'], [147, 'contradiction'], [148, 'neutral'], [149, 'neutral'], [150, 'contradiction'], [151, 'entailment'], [152, 'contradiction'], [153, 'neutral'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'contradiction'], [158, 'contradiction'], [159, 'neutral'], [160, 'neutral'], [161, 'entailment'], [162, 'contradiction'], [163, 'entailment'], [164, 'neutral'], [165, 'contradiction'], [166, 'neutral'], [167, 'entailment'], [168, 'neutral'], [169, 'entailment'], [170, 'neutral'], [171, 'neutral'], [172, 'entailment'], [173, 'neutral'], [174, 'neutral'], [175, 'neutral'], [176, 'neutral'], [177, 'neutral'], [178, 'contradiction'], [179, 'neutral'], [180, 'contradiction'], [181, 'neutral'], [182, 'neutral'], [183, 'neutral'], [184, 'entailment'], [185, 'neutral'], [186, 'contradiction'], [187, 'neutral'], [188, 'entailment'], [189, 'contradiction'], [190, 'neutral'], [191, 'entailment'], [192, 'contradiction'], [193, 'entailment'], [194, 'neutral'], [195, 'entailment'], [196, 'entailment'], [197, 'neutral'], [198, 'entailment'], [199, 'neutral'], [200, 'neutral'], [201, 'entailment'], [202, 'entailment'], [203, 'contradiction'], [204, 'contradiction'], [205, 'entailment'], [206, 'entailment'], [207, 'neutral'], [208, 'entailment'], [209, 'neutral'], [210, 'contradiction'], [211, 'contradiction'], [212, 'contradiction'], [213, 'neutral'], [214, 'contradiction'], [215, 'contradiction'], [216, 'contradiction'], [217, 'entailment'], [218, 'contradiction'], [219, 'contradiction'], [220, 'neutral'], [221, 'neutral'], [222, 'entailment'], [223, 'contradiction'], [224, 'neutral'], [225, 'neutral'], [226, 'contradiction'], [227, 'neutral'], [228, 'contradiction'], [229, 'contradiction'], [230, 'entailment'], [231, 'neutral'], [232, 'entailment'], [233, 'entailment'], [234, 'entailment'], [235, 'neutral'], [236, 'neutral'], [237, 'contradiction'], [238, 'entailment'], [239, 'contradiction'], [240, 'entailment'], [241, 'contradiction'], [242, 'neutral'], [243, 'entailment'], [244, 'neutral'], [245, 'entailment'], [246, 'neutral'], [247, 'neutral'], [248, 'contradiction'], [249, 'contradiction'], [250, 'entailment'], [251, 'contradiction'], [252, 'neutral'], [253, 'entailment'], [254, 'neutral'], [255, 'neutral'], [256, 'entailment'], [257, 'contradiction'], [258, 'entailment'], [259, 'entailment'], [260, 'contradiction'], [261, 'entailment'], [262, 'contradiction'], [263, 'neutral'], [264, 'neutral'], [265, 'neutral'], [266, 'entailment'], [267, 'neutral'], [268, 'neutral'], [269, 'entailment'], [270, 'neutral'], [271, 'neutral'], [272, 'entailment'], [273, 'entailment'], [274, 'neutral'], [275, 'contradiction'], [276, 'entailment'], [277, 'contradiction'], [278, 'neutral'], [279, 'neutral'], [280, 'neutral'], [281, 'entailment'], [282, 'contradiction'], [283, 'entailment'], [284, 'contradiction'], [285, 'entailment'], [286, 'contradiction'], [287, 'contradiction'], [288, 'entailment'], [289, 'neutral'], [290, 'entailment'], [291, 'contradiction'], [292, 'entailment'], [293, 'neutral'], [294, 'entailment'], [295, 'contradiction'], [296, 'contradiction'], [297, 'contradiction'], [298, 'neutral'], [299, 'entailment'], [300, 'entailment'], [301, 'entailment'], [302, 'neutral'], [303, 'entailment'], [304, 'contradiction'], [305, 'entailment'], [306, 'neutral'], [307, 'contradiction'], [308, 'entailment'], [309, 'entailment'], [310, 'entailment'], [311, 'contradiction'], [312, 'neutral'], [313, 'neutral'], [314, 'neutral'], [315, 'neutral'], [316, 'neutral'], [317, 'neutral'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'neutral'], [322, 'neutral'], [323, 'entailment'], [324, 'contradiction'], [325, 'entailment'], [326, 'contradiction'], [327, 'neutral'], [328, 'contradiction'], [329, 'contradiction'], [330, 'neutral'], [331, 'entailment'], [332, 'entailment'], [333, 'contradiction'], [334, 'contradiction'], [335, 'contradiction'], [336, 'entailment'], [337, 'contradiction'], [338, 'contradiction'], [339, 'neutral'], [340, 'contradiction'], [341, 'neutral'], [342, 'contradiction'], [343, 'contradiction'], [344, 'neutral'], [345, 'entailment'], [346, 'contradiction'], [347, 'contradiction'], [348, 'contradiction'], [349, 'neutral'], [350, 'contradiction'], [351, 'neutral'], [352, 'entailment'], [353, 'contradiction'], [354, 'neutral'], [355, 'contradiction'], [356, 'neutral'], [357, 'entailment'], [358, 'contradiction'], [359, 'neutral'], [360, 'contradiction'], [361, 'contradiction'], [362, 'neutral'], [363, 'neutral'], [364, 'contradiction'], [365, 'neutral'], [366, 'neutral'], [367, 'entailment'], [368, 'contradiction'], [369, 'neutral'], [370, 'contradiction'], [371, 'neutral'], [372, 'entailment'], [373, 'neutral'], [374, 'neutral'], [375, 'entailment'], [376, 'entailment'], [377, 'neutral'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'neutral'], [382, 'contradiction'], [383, 'neutral'], [384, 'entailment'], [385, 'neutral'], [386, 'entailment'], [387, 'entailment'], [388, 'neutral'], [389, 'contradiction'], [390, 'neutral'], [391, 'entailment'], [392, 'contradiction'], [393, 'contradiction'], [394, 'contradiction'], [395, 'neutral'], [396, 'neutral'], [397, 'neutral'], [398, 'contradiction'], [399, 'neutral'], [400, 'contradiction'], [401, 'neutral'], [402, 'contradiction'], [403, 'contradiction'], [404, 'entailment'], [405, 'neutral'], [406, 'contradiction'], [407, 'neutral'], [408, 'contradiction'], [409, 'neutral'], [410, 'contradiction'], [411, 'contradiction'], [412, 'contradiction'], [413, 'contradiction'], [414, 'neutral'], [415, 'contradiction'], [416, 'contradiction'], [417, 'entailment'], [418, 'neutral'], [419, 'contradiction'], [420, 'neutral'], [421, 'neutral'], [422, 'neutral'], [423, 'neutral'], [424, 'entailment'], [425, 'neutral'], [426, 'neutral'], [427, 'contradiction'], [428, 'contradiction'], [429, 'contradiction'], [430, 'entailment'], [431, 'neutral'], [432, 'neutral'], [433, 'contradiction'], [434, 'entailment'], [435, 'neutral'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'contradiction'], [442, 'contradiction'], [443, 'neutral'], [444, 'contradiction'], [445, 'neutral'], [446, 'neutral'], [447, 'entailment'], [448, 'contradiction'], [449, 'neutral'], [450, 'contradiction'], [451, 'entailment'], [452, 'entailment'], [453, 'contradiction'], [454, 'contradiction'], [455, 'entailment'], [456, 'neutral'], [457, 'contradiction'], [458, 'contradiction'], [459, 'contradiction'], [460, 'entailment'], [461, 'entailment'], [462, 'contradiction'], [463, 'neutral'], [464, 'neutral'], [465, 'contradiction'], [466, 'contradiction'], [467, 'neutral'], [468, 'entailment'], [469, 'neutral'], [470, 'contradiction'], [471, 'neutral'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'neutral'], [476, 'entailment'], [477, 'contradiction'], [478, 'contradiction'], [479, 'contradiction'], [480, 'entailment'], [481, 'entailment'], [482, 'contradiction'], [483, 'entailment'], [484, 'neutral'], [485, 'neutral'], [486, 'entailment'], [487, 'neutral'], [488, 'contradiction'], [489, 'entailment'], [490, 'entailment'], [491, 'neutral'], [492, 'neutral'], [493, 'entailment'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'neutral'], [498, 'neutral'], [499, 'contradiction'], [500, 'entailment'], [501, 'entailment'], [502, 'neutral'], [503, 'contradiction'], [504, 'contradiction'], [505, 'entailment'], [506, 'neutral'], [507, 'contradiction'], [508, 'entailment'], [509, 'contradiction'], [510, 'neutral'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'entailment'], [515, 'contradiction'], [516, 'entailment'], [517, 'entailment'], [518, 'contradiction'], [519, 'contradiction'], [520, 'neutral'], [521, 'neutral'], [522, 'contradiction'], [523, 'neutral'], [524, 'contradiction'], [525, 'contradiction'], [526, 'entailment'], [527, 'entailment'], [528, 'contradiction'], [529, 'entailment'], [530, 'neutral'], [531, 'neutral'], [532, 'contradiction'], [533, 'neutral'], [534, 'neutral'], [535, 'contradiction'], [536, 'contradiction'], [537, 'contradiction'], [538, 'neutral'], [539, 'neutral'], [540, 'neutral'], [541, 'contradiction'], [542, 'contradiction'], [543, 'entailment'], [544, 'contradiction'], [545, 'neutral'], [546, 'contradiction'], [547, 'entailment'], [548, 'neutral'], [549, 'entailment'], [550, 'neutral'], [551, 'contradiction'], [552, 'neutral'], [553, 'entailment'], [554, 'entailment'], [555, 'neutral'], [556, 'neutral'], [557, 'neutral'], [558, 'neutral'], [559, 'contradiction'], [560, 'contradiction'], [561, 'contradiction'], [562, 'neutral'], [563, 'neutral'], [564, 'entailment'], [565, 'neutral'], [566, 'entailment'], [567, 'entailment'], [568, 'neutral'], [569, 'contradiction'], [570, 'neutral'], [571, 'entailment'], [572, 'entailment'], [573, 'neutral'], [574, 'entailment'], [575, 'contradiction'], [576, 'entailment'], [577, 'neutral'], [578, 'contradiction'], [579, 'neutral'], [580, 'contradiction'], [581, 'entailment'], [582, 'neutral'], [583, 'neutral'], [584, 'entailment'], [585, 'entailment'], [586, 'neutral'], [587, 'entailment'], [588, 'contradiction'], [589, 'entailment'], [590, 'entailment'], [591, 'neutral'], [592, 'contradiction'], [593, 'entailment'], [594, 'contradiction'], [595, 'contradiction'], [596, 'contradiction'], [597, 'neutral'], [598, 'entailment'], [599, 'entailment'], [600, 'contradiction'], [601, 'neutral'], [602, 'contradiction'], [603, 'entailment'], [604, 'neutral'], [605, 'neutral'], [606, 'contradiction'], [607, 'contradiction'], [608, 'contradiction'], [609, 'contradiction'], [610, 'entailment'], [611, 'entailment'], [612, 'neutral'], [613, 'entailment'], [614, 'contradiction'], [615, 'contradiction'], [616, 'neutral'], [617, 'neutral'], [618, 'contradiction'], [619, 'neutral'], [620, 'contradiction'], [621, 'contradiction'], [622, 'entailment'], [623, 'contradiction'], [624, 'contradiction'], [625, 'contradiction'], [626, 'contradiction'], [627, 'contradiction'], [628, 'neutral'], [629, 'entailment'], [630, 'contradiction'], [631, 'entailment'], [632, 'neutral'], [633, 'entailment'], [634, 'neutral'], [635, 'entailment'], [636, 'contradiction'], [637, 'entailment'], [638, 'entailment'], [639, 'neutral'], [640, 'neutral'], [641, 'entailment'], [642, 'neutral'], [643, 'entailment'], [644, 'neutral'], [645, 'entailment'], [646, 'neutral'], [647, 'contradiction'], [648, 'contradiction'], [649, 'neutral'], [650, 'entailment'], [651, 'contradiction'], [652, 'contradiction'], [653, 'neutral'], [654, 'neutral'], [655, 'neutral'], [656, 'entailment'], [657, 'contradiction'], [658, 'entailment'], [659, 'contradiction'], [660, 'neutral'], [661, 'contradiction'], [662, 'neutral'], [663, 'neutral'], [664, 'entailment'], [665, 'contradiction'], [666, 'neutral'], [667, 'entailment'], [668, 'neutral'], [669, 'neutral'], [670, 'neutral'], [671, 'neutral'], [672, 'neutral'], [673, 'neutral'], [674, 'neutral'], [675, 'entailment'], [676, 'neutral'], [677, 'neutral'], [678, 'contradiction'], [679, 'contradiction'], [680, 'neutral'], [681, 'contradiction'], [682, 'entailment'], [683, 'contradiction'], [684, 'contradiction'], [685, 'contradiction'], [686, 'entailment'], [687, 'contradiction'], [688, 'entailment'], [689, 'entailment'], [690, 'neutral'], [691, 'entailment'], [692, 'entailment'], [693, 'neutral'], [694, 'entailment'], [695, 'entailment'], [696, 'entailment'], [697, 'contradiction'], [698, 'entailment'], [699, 'neutral'], [700, 'entailment'], [701, 'entailment'], [702, 'entailment'], [703, 'neutral'], [704, 'entailment'], [705, 'entailment'], [706, 'contradiction'], [707, 'contradiction'], [708, 'neutral'], [709, 'neutral'], [710, 'neutral'], [711, 'entailment'], [712, 'neutral'], [713, 'entailment'], [714, 'entailment'], [715, 'entailment'], [716, 'contradiction'], [717, 'neutral'], [718, 'neutral'], [719, 'entailment'], [720, 'entailment'], [721, 'neutral'], [722, 'contradiction'], [723, 'entailment'], [724, 'neutral'], [725, 'contradiction'], [726, 'neutral'], [727, 'neutral'], [728, 'contradiction'], [729, 'entailment'], [730, 'entailment'], [731, 'neutral'], [732, 'entailment'], [733, 'neutral'], [734, 'entailment'], [735, 'neutral'], [736, 'contradiction'], [737, 'neutral'], [738, 'entailment'], [739, 'entailment'], [740, 'neutral'], [741, 'neutral'], [742, 'entailment'], [743, 'entailment'], [744, 'neutral'], [745, 'neutral'], [746, 'neutral'], [747, 'contradiction'], [748, 'neutral'], [749, 'neutral'], [750, 'neutral'], [751, 'neutral'], [752, 'neutral'], [753, 'neutral'], [754, 'entailment'], [755, 'neutral'], [756, 'neutral'], [757, 'contradiction'], [758, 'neutral'], [759, 'neutral'], [760, 'entailment'], [761, 'neutral'], [762, 'entailment'], [763, 'contradiction'], [764, 'neutral'], [765, 'entailment'], [766, 'neutral'], [767, 'entailment'], [768, 'contradiction'], [769, 'neutral'], [770, 'contradiction'], [771, 'neutral'], [772, 'entailment'], [773, 'contradiction'], [774, 'neutral'], [775, 'neutral'], [776, 'contradiction'], [777, 'entailment'], [778, 'neutral'], [779, 'neutral'], [780, 'entailment'], [781, 'contradiction'], [782, 'contradiction'], [783, 'neutral'], [784, 'entailment'], [785, 'neutral'], [786, 'contradiction'], [787, 'neutral'], [788, 'entailment'], [789, 'contradiction'], [790, 'entailment'], [791, 'neutral'], [792, 'entailment'], [793, 'neutral'], [794, 'neutral'], [795, 'entailment'], [796, 'contradiction'], [797, 'entailment'], [798, 'entailment'], [799, 'neutral'], [800, 'entailment'], [801, 'neutral'], [802, 'entailment'], [803, 'neutral'], [804, 'contradiction'], [805, 'contradiction'], [806, 'entailment'], [807, 'entailment'], [808, 'neutral'], [809, 'entailment'], [810, 'neutral'], [811, 'contradiction'], [812, 'contradiction'], [813, 'contradiction'], [814, 'neutral'], [815, 'neutral'], [816, 'neutral'], [817, 'neutral'], [818, 'neutral'], [819, 'entailment'], [820, 'neutral'], [821, 'neutral'], [822, 'neutral'], [823, 'neutral'], [824, 'contradiction'], [825, 'neutral'], [826, 'contradiction'], [827, 'neutral'], [828, 'contradiction'], [829, 'entailment'], [830, 'entailment'], [831, 'contradiction'], [832, 'contradiction'], [833, 'neutral'], [834, 'neutral'], [835, 'contradiction'], [836, 'neutral'], [837, 'contradiction'], [838, 'neutral'], [839, 'contradiction'], [840, 'contradiction'], [841, 'neutral'], [842, 'contradiction'], [843, 'entailment'], [844, 'neutral'], [845, 'neutral'], [846, 'contradiction'], [847, 'contradiction'], [848, 'entailment'], [849, 'neutral'], [850, 'neutral'], [851, 'contradiction'], [852, 'entailment'], [853, 'neutral'], [854, 'contradiction'], [855, 'entailment'], [856, 'entailment'], [857, 'neutral'], [858, 'contradiction'], [859, 'entailment'], [860, 'contradiction'], [861, 'entailment'], [862, 'neutral'], [863, 'neutral'], [864, 'neutral'], [865, 'entailment'], [866, 'entailment'], [867, 'neutral'], [868, 'contradiction'], [869, 'neutral'], [870, 'neutral'], [871, 'neutral'], [872, 'entailment'], [873, 'entailment'], [874, 'neutral'], [875, 'entailment'], [876, 'entailment'], [877, 'contradiction'], [878, 'neutral'], [879, 'neutral'], [880, 'neutral'], [881, 'neutral'], [882, 'contradiction'], [883, 'entailment'], [884, 'entailment'], [885, 'entailment'], [886, 'neutral'], [887, 'neutral'], [888, 'entailment'], [889, 'neutral'], [890, 'entailment'], [891, 'contradiction'], [892, 'entailment'], [893, 'entailment'], [894, 'contradiction'], [895, 'neutral'], [896, 'entailment'], [897, 'neutral'], [898, 'entailment'], [899, 'neutral'], [900, 'neutral'], [901, 'contradiction'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'neutral'], [906, 'contradiction'], [907, 'contradiction'], [908, 'neutral'], [909, 'entailment'], [910, 'neutral'], [911, 'neutral'], [912, 'neutral'], [913, 'entailment'], [914, 'neutral'], [915, 'neutral'], [916, 'contradiction'], [917, 'contradiction'], [918, 'neutral'], [919, 'contradiction'], [920, 'neutral'], [921, 'entailment'], [922, 'entailment'], [923, 'contradiction'], [924, 'contradiction'], [925, 'contradiction'], [926, 'entailment'], [927, 'entailment'], [928, 'neutral'], [929, 'contradiction'], [930, 'neutral'], [931, 'entailment'], [932, 'neutral'], [933, 'neutral'], [934, 'contradiction'], [935, 'contradiction'], [936, 'entailment'], [937, 'entailment'], [938, 'entailment'], [939, 'neutral'], [940, 'entailment'], [941, 'entailment'], [942, 'contradiction'], [943, 'neutral'], [944, 'neutral'], [945, 'entailment'], [946, 'entailment'], [947, 'neutral'], [948, 'neutral'], [949, 'entailment'], [950, 'contradiction'], [951, 'neutral'], [952, 'contradiction'], [953, 'contradiction'], [954, 'contradiction'], [955, 'neutral'], [956, 'neutral'], [957, 'entailment'], [958, 'contradiction'], [959, 'contradiction'], [960, 'neutral'], [961, 'contradiction'], [962, 'contradiction'], [963, 'contradiction'], [964, 'entailment'], [965, 'entailment'], [966, 'neutral'], [967, 'entailment'], [968, 'entailment'], [969, 'contradiction'], [970, 'entailment'], [971, 'entailment'], [972, 'neutral'], [973, 'contradiction'], [974, 'contradiction'], [975, 'entailment'], [976, 'entailment'], [977, 'neutral'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'neutral'], [982, 'entailment'], [983, 'contradiction'], [984, 'neutral'], [985, 'neutral'], [986, 'contradiction'], [987, 'contradiction'], [988, 'neutral'], [989, 'contradiction'], [990, 'entailment'], [991, 'entailment'], [992, 'neutral'], [993, 'contradiction'], [994, 'neutral'], [995, 'entailment'], [996, 'neutral'], [997, 'contradiction'], [998, 'contradiction'], [999, 'entailment'], [1000, 'entailment'], [1001, 'entailment'], [1002, 'contradiction'], [1003, 'entailment'], [1004, 'neutral'], [1005, 'neutral'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'neutral'], [1009, 'neutral'], [1010, 'neutral'], [1011, 'entailment'], [1012, 'neutral'], [1013, 'contradiction'], [1014, 'neutral'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'contradiction'], [1019, 'contradiction'], [1020, 'entailment'], [1021, 'neutral'], [1022, 'neutral'], [1023, 'neutral'], [1024, 'entailment'], [1025, 'neutral'], [1026, 'neutral'], [1027, 'neutral'], [1028, 'contradiction'], [1029, 'contradiction'], [1030, 'entailment'], [1031, 'neutral'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'neutral'], [1035, 'contradiction'], [1036, 'neutral'], [1037, 'contradiction'], [1038, 'contradiction'], [1039, 'contradiction'], [1040, 'contradiction'], [1041, 'neutral'], [1042, 'contradiction'], [1043, 'entailment'], [1044, 'contradiction'], [1045, 'neutral'], [1046, 'contradiction'], [1047, 'entailment'], [1048, 'entailment'], [1049, 'contradiction'], [1050, 'entailment'], [1051, 'contradiction'], [1052, 'entailment'], [1053, 'contradiction'], [1054, 'neutral'], [1055, 'neutral'], [1056, 'contradiction'], [1057, 'neutral'], [1058, 'entailment'], [1059, 'neutral'], [1060, 'neutral'], [1061, 'contradiction'], [1062, 'contradiction'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'neutral'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'neutral'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'neutral'], [1073, 'neutral'], [1074, 'entailment'], [1075, 'contradiction'], [1076, 'entailment'], [1077, 'neutral'], [1078, 'contradiction'], [1079, 'entailment'], [1080, 'neutral'], [1081, 'contradiction'], [1082, 'contradiction'], [1083, 'contradiction'], [1084, 'contradiction'], [1085, 'contradiction'], [1086, 'neutral'], [1087, 'entailment'], [1088, 'contradiction'], [1089, 'neutral'], [1090, 'entailment'], [1091, 'neutral'], [1092, 'contradiction'], [1093, 'neutral'], [1094, 'neutral'], [1095, 'neutral'], [1096, 'entailment'], [1097, 'neutral'], [1098, 'neutral'], [1099, 'contradiction'], [1100, 'entailment'], [1101, 'contradiction'], [1102, 'contradiction'], [1103, 'entailment'], [1104, 'contradiction'], [1105, 'entailment'], [1106, 'contradiction'], [1107, 'contradiction'], [1108, 'entailment'], [1109, 'contradiction'], [1110, 'contradiction'], [1111, 'contradiction'], [1112, 'contradiction'], [1113, 'contradiction'], [1114, 'neutral'], [1115, 'neutral'], [1116, 'neutral'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'contradiction'], [1120, 'contradiction'], [1121, 'entailment'], [1122, 'neutral'], [1123, 'contradiction'], [1124, 'neutral'], [1125, 'neutral'], [1126, 'entailment'], [1127, 'contradiction'], [1128, 'neutral'], [1129, 'contradiction'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'entailment'], [1133, 'contradiction'], [1134, 'contradiction'], [1135, 'entailment'], [1136, 'contradiction'], [1137, 'contradiction'], [1138, 'contradiction'], [1139, 'entailment'], [1140, 'entailment'], [1141, 'contradiction'], [1142, 'contradiction'], [1143, 'contradiction'], [1144, 'entailment'], [1145, 'neutral'], [1146, 'entailment'], [1147, 'neutral'], [1148, 'entailment'], [1149, 'contradiction'], [1150, 'entailment'], [1151, 'contradiction'], [1152, 'neutral'], [1153, 'neutral'], [1154, 'neutral'], [1155, 'neutral'], [1156, 'neutral'], [1157, 'entailment'], [1158, 'neutral'], [1159, 'neutral'], [1160, 'entailment'], [1161, 'contradiction'], [1162, 'contradiction'], [1163, 'contradiction'], [1164, 'neutral'], [1165, 'entailment'], [1166, 'neutral'], [1167, 'entailment'], [1168, 'neutral'], [1169, 'neutral'], [1170, 'contradiction'], [1171, 'neutral'], [1172, 'contradiction'], [1173, 'neutral'], [1174, 'contradiction'], [1175, 'entailment'], [1176, 'neutral'], [1177, 'neutral'], [1178, 'neutral'], [1179, 'contradiction'], [1180, 'neutral'], [1181, 'entailment'], [1182, 'contradiction'], [1183, 'neutral'], [1184, 'contradiction'], [1185, 'neutral'], [1186, 'neutral'], [1187, 'neutral'], [1188, 'entailment'], [1189, 'contradiction'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'contradiction'], [1193, 'neutral'], [1194, 'entailment'], [1195, 'entailment'], [1196, 'contradiction'], [1197, 'neutral'], [1198, 'contradiction'], [1199, 'neutral'], [1200, 'entailment'], [1201, 'neutral'], [1202, 'entailment'], [1203, 'neutral'], [1204, 'neutral'], [1205, 'neutral'], [1206, 'contradiction'], [1207, 'contradiction'], [1208, 'entailment'], [1209, 'contradiction'], [1210, 'neutral'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'contradiction'], [1214, 'neutral'], [1215, 'contradiction'], [1216, 'neutral'], [1217, 'entailment'], [1218, 'neutral'], [1219, 'neutral'], [1220, 'contradiction'], [1221, 'contradiction'], [1222, 'neutral'], [1223, 'neutral'], [1224, 'entailment'], [1225, 'contradiction'], [1226, 'neutral'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'neutral'], [1230, 'contradiction'], [1231, 'contradiction'], [1232, 'entailment'], [1233, 'neutral'], [1234, 'contradiction'], [1235, 'entailment'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'neutral'], [1240, 'neutral'], [1241, 'neutral'], [1242, 'neutral'], [1243, 'neutral'], [1244, 'entailment'], [1245, 'contradiction'], [1246, 'contradiction'], [1247, 'entailment'], [1248, 'neutral'], [1249, 'entailment'], [1250, 'neutral'], [1251, 'entailment'], [1252, 'contradiction'], [1253, 'contradiction'], [1254, 'neutral'], [1255, 'contradiction'], [1256, 'entailment'], [1257, 'entailment'], [1258, 'contradiction'], [1259, 'entailment'], [1260, 'neutral'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'neutral'], [1264, 'neutral'], [1265, 'neutral'], [1266, 'entailment'], [1267, 'contradiction'], [1268, 'contradiction'], [1269, 'contradiction'], [1270, 'contradiction'], [1271, 'entailment'], [1272, 'contradiction'], [1273, 'entailment'], [1274, 'contradiction'], [1275, 'neutral'], [1276, 'neutral'], [1277, 'entailment'], [1278, 'contradiction'], [1279, 'entailment'], [1280, 'contradiction'], [1281, 'entailment'], [1282, 'contradiction'], [1283, 'entailment'], [1284, 'neutral'], [1285, 'entailment'], [1286, 'contradiction'], [1287, 'neutral'], [1288, 'entailment'], [1289, 'neutral'], [1290, 'neutral'], [1291, 'neutral'], [1292, 'neutral'], [1293, 'neutral'], [1294, 'entailment'], [1295, 'contradiction'], [1296, 'contradiction'], [1297, 'neutral'], [1298, 'contradiction'], [1299, 'neutral'], [1300, 'contradiction'], [1301, 'entailment'], [1302, 'entailment'], [1303, 'neutral'], [1304, 'neutral'], [1305, 'neutral'], [1306, 'contradiction'], [1307, 'neutral'], [1308, 'entailment'], [1309, 'contradiction'], [1310, 'neutral'], [1311, 'contradiction'], [1312, 'contradiction'], [1313, 'neutral'], [1314, 'entailment'], [1315, 'neutral'], [1316, 'neutral'], [1317, 'entailment'], [1318, 'neutral'], [1319, 'contradiction'], [1320, 'contradiction'], [1321, 'entailment'], [1322, 'neutral'], [1323, 'contradiction'], [1324, 'contradiction'], [1325, 'neutral'], [1326, 'entailment'], [1327, 'neutral'], [1328, 'neutral'], [1329, 'contradiction'], [1330, 'neutral'], [1331, 'neutral'], [1332, 'contradiction'], [1333, 'neutral'], [1334, 'contradiction'], [1335, 'neutral'], [1336, 'contradiction'], [1337, 'neutral'], [1338, 'entailment'], [1339, 'neutral'], [1340, 'neutral'], [1341, 'contradiction'], [1342, 'entailment'], [1343, 'neutral'], [1344, 'neutral'], [1345, 'contradiction'], [1346, 'contradiction'], [1347, 'entailment'], [1348, 'contradiction'], [1349, 'neutral'], [1350, 'neutral'], [1351, 'neutral'], [1352, 'contradiction'], [1353, 'entailment'], [1354, 'neutral'], [1355, 'contradiction'], [1356, 'contradiction'], [1357, 'contradiction'], [1358, 'entailment'], [1359, 'contradiction'], [1360, 'neutral'], [1361, 'contradiction'], [1362, 'neutral'], [1363, 'neutral'], [1364, 'neutral'], [1365, 'neutral'], [1366, 'contradiction'], [1367, 'contradiction'], [1368, 'neutral'], [1369, 'contradiction'], [1370, 'neutral'], [1371, 'contradiction'], [1372, 'neutral'], [1373, 'contradiction'], [1374, 'neutral'], [1375, 'neutral'], [1376, 'neutral'], [1377, 'contradiction'], [1378, 'entailment'], [1379, 'neutral'], [1380, 'contradiction'], [1381, 'neutral'], [1382, 'neutral'], [1383, 'entailment'], [1384, 'contradiction'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'contradiction'], [1388, 'neutral'], [1389, 'contradiction'], [1390, 'entailment'], [1391, 'entailment'], [1392, 'neutral'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'neutral'], [1396, 'entailment'], [1397, 'entailment'], [1398, 'entailment'], [1399, 'neutral'], [1400, 'neutral'], [1401, 'neutral'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'contradiction'], [1406, 'entailment'], [1407, 'neutral'], [1408, 'contradiction'], [1409, 'contradiction'], [1410, 'contradiction'], [1411, 'neutral'], [1412, 'entailment'], [1413, 'entailment'], [1414, 'entailment'], [1415, 'neutral'], [1416, 'neutral'], [1417, 'contradiction'], [1418, 'entailment'], [1419, 'entailment'], [1420, 'neutral'], [1421, 'contradiction'], [1422, 'neutral'], [1423, 'entailment'], [1424, 'neutral'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'contradiction'], [1428, 'neutral'], [1429, 'neutral'], [1430, 'entailment'], [1431, 'neutral'], [1432, 'neutral'], [1433, 'entailment'], [1434, 'neutral'], [1435, 'neutral'], [1436, 'contradiction'], [1437, 'neutral'], [1438, 'neutral'], [1439, 'contradiction'], [1440, 'neutral'], [1441, 'entailment'], [1442, 'contradiction'], [1443, 'entailment'], [1444, 'neutral'], [1445, 'contradiction'], [1446, 'contradiction'], [1447, 'neutral'], [1448, 'contradiction'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'neutral'], [1452, 'entailment'], [1453, 'neutral'], [1454, 'neutral'], [1455, 'contradiction'], [1456, 'contradiction'], [1457, 'neutral'], [1458, 'neutral'], [1459, 'neutral'], [1460, 'contradiction'], [1461, 'neutral'], [1462, 'contradiction'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'contradiction'], [1466, 'contradiction'], [1467, 'neutral'], [1468, 'neutral'], [1469, 'neutral'], [1470, 'entailment'], [1471, 'contradiction'], [1472, 'neutral'], [1473, 'contradiction'], [1474, 'entailment'], [1475, 'neutral'], [1476, 'neutral'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'contradiction'], [1480, 'contradiction'], [1481, 'contradiction'], [1482, 'contradiction'], [1483, 'neutral'], [1484, 'entailment'], [1485, 'neutral'], [1486, 'neutral'], [1487, 'contradiction'], [1488, 'contradiction'], [1489, 'neutral'], [1490, 'neutral'], [1491, 'entailment'], [1492, 'neutral'], [1493, 'entailment'], [1494, 'neutral'], [1495, 'entailment'], [1496, 'contradiction'], [1497, 'contradiction'], [1498, 'entailment'], [1499, 'contradiction'], [1500, 'contradiction'], [1501, 'neutral'], [1502, 'entailment'], [1503, 'entailment'], [1504, 'contradiction'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'entailment'], [1508, 'neutral'], [1509, 'entailment'], [1510, 'entailment'], [1511, 'contradiction'], [1512, 'neutral'], [1513, 'neutral'], [1514, 'contradiction'], [1515, 'contradiction'], [1516, 'entailment'], [1517, 'neutral'], [1518, 'contradiction'], [1519, 'entailment'], [1520, 'neutral'], [1521, 'contradiction'], [1522, 'neutral'], [1523, 'entailment'], [1524, 'contradiction'], [1525, 'neutral'], [1526, 'neutral'], [1527, 'neutral'], [1528, 'neutral'], [1529, 'contradiction'], [1530, 'neutral'], [1531, 'entailment'], [1532, 'contradiction'], [1533, 'contradiction'], [1534, 'neutral'], [1535, 'contradiction'], [1536, 'neutral'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'neutral'], [1540, 'contradiction'], [1541, 'contradiction'], [1542, 'neutral'], [1543, 'neutral'], [1544, 'entailment'], [1545, 'contradiction'], [1546, 'neutral'], [1547, 'neutral'], [1548, 'neutral'], [1549, 'neutral'], [1550, 'contradiction'], [1551, 'entailment'], [1552, 'neutral'], [1553, 'entailment'], [1554, 'neutral'], [1555, 'neutral'], [1556, 'entailment'], [1557, 'neutral'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'neutral'], [1561, 'entailment'], [1562, 'neutral'], [1563, 'neutral'], [1564, 'contradiction'], [1565, 'entailment'], [1566, 'neutral'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'contradiction'], [1570, 'entailment'], [1571, 'contradiction'], [1572, 'entailment'], [1573, 'contradiction'], [1574, 'contradiction'], [1575, 'contradiction'], [1576, 'neutral'], [1577, 'contradiction'], [1578, 'neutral'], [1579, 'entailment'], [1580, 'neutral'], [1581, 'neutral'], [1582, 'contradiction'], [1583, 'entailment'], [1584, 'neutral'], [1585, 'neutral'], [1586, 'neutral'], [1587, 'neutral'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'contradiction'], [1591, 'entailment'], [1592, 'contradiction'], [1593, 'entailment'], [1594, 'neutral'], [1595, 'neutral'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'neutral'], [1599, 'neutral'], [1600, 'contradiction'], [1601, 'contradiction'], [1602, 'contradiction'], [1603, 'neutral'], [1604, 'entailment'], [1605, 'neutral'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'contradiction'], [1609, 'entailment'], [1610, 'neutral'], [1611, 'neutral'], [1612, 'entailment'], [1613, 'neutral'], [1614, 'entailment'], [1615, 'contradiction'], [1616, 'neutral'], [1617, 'neutral'], [1618, 'neutral'], [1619, 'contradiction'], [1620, 'neutral'], [1621, 'entailment'], [1622, 'contradiction'], [1623, 'neutral'], [1624, 'contradiction'], [1625, 'neutral'], [1626, 'neutral'], [1627, 'entailment'], [1628, 'contradiction'], [1629, 'entailment'], [1630, 'contradiction'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'entailment'], [1634, 'entailment'], [1635, 'neutral'], [1636, 'entailment'], [1637, 'contradiction'], [1638, 'entailment'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'entailment'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'contradiction'], [1645, 'neutral'], [1646, 'contradiction'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'contradiction'], [1650, 'contradiction'], [1651, 'entailment'], [1652, 'neutral'], [1653, 'contradiction'], [1654, 'contradiction'], [1655, 'entailment'], [1656, 'neutral'], [1657, 'contradiction'], [1658, 'neutral'], [1659, 'neutral'], [1660, 'entailment'], [1661, 'neutral'], [1662, 'entailment'], [1663, 'neutral'], [1664, 'neutral'], [1665, 'neutral']]\n"
     ]
    }
   ],
   "source": [
    "def num_to_label(label):\n",
    "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
    "    str_label = []\n",
    "\n",
    "    for i, v in enumerate(label):\n",
    "        str_label.append([i,label_dict[v]])\n",
    "    \n",
    "    return str_label\n",
    "\n",
    "answer = num_to_label(pred_answer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQ2t9exhwx9r",
    "outputId": "c7da8224-ffdb-4911-f111-3270c87ba521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index          label\n",
      "0         0  contradiction\n",
      "1         1        neutral\n",
      "2         2     entailment\n",
      "3         3  contradiction\n",
      "4         4  contradiction\n",
      "...     ...            ...\n",
      "1661   1661        neutral\n",
      "1662   1662     entailment\n",
      "1663   1663        neutral\n",
      "1664   1664        neutral\n",
      "1665   1665        neutral\n",
      "\n",
      "[1666 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
    "\n",
    "df.to_csv('roberta_large_submission.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7Zi4_T3w--b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K7aUlj6L7eAH",
    "outputId": "575cdb6d-f613-45e8-82d4-146d2a0c2761"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 17, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_103891/2152939973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meval_klue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/klue-nli-v1.1_dev.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_klue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/klue-nli-v1.1_train.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkakao_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/xnli.dev.ko.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mkakao_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/snli_1.0_train.ko.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mkakao_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/xnli.test.ko.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_env/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 17, saw 4\n"
     ]
    }
   ],
   "source": [
    "# dpath = '/content/drive/My Drive/Seculayer/KSRC/'\n",
    "train = pd.read_csv('data/train_data.csv',encoding='utf-8')\n",
    "test = pd.read_csv('data/test_data.csv',encoding='utf-8')\n",
    "eval_klue = pd.read_json(\"data/klue-nli-v1.1_dev.json\")\n",
    "train_klue = pd.read_json(\"data/klue-nli-v1.1_train.json\")\n",
    "kakao_dev = pd.read_csv('data/xnli.dev.ko.tsv')\n",
    "kakao_train = pd.read_csv('data/snli_1.0_train.ko.tsv')\n",
    "kakao_test = pd.read_csv('data/xnli.test.ko.tsv')\n",
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "094f33ed2071450d91c60f15b0331e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "095be4a6f89d4603b8a0b314727bd7a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1e6ccdaaa224d05be7928a5aafaab64",
      "max": 751504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5a393fdf1044e6298a258d4bb8fcd84",
      "value": 751504
     }
    },
    "0bbfd5f0ec2d4436a06bb502f8131f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cde98b9a09144b6b25b121ab70b4ff4",
      "placeholder": "​",
      "style": "IPY_MODEL_21f45f4a718446cea0a2ae70c743ba61",
      "value": "Downloading: 100%"
     }
    },
    "0cde98b9a09144b6b25b121ab70b4ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c3fbc303704c62957bd8c329b8024e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fe9d0f2a6924eba82b3502d43030b61",
       "IPY_MODEL_8902ff1c00df45c78d5b02464ee50756",
       "IPY_MODEL_8fdfe2b3e6e64012ac265a462fbcf328"
      ],
      "layout": "IPY_MODEL_ddd8542cdb7c4844b19cb62fa5e5e146"
     }
    },
    "16cd5a8125f64e618585d262ed0dcc39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1809bf6050194337a8a1efd347bf1f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a91d489ae164c8ca4243d06894962fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c5b91e6ae4d46d0b2f099cd1d4c15cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bbfd5f0ec2d4436a06bb502f8131f49",
       "IPY_MODEL_2613deb06698404396c37a2cc26f5dc4",
       "IPY_MODEL_daa90c709c4b46439770068ba936d25f"
      ],
      "layout": "IPY_MODEL_d66d726b5a104734a7bcfa4d5bfd53b2"
     }
    },
    "1ced7dcc914c47788ca51353a2245f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25ef02ee9d634d79b632eb0a5ad0f6fa",
       "IPY_MODEL_095be4a6f89d4603b8a0b314727bd7a4",
       "IPY_MODEL_c3e047157c734a5fbf6a6c8dc27c5913"
      ],
      "layout": "IPY_MODEL_16cd5a8125f64e618585d262ed0dcc39"
     }
    },
    "1d38cc6507084d34a2d41ada6a37b83e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f45f4a718446cea0a2ae70c743ba61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25ef02ee9d634d79b632eb0a5ad0f6fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3560910251ab4451ba5df9bf0953e999",
      "placeholder": "​",
      "style": "IPY_MODEL_c0ef75dc157d4b2a9c881661aa39347c",
      "value": "Downloading: 100%"
     }
    },
    "2613deb06698404396c37a2cc26f5dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3882a8be8ec44b9fb9595d4239c46930",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6e6cbbc9d0e443ca58cdcfe2c44f49e",
      "value": 375
     }
    },
    "27848cf6c21243f99f6421c294e2844f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c17f7168c24bcfbfb6cacf9d8a2b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd3c31a170a431ca04bbeeb641f6590": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341d1f2f2ec34446bcc1049dafda1c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3560910251ab4451ba5df9bf0953e999": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3882a8be8ec44b9fb9595d4239c46930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa68625b6364fdcb47c203b43277941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bebe6d4ba11479c8d6b952c786d5393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f4bd07499745d09d398568221a49aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a046ee54d1d485e84835c858f31be0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c07c3365e984f3596c00edb9cd2c184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cdf8336d32747629b01a6550240c6fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d26fc2e49c4bfaa89415d44a0606ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b541face9d74d2eae19066c55320567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afd8616825be40a8a52b1df11d73c64d",
      "placeholder": "​",
      "style": "IPY_MODEL_341d1f2f2ec34446bcc1049dafda1c82",
      "value": "Downloading: 100%"
     }
    },
    "5fe9d0f2a6924eba82b3502d43030b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3f1a17e1bd642e9b17fa94aff662eda",
      "placeholder": "​",
      "style": "IPY_MODEL_6c7eed7e50f34a1584a9639f26c277fe",
      "value": "Downloading: 100%"
     }
    },
    "683388a3551c4cfc922c56cba867d04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6860bf24436f4e098c668a285fd06f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b541face9d74d2eae19066c55320567",
       "IPY_MODEL_fbabe1a9a00a419b8c5f54375e80d952",
       "IPY_MODEL_f207ba49d03d4d11abd8a50c624eb7c8"
      ],
      "layout": "IPY_MODEL_3aa68625b6364fdcb47c203b43277941"
     }
    },
    "6be5e8971a294d58b173245f74bf1975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cd3c31a170a431ca04bbeeb641f6590",
      "placeholder": "​",
      "style": "IPY_MODEL_77abc577d69e4ca69ff1afe8c3a37d43",
      "value": "Downloading: 100%"
     }
    },
    "6c7eed7e50f34a1584a9639f26c277fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "704b74d3a9a040e9a11e57234af566ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73c789717a3745a9b431931ce845432b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77abc577d69e4ca69ff1afe8c3a37d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7af67cc2ae4b4c3abb9e7a208ecc9fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cb35513245c4927858d1ad05062340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8242b29066ed4717b957c897adba8533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8437c6dcd988498fb32f3d0557bb2385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_accc4b1e20d149aab8385df3109eb92f",
       "IPY_MODEL_9579ee57512f4bfbae9eeaac961ef7cb",
       "IPY_MODEL_a3591cd1d9f04511b42b45cde368fbc7"
      ],
      "layout": "IPY_MODEL_1d38cc6507084d34a2d41ada6a37b83e"
     }
    },
    "86daa3417a4147c4acc5b2cb0aff4935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6be5e8971a294d58b173245f74bf1975",
       "IPY_MODEL_ebdfb09f0319470db6ef22d68916b111",
       "IPY_MODEL_c0c048b2bc734c2a9a05a3195b29b136"
      ],
      "layout": "IPY_MODEL_f2b21dab53e944a58572bbdd6c9c94b0"
     }
    },
    "8902ff1c00df45c78d5b02464ee50756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c17f7168c24bcfbfb6cacf9d8a2b24",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1809bf6050194337a8a1efd347bf1f88",
      "value": 173
     }
    },
    "8fdfe2b3e6e64012ac265a462fbcf328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c40ba97a8a66488cb7b62cf85aead2b5",
      "placeholder": "​",
      "style": "IPY_MODEL_e8da32862f9049ceb6796662fcd4444f",
      "value": " 173/173 [00:00&lt;00:00, 3.16kB/s]"
     }
    },
    "9251c8da568641daacabf3e198c79290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9579ee57512f4bfbae9eeaac961ef7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_094f33ed2071450d91c60f15b0331e8c",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cb35513245c4927858d1ad05062340d",
      "value": 248477
     }
    },
    "a3591cd1d9f04511b42b45cde368fbc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f4bd07499745d09d398568221a49aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e03141fe0ca24aa888dc4ce1734ef897",
      "value": " 248k/248k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "accc4b1e20d149aab8385df3109eb92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c07c3365e984f3596c00edb9cd2c184",
      "placeholder": "​",
      "style": "IPY_MODEL_b18b9e54b8bb47a7ac0d5d4db9cc0946",
      "value": "Downloading: 100%"
     }
    },
    "afd8616825be40a8a52b1df11d73c64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18b9e54b8bb47a7ac0d5d4db9cc0946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1e6ccdaaa224d05be7928a5aafaab64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0c048b2bc734c2a9a05a3195b29b136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9251c8da568641daacabf3e198c79290",
      "placeholder": "​",
      "style": "IPY_MODEL_1a91d489ae164c8ca4243d06894962fa",
      "value": " 1.35G/1.35G [00:20&lt;00:00, 73.7MB/s]"
     }
    },
    "c0ef75dc157d4b2a9c881661aa39347c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3e047157c734a5fbf6a6c8dc27c5913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a046ee54d1d485e84835c858f31be0c",
      "placeholder": "​",
      "style": "IPY_MODEL_57d26fc2e49c4bfaa89415d44a0606ec",
      "value": " 752k/752k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "c40ba97a8a66488cb7b62cf85aead2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a393fdf1044e6298a258d4bb8fcd84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d66d726b5a104734a7bcfa4d5bfd53b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa90c709c4b46439770068ba936d25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cdf8336d32747629b01a6550240c6fe",
      "placeholder": "​",
      "style": "IPY_MODEL_8242b29066ed4717b957c897adba8533",
      "value": " 375/375 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "ddd8542cdb7c4844b19cb62fa5e5e146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e03141fe0ca24aa888dc4ce1734ef897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8da32862f9049ceb6796662fcd4444f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebdfb09f0319470db6ef22d68916b111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c789717a3745a9b431931ce845432b",
      "max": 1346930258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_704b74d3a9a040e9a11e57234af566ea",
      "value": 1346930258
     }
    },
    "f207ba49d03d4d11abd8a50c624eb7c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bebe6d4ba11479c8d6b952c786d5393",
      "placeholder": "​",
      "style": "IPY_MODEL_683388a3551c4cfc922c56cba867d04c",
      "value": " 547/547 [00:00&lt;00:00, 9.70kB/s]"
     }
    },
    "f2b21dab53e944a58572bbdd6c9c94b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f1a17e1bd642e9b17fa94aff662eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6e6cbbc9d0e443ca58cdcfe2c44f49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbabe1a9a00a419b8c5f54375e80d952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27848cf6c21243f99f6421c294e2844f",
      "max": 547,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7af67cc2ae4b4c3abb9e7a208ecc9fd5",
      "value": 547
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
