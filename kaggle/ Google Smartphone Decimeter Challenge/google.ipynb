{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58284316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f58d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../google-smartphone-decimeter-challenge\")\n",
    "df_test = pd.read_csv(\n",
    "    data_path / 'baseline_locations_test.csv')\n",
    "df_sub    = pd.read_csv(\n",
    "    data_path / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb51eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ac518fc58c459dbc2221dcd716ecad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "truths = (data_path / 'train').rglob('ground_truth.csv')\n",
    "df_list = []\n",
    "cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg',\n",
    "       'lngDeg']\n",
    "for t in tqdm(truths, total=73):\n",
    "    df_phone = pd.read_csv(t, usecols=cols)  \n",
    "    df_list.append(df_phone)\n",
    "df_truth = pd.concat(df_list, ignore_index=True)\n",
    "df_phone.head()\n",
    "df_basepreds = pd.read_csv(data_path / 'baseline_locations_train.csv', usecols=cols)\n",
    "df_all = df_truth.merge(df_basepreds, how='inner', on=cols[:3], suffixes=('_truth', '_basepred'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ba83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d193c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64035</th>\n",
       "      <td>2020-09-04-US-SF-1</td>\n",
       "      <td>8340.257976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114354</th>\n",
       "      <td>2020-07-17-US-MTV-2</td>\n",
       "      <td>5050.995543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52894</th>\n",
       "      <td>2021-04-26-US-SVL-1</td>\n",
       "      <td>2254.344928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113362</th>\n",
       "      <td>2020-07-17-US-MTV-2</td>\n",
       "      <td>2026.294654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113360</th>\n",
       "      <td>2020-07-17-US-MTV-2</td>\n",
       "      <td>1934.676643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108223</th>\n",
       "      <td>2021-04-29-US-SJC-2</td>\n",
       "      <td>1599.570433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83930</th>\n",
       "      <td>2020-05-29-US-MTV-1</td>\n",
       "      <td>1128.348831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113361</th>\n",
       "      <td>2020-07-17-US-MTV-2</td>\n",
       "      <td>1044.316856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54443</th>\n",
       "      <td>2021-01-05-US-SVL-1</td>\n",
       "      <td>653.703379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74448</th>\n",
       "      <td>2021-04-15-US-MTV-1</td>\n",
       "      <td>549.061548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             collectionName         dist\n",
       "64035    2020-09-04-US-SF-1  8340.257976\n",
       "114354  2020-07-17-US-MTV-2  5050.995543\n",
       "52894   2021-04-26-US-SVL-1  2254.344928\n",
       "113362  2020-07-17-US-MTV-2  2026.294654\n",
       "113360  2020-07-17-US-MTV-2  1934.676643\n",
       "108223  2021-04-29-US-SJC-2  1599.570433\n",
       "83930   2020-05-29-US-MTV-1  1128.348831\n",
       "113361  2020-07-17-US-MTV-2  1044.316856\n",
       "54443   2021-01-05-US-SVL-1   653.703379\n",
       "74448   2021-04-15-US-MTV-1   549.061548"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['dist'] = calc_haversine(df_all.latDeg_truth, df_all.lngDeg_truth, \n",
    "    df_all.latDeg_basepred, df_all.lngDeg_basepred)\n",
    "df_all.dist.describe()\n",
    "df_all.sort_values(by = 'dist',ascending = False)[['collectionName','dist']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609945d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    91486.000000\n",
       "mean        16.937410\n",
       "std         12.526582\n",
       "min          0.000000\n",
       "25%          5.200745\n",
       "50%         14.842604\n",
       "75%         28.551707\n",
       "max        391.394578\n",
       "Name: dist_pre, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['dist_pre'] = 0\n",
    "df_test['dist_pro'] = 0\n",
    "df_test['latDeg_pre'] = df_test['latDeg'].shift(periods=1,fill_value=0)\n",
    "df_test['lngDeg_pre'] = df_test['lngDeg'].shift(periods=1,fill_value=0)\n",
    "df_test['latDeg_pro'] = df_test['latDeg'].shift(periods=-1,fill_value=0)\n",
    "df_test['lngDeg_pro'] = df_test['lngDeg'].shift(periods=-1,fill_value=0)\n",
    "df_test['dist_pre'] = calc_haversine(df_test.latDeg_pre, df_test.lngDeg_pre, df_test.latDeg, df_test.lngDeg)\n",
    "df_test['dist_pro'] = calc_haversine(df_test.latDeg, df_test.lngDeg, df_test.latDeg_pro, df_test.lngDeg_pro)\n",
    "\n",
    "list_phone = df_test['phone'].unique()\n",
    "for phone in list_phone:\n",
    "    ind_s = df_test[df_test['phone'] == phone].index[0]\n",
    "    ind_e = df_test[df_test['phone'] == phone].index[-1]\n",
    "    df_test.loc[ind_s,'dist_pre'] = 0\n",
    "    df_test.loc[ind_e,'dist_pro'] = 0\n",
    "df_test.dist_pre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ad3b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_95 = df_test['dist_pro'].mean() + (df_test['dist_pro'].std() * 2)\n",
    "pre_95 = df_test['dist_pre'].mean() + (df_test['dist_pre'].std() * 2)\n",
    "ind = df_test[(df_test['dist_pro'] > pro_95)&(df_test['dist_pre'] > pre_95)][['dist_pre','dist_pro']].index\n",
    "\n",
    "for i in ind:\n",
    "    df_test.loc[i,'latDeg'] = (df_test.loc[i-1,'latDeg'] + df_test.loc[i+1,'latDeg'])/2\n",
    "    df_test.loc[i,'lngDeg'] = (df_test.loc[i-1,'lngDeg'] + df_test.loc[i+1,'lngDeg'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e555e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simdkalman\n",
      "  Downloading simdkalman-1.0.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/bainaonao/opt/anaconda3/lib/python3.9/site-packages (from simdkalman) (1.21.5)\n",
      "Installing collected packages: simdkalman\n",
      "Successfully installed simdkalman-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install simdkalman\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simdkalman\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e86c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7cb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in tqdm(unique_paths):\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80a4c6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61af8d26f83e4d2d89b1e5f56959fa92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf_smoothed_baseline = apply_kf_smoothing(df_test)\n",
    "df_sub = df_sub.assign(\n",
    "    latDeg = kf_smoothed_baseline.latDeg,\n",
    "    lngDeg = kf_smoothed_baseline.lngDeg\n",
    ")\n",
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff568f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
