{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  5 09:45:55 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   34C    P0    40W / 300W |      3MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   48C    P0   112W / 300W |   3663MiB / 32510MiB |     86%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      8898      C   .../envs/test_env/bin/python     1093MiB |\r\n",
      "|    1   N/A  N/A     90993      C   .../envs/test_env/bin/python     2567MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/centos/psw/KSRC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_bVw3BzS66Gp"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast, BartModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K7aUlj6L7eAH",
    "outputId": "575cdb6d-f613-45e8-82d4-146d2a0c2761"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...   \n",
       "2      2                    이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dpath = '/content/drive/My Drive/Seculayer/KSRC/'\n",
    "train = pd.read_csv('data/kakao_backtrans_klue_train.csv',encoding='utf-8').rename(columns={\"Unnamed: 0\" : \"index\"})\n",
    "test = pd.read_csv('data/test_data.csv',encoding='utf-8')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "yv3YDRoOHPoX",
    "outputId": "0883bafc-6b61-4dd4-c270-51516ed832f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2      2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불 용어 처리 \n",
    "\n",
    "train['premise'] = train['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['premise'] = test['premise'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "hCfxgISsHvZl",
    "outputId": "43f42d44-7632-48bd-d175-3c42d7029276"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2      2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                               hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다        neutral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hypothesis'] = train['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['hypothesis'] = test['hypothesis'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6FpW8SM7lwW",
    "outputId": "e779fb75-c660-4224-8296-fb17f2facfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212471 entries, 0 to 212470\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   index       212471 non-null  int64 \n",
      " 1   premise     212471 non-null  object\n",
      " 2   hypothesis  212471 non-null  object\n",
      " 3   label       212471 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 6.5+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1666 entries, 0 to 1665\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       1666 non-null   int64 \n",
      " 1   premise     1666 non-null   object\n",
      " 2   hypothesis  1666 non-null   object\n",
      " 3   label       1666 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 52.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 결측치는 없음\n",
    "\n",
    "print(train.info(), end='\\n\\n')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4L1jeCl72DF",
    "outputId": "b5c8ce74-4bce-4603-a0f6-e8cbcd527b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label: \n",
      "entailment       71740\n",
      "contradiction    71446\n",
      "neutral          69285\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Label: ', train['label'].value_counts(), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9SAoqqNmAU3x",
    "outputId": "cbe32eff-2df0-4a4f-9d17-50537c24cd33"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data imbalance는 사실상 존재하지 않음 \n",
    "\n",
    "sns.countplot(data=train,x='label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T6hQolMqAkji"
   },
   "outputs": [],
   "source": [
    "max_premise = np.max(train['premise'].str.len())\n",
    "\n",
    "max_hypothesis = np.max(train['hypothesis'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AApuxsJBcYi",
    "outputId": "744f3bd4-e74b-40cf-defb-abfd64225d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max premise = 135 \n",
      "max hypothesis = 102\n"
     ]
    }
   ],
   "source": [
    "print('max premise =',max_premise,\"\\nmax hypothesis =\",max_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAf/klEQVR4nO3dfZBc1Xnn8e9Pb8MgGEtjxhJIIpKD1jambKxMAIeUy0G2EMRlsWXM4vXGkldZJWVI/BpHxFtLGZss1LqCzdaKRDEKwnGQMYZFsVmDLGNnkzIvEmDxZlYDGEsaDZogId4iYTHP/nFPi1bTPdNz1Xe6e+b3qZrqe8899/bTV+p55p577jmKCMzMzPKY1OwAzMysfTmJmJlZbk4iZmaWm5OImZnl5iRiZma5TWl2AEU44YQTYv78+c0Ow8ysrWzduvVfI6JnNPuMyyQyf/58tmzZ0uwwzMzaiqRnRruPm7PMzCw3JxEzM8vNScTMzHJzEjEzs9ycRMzMLDcnETMzy81JxMzMcnMSMTOz3Mblw4bj0dDQEAMDAwDMnj2bSZOc/82s+fybqE0MDAywYs1drFhz1+FkYmbWbL4SaSOdXd3NDsHM7Ai+EjEzs9ycRMzMLDcnETMzy81JxMzMcnMSMTOz3Nw7q82EnxcxsxbiJNJmDr60jy9sGGTKtKnc8KklnHTSSc0OycwmsEL/jJX0WUmPSnpE0k2SjpG0QNK9kvokfUfStFS3I633pe3zy45zWSp/QtK5RcbcDjq6uv3MiJm1hMKSiKQ5wJ8CvRFxGjAZuBi4GrgmIk4B9gEr0y4rgX2p/JpUD0mnpv3eCSwF1kiaXFTc7WpoaIj+/n76+/sZGhpqdjhmNkEU3aA+BeiUNAU4FtgNnAPckravBy5Iy8vSOmn7YklK5Rsi4mBEPA30AWcUHHfb8bAoZtYMhSWRiNgFfA34FVny2A9sBZ6PiEOp2k5gTlqeA+xI+x5K9d9cXl5ln8MkrZK0RdKWwcHBxn+gFlO6wV5+5dHpZi4zG2NFNmfNJLuKWACcBEwna44qRESsjYjeiOjt6ekp6m1aRnaDfauvPMysqYpszvoA8HREDEbEr4FbgbOBGal5C2AusCst7wLmAaTtbwKeKy+vss+E5hvsZtZsRSaRXwFnSTo23dtYDDwG3A1cmOosB25PyxvTOmn7jyMiUvnFqffWAmAhcF+BcZuZWZ0Ke04kIu6VdAvwAHAIeBBYC/wA2CDpq6ns+rTL9cC3JPUBe8l6ZBERj0q6mSwBHQIuiYjXiorbzMzqV+jDhhFxOXB5RfFTVOldFREHgI/WOM6VwJUND9DMzI6Kx8wwM7PcnETMzCw3JxEzM8vNScTMzHJzEjEzs9ycRMzMLDcnETMzy81JxMzMcnMSMTOz3Dw97jjjOdjNbCw5ibS4oZQUBgYGIEau7znYzWwsOYm0uNKMhQde3Mf0npPr2qejq5tp06YWHJmZmZNIW+js6kb1XIaYmY0xN5ibmVluTiJmZpZbkXOsv03SQ2U/L0j6jKRuSZskbU+vM1N9SbpWUp+kbZIWlR1reaq/XdLy2u9qZmZjqbAkEhFPRMTpEXE68FvAK8BtwGpgc0QsBDandYDzyKa+XQisAq4DkNRNNrHVmWSTWV1eSjxmZtZcY9WctRh4MiKeAZYB61P5euCCtLwMuDEy9wAzJJ0InAtsioi9EbEP2AQsHaO4zcxsGGOVRC4GbkrLsyJid1oeAGal5TnAjrJ9dqayWuVmZtZkhScRSdOADwPfrdwWEUFdj9DV9T6rJG2RtGVwcLARhzQzsxGMxZXIecADEfFsWn82NVORXvek8l3AvLL95qayWuVHiIi1EdEbEb09PT0N/ghmZlbNWCSRj/F6UxbARqDUw2o5cHtZ+SdSL62zgP2p2etOYImkmemG+pJUZmZmTVboE+uSpgMfBP6orPgq4GZJK4FngItS+R3A+UAfWU+uTwJExF5JXwHuT/WuiIi9RcZtZmb1KTSJRMTLwJsryp4j661VWTeAS2ocZx2wrogYzcwsPz+xbmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OImZnlVmgSkTRD0i2SfiHpcUnvldQtaZOk7el1ZqorSddK6pO0TdKisuMsT/W3S1pe+x2tJIaGGBgYoL+/n6GhoWaHY2bjVNFXIt8AfhgRbwfeDTwOrAY2R8RCYHNaBzgPWJh+VgHXAUjqBi4HzgTOAC4vJR6r7eBL+/jChq2sWHMXAwMDzQ7HzMapwpKIpDcB7wOuB4iIVyPieWAZsD5VWw9ckJaXATdG5h5ghqQTgXOBTRGxNyL2AZuApUXFPZ50dHXT2dXd7DDMbBwr8kpkATAI/J2kByV9U9J0YFZE7E51BoBZaXkOsKNs/52prFb5ESStkrRF0pbBwcEGfxQzM6umyCQyBVgEXBcR7wFe5vWmKwAiIoBoxJtFxNqI6I2I3p6enkYc0szMRlBkEtkJ7IyIe9P6LWRJ5dnUTEV63ZO27wLmle0/N5XVKjczsyYrLIlExACwQ9LbUtFi4DFgI1DqYbUcuD0tbwQ+kXppnQXsT81edwJLJM1MN9SXpDIzM2uyKQUf/0+Ab0uaBjwFfJIscd0saSXwDHBRqnsHcD7QB7yS6hIReyV9Bbg/1bsiIvYWHLeZmdWh0CQSEQ8BvVU2La5SN4BLahxnHbCuocGZmdlRK/pKxJqs9NAhwOzZs5k0yYMUmFnjOImMc9lDh4NMmTaVGz61hJNOOqnZIZnZOOIkMgF0dHUzbdrUZodhZuOQ2zbMzCw3JxEzM8vNScTMzHJzEjEzs9ycRMzMLDf3zmpRQ+n5joGBgQYNUXnkccHPjZjZ0XMSaVEDAwOsWHMXB17cx/Sek4/6eFGWlFZ/bxsIPzdiZkfNSaSFdXZ1owZdhpQeOjx08CWm95zs50bMrCGcRCaQjq5uph7wP7mZNY4bxM3MLDcnETMzy81JxMzMcis0iUj6paSHJT0kaUsq65a0SdL29DozlUvStZL6JG2TtKjsOMtT/e2Sltd6P6tfqbdWf38/Q0NDzQ7HzNrUWFyJ/F5EnB4RpcmpVgObI2IhsDmtA5wHLEw/q4DrIEs6wOXAmcAZwOWlxGP5Zb21trJizV2HnxsxMxutZjRnLQPWp+X1wAVl5TdG5h5ghqQTgXOBTRGxNyL2AZuApWMc87jU0dVNZ1d3s8MwszZWdBIJ4C5JWyWtSmWzImJ3Wh4AZqXlOcCOsn13prJa5UeQtErSFklbBgcHG/kZzMyshrqSiKSz6ymr4ncjYhFZU9Ulkt5XvjHNq96Qp+kiYm1E9EZEb09PTyMOaWZmI6j3SuR/1ll2hIjYlV73ALeR3dN4NjVTkV73pOq7gHllu89NZbXKzcysyYZ9fFnSe4HfAXokfa5sUxcweYR9pwOTIuLFtLwEuALYCCwHrkqvt6ddNgKXStpAdhN9f0TslnQn8JdlN9OXAJeN4jNaHTwwo5nlMdIYGNOA41K948vKXwAuHGHfWcBtkkrv8w8R8UNJ9wM3S1oJPANclOrfAZwP9AGvAJ8EiIi9kr4C3J/qXRERe+v4bDYKpQEfwQMzmln9hk0iEfFT4KeSboiIZ0Zz4Ih4Cnh3lfLngMVVygO4pMax1gHrRvP+NnruqWVmo1XvaHwdktYC88v3iYhzigjKzMzaQ71J5LvAXwPfBF4rLhwzM2sn9SaRQxFxXaGRmJlZ26m3C84/SvqUpBPT2FfdaTgSMzObwOq9EikNevhnZWUBvLWx4ZiZWTupK4lExIKiAzEzs/ZTVxKR9Ilq5RFxY2PDMTOzdlJvc9Zvly0fQ/acxwOAk4iZ2QRWb3PWn5SvS5oBbCgiIGuu8PAnZjYK9V6JVHoZ8H2ScSibrGqQKdOmevgTMxtRvfdE/pHXh2yfDLwDuLmooKy5Orq6mTZtarPDMLM2UO+VyNfKlg8Bz0TEzgLiMTOzNlJXg3caiPEXZCP5zgReLTIoa77SvZH+/n6GhoaaHY6Ztah6Zza8CLgP+CjZ0O33ShppKHhrY9m9ka2sWHPX4RvtZmaV6m3O+hLw22mGQiT1AD8CbikqMGs+3xsxs5HU239zUimBJM/Vu6+kyZIelPT9tL5A0r2S+iR9R9K0VN6R1vvS9vllx7gslT8h6dw6Y7YGcLOWmQ2n3iTyQ0l3SlohaQXwA7KZCOvxaeDxsvWrgWsi4hRgH7Ayla8E9qXya1I9JJ0KXAy8E1gKrJE07NS81jhu1jKz4QybRCSdIunsiPgz4G+Ad6WfnwFrRzq4pLnA75PNQ4KyuXLP4fVmsPXABWl5WVonbV+c6i8DNkTEwYh4mmz63DPq/YB29Dq6uj3roZlVNdKVyNfJ5lMnIm6NiM9FxOeA29K2kXwd+CJQagd5M/B8RBxK6zuBOWl5DrAjvdchYH+qf7i8yj5mZtZEIyWRWRHxcGVhKps/3I6SPgTsiYit+cOrn6RVkrZI2jI4ODgWb2lmNuGNlERmDLOtc4R9zwY+LOmXZONsnQN8A5ghqdQrbC6wKy3vAuYBpO1vIruBf7i8yj6HRcTaiOiNiN6enp4RQmtdQ0ND9Pf3Z/cfYuT6ZmbNNFIS2SLpv1QWSvpDYNgrjIi4LCLmRsR8shvjP46IjwN3A6VnTJYDt6fljbw++dWFqX6k8otT760FwEKyZ1bGpYGBAVasuYvPrP8pr/76180Ox8xsWCM9J/IZ4DZJH+f1pNELTAP+fc73/HNgg6SvAg8C16fy64FvSeoD9pIlHiLiUUk3A4+RDblySUS8lvO920JnVzdqscsQj+5rZtUMm0Qi4lngdyT9HnBaKv5BRPx4NG8SET8BfpKWn6JK76qIOED2RHy1/a8ErhzNe1pjeXRfM6um3vlE7iZrhrIJzE+wm1klt0mYmVlueSelsgnK90bMrJyTiI2K742YWTknERs13xsxsxInETsqQ27eMpvQ/I23o1J6ONKj/JpNTL4SsaPmEX7NJi4nkSarbA4yM2snTiJNVmoOArjhU0uaHI2Z2eg4ibSA8dQc5BvtZhOLk4g1ROkhxIGBAVZ/bxsIP0diNgE4iVhDlB5CPHTwJab3nOznSMwmCCcRa5iOrm6mHvB/KbOJxA3WZmaWm/9stEJ4oEaziaGwb7akYyTdJ+nnkh6V9OVUvkDSvZL6JH1H0rRU3pHW+9L2+WXHuiyVPyHp3KJitsbJ7pFs9ZPsZuNckX8eHgTOiYh3A6cDSyWdBVwNXBMRpwD7gJWp/kpgXyq/JtVD0qlkU+W+E1gKrJE0ucC4rUE6uro55rgZDAwM0N/fz9DQULNDMrMGKyyJROaltDo1/QRwDnBLKl8PXJCWl6V10vbFkpTKN0TEwYh4GuijyvS61pp8RWI2vhXaUC1psqSHgD3AJuBJ4PmIOJSq7ATmpOU5wA6AtH0/8Oby8ir7lL/XKklbJG0ZHBws4NM01tDQEP39/dkv1mh2NMXq6Ooe9QOVpfPjKxiz1lbojfWIeA04XdIM4Dbg7QW+11pgLUBvb2/L/1ouDXdy4MV9fq6iisrhYPzQollrGpPeWRHxvKS7gfcCMyRNSVcbc4FdqdouYB6wU9IU4E3Ac2XlJeX7tLXOrm403i9Dkjy9tcbTcDBm41WRvbN60hUIkjqBDwKPA3cDF6Zqy4Hb0/LGtE7a/uOIiFR+ceq9tQBYCNxXVNxWDN8bMRufirwSORFYn3pSTQJujojvS3oM2CDpq8CDwPWp/vXAtyT1AXvJemQREY9Kuhl4DDgEXJKayazNeFpds/GnsCQSEduA91Qpf4oqvasi4gDw0RrHuhK4stExWusZKhvIkQDU7IjMbDh+Yt1awlDFKMAHXso6HEydMtlPvpu1MCcRawmVvdU6lXU4KI0OPHnqZK7+yOnMnj3bycSshTiJWFOVX4F0Hl+9t1pHVzdDB17gCxu2MmXaVHf5NWshTiI2piq7+lZegQzHN+bNWo+TiI2pUvNU6YoC8j0v42l4zVqDk4iNuUZcUfiJdrPW4CRibctPtJs1n9sAzMwsNycRMzPLzc1Z1tYqe3sBvuFuNoacRKytVevt5RvuZmPHScTaXmVvr/Ib7u4KbFYsJxEbF8qbtcoHbnRXYLNiOYnYuFBq1jp08KU3zBTZ2dWda1IsMxuZk4iNGx1d3Uw9UP2/dOW9E1+RmDVGkTMbzpN0t6THJD0q6dOpvFvSJknb0+vMVC5J10rqk7RN0qKyYy1P9bdLWl7rPc1KonJeErIk4wcUzRqryCuRQ8DnI+IBSccDWyVtAlYAmyPiKkmrgdXAnwPnkU19uxA4E7gOOFNSN3A50Ev262CrpI0Rsa/A2K3NVTZvDcc3383yK3Jmw93A7rT8oqTHgTnAMuD9qdp64CdkSWQZcGOaV/0eSTMknZjqboqIvQApES0FbioqdhsfhmveKk8cpYmwkG++m43WmNwTkTSfbKrce4FZKcEADACz0vIcYEfZbjtTWa3yyvdYBawCOPnk4f/ybKY3TP9qTVHqtdXZ1c2+XU++4Wa8mdWn8CQi6Tjge8BnIuIF6fVJsyMiJDXkV2lErAXWAvT29rbsr+fRzJ9hxers6qZzRg8HXniu2aGYta1CG38lTSVLIN+OiFtT8bOpmYr0uieV7wLmle0+N5XVKm9bnV3ddB4/o9lhmJkdtSJ7Zwm4Hng8Iv6qbNNGoNTDajlwe1n5J1IvrbOA/anZ605giaSZqSfXklRm1lClHl39/f0MDQ01OxyztlBkc9bZwB8AD0t6KJX9BXAVcLOklcAzwEVp2x3A+UAf8ArwSYCI2CvpK8D9qd4VpZvsZo1U6tE1eepkrv7I6cyePdu9tcxGUGTvrH/m8OATb7C4Sv0ALqlxrHXAusZFN/Z8Q709dHR1M3TgBb6wYasfTDSrg59YHyO+od5eygd19HMkZrU5iYyhzq5u5MuQtuNBHM1qcxIxq4OHSzGrzknELCc3c5k5iZjVVGuOkhI3c5k5iZjVVGuOkvKedp3HdxORrZeeLZk0aZKvTGzCcBIxG0a1QRwre9plXYKzZDOl4zh3DbYJxUnELIfKnnalZDPpmC4P5GgTiq+3zcwsNycRMzPLzc1ZBfNwJxNPqVeXb7TbROAkUjAPdzLxlPfq8o12G++cRMaAhzuZeOq50e6HFW08cBIxK1hUJAvgcBOn53a3duckYlawUvNWqVkLOKKJ012CrZ0VObPhOkl7JD1SVtYtaZOk7el1ZiqXpGsl9UnaJmlR2T7LU/3tkpZXey+zVtfR1X3EII7lUyR7RkVrZ0U2wt4ALK0oWw1sjoiFwOa0DnAesDD9rAKugyzpAJcDZwJnAJeXEo/ZeJFdqWxlxZq7Xh+ry6xNFJZEIuKfgMppbJcB69PyeuCCsvIbI3MPMEPSicC5wKaI2BsR+4BNvDExmbW9yisVs3Yx1t1BZkXE7rQ8AMxKy3OAHWX1dqayWuVvIGmVpC2StgwODjY2ajMzq6ppN9YjIiQ1rN9rRKwF1gL09va6P621rSE/rGhtZKyTyLOSToyI3am5ak8q3wXMK6s3N5XtAt5fUf6TMYjTbMxF2egGq7+3jQMv7fPDitbyxjqJbASWA1el19vLyi+VtIHsJvr+lGjuBP6y7Gb6EuCyMY7ZbExUzl/SqWDSMV1MnTLZDyVayyosiUi6iewq4gRJO8l6WV0F3CxpJfAMcFGqfgdwPtAHvAJ8EiAi9kr6CnB/qndFRFTerDcbN6rNX1L5nEmtKxI/AW/NUFgSiYiP1di0uErdAC6pcZx1wLoGhjYmPPCiNVJHV/cbZlaEI5OFp+u1ZvAT6wXxwItWlOGShbsJ21hzEimQB160onR2dVcdk8tsrDmJmLWp0r2SyVMnc/VHTs8KA1Azo7KJxknErI11dHUzdOAFvrBh6+FeXSMN6Ogb8NZITiJm40B5r66RZlb0DXhrJCcRs3Gm1syKs2fPPtxjsPP4bjd7WUM4iTSYu/ZaK6g2s2Jlj8GRugyb1cNJpMHctddaWbUeg27esqPhJFIAd+21dlDeRdjNW5aXk4jZBFU5Vpen6bU8nESOUmV7slk7GU2vLrNqnESOUmV7slm7qtWry/dIbDhOIg3g8YpsvKjWq8tsOL5ONTOz3HwlktMbngdxzxYbZyoHePS9EavGSWSUhqpMYeqeLTYe1ZoMyw8nWrm2SSKSlgLfACYD34yIq8by/Wslj075eRAbv6pNhlX6DgRDXP2R05k9e/YRySRvknFyak9tkUQkTQb+F/BBYCdwv6SNEfFYUe85VNHdcc+ePU4eNqFVjsZQGj24NBT9W97yFuD17wriiDG7St+lWkr7VSan0nuPtutxraQ0XLLKs08raGZ8bZFEgDOAvoh4CkDSBmAZUEgS6e/vZ2BggM/e8BMOvrSfSR3TGTr4MseeMBeAgy/szbpBvnro8Otr06Ye/kf8txf2cuDF54/YPtJr3v39vkf3vgD/1uKfuZXOWcnh70DHcRx8aT+X/u2PGDr48hHflSlpv2rfpVqvx54wl0MHX+LSv/0RU6dO4ZoV7wc4Yv9S+UjPZZXeFziifq3yvPu0gvL4blp98Zh2y1Y2vXlrk3QhsDQi/jCt/wFwZkRcWlZnFbAqrb4NeKLKoU4A/rXgcIvSrrG3a9zQvrG3a9zQvrG3a9xwZOy/ERE9o9m5Xa5ERhQRa4G1w9WRtCUiescopIZq19jbNW5o39jbNW5o39jbNW44+thbq2Gvtl3AvLL1uanMzMyaqF2SyP3AQkkLJE0DLgY2NjkmM7MJry2asyLikKRLgTvJuviui4hHcxxq2OauFteusbdr3NC+sbdr3NC+sbdr3HCUsbfFjXUzM2tN7dKcZWZmLchJxMzMcpswSUTSUklPSOqTtLrZ8dQiaZ6kuyU9JulRSZ9O5d2SNknanl5nNjvWaiRNlvSgpO+n9QWS7k3n/TupY0TLkTRD0i2SfiHpcUnvbYdzLumz6f/JI5JuknRMq55zSesk7ZH0SFlZ1XOszLXpM2yTtKh5kdeM/X+k/y/bJN0maUbZtstS7E9IOrcpQVM97rJtn5cUkk5I67nO+YRIImXDppwHnAp8TNKpzY2qpkPA5yPiVOAs4JIU62pgc0QsBDan9Vb0aeDxsvWrgWsi4hRgH7CyKVGN7BvADyPi7cC7yT5DS59zSXOAPwV6I+I0sk4nF9O65/wGYGlFWa1zfB6wMP2sAq4boxhruYE3xr4JOC0i3gX8P+AygPR9vRh4Z9pnTfod1Aw38Ma4kTQPWAL8qqw41zmfEEmEsmFTIuJVoDRsSsuJiN0R8UBafpHsl9kcsnjXp2rrgQuaEuAwJM0Ffh/4ZloXcA5wS6rSqnG/CXgfcD1ARLwaEc/TBuecrIdlp6QpwLHAblr0nEfEPwF7K4prneNlwI2RuQeYIenEMQm0imqxR8RdEXEord5D9vwaZLFviIiDEfE00Ef2O2jM1TjnANcAXySbyKIk1zmfKElkDrCjbH1nKmtpkuYD7wHuBWZFxO60aQCY1ay4hvF1sv+YpZH23gw8X/ZFa9XzvgAYBP4uNcV9U9J0WvycR8Qu4Gtkf03uBvYDW2mPc15S6xy323f2PwP/Jy23dOySlgG7IuLnFZtyxT1RkkjbkXQc8D3gMxHxQvm2yPplt1TfbEkfAvZExNZmx5LDFGARcF1EvAd4mYqmqxY95zPJ/npcAJwETKdK00W7aMVzXA9JXyJrhv52s2MZiaRjgb8A/lujjjlRkkhbDZsiaSpZAvl2RNyaip8tXVqm1z3Niq+Gs4EPS/olWXPhOWT3GWakphZo3fO+E9gZEfem9VvIkkqrn/MPAE9HxGBE/Bq4lezfoR3OeUmtc9wW31lJK4APAR+P1x+6a+XYf5Psj46fp+/qXOABSbPJGfdESSJtM2xKuo9wPfB4RPxV2aaNwPK0vBy4faxjG05EXBYRcyNiPtn5/XFEfBy4G7gwVWu5uAEiYgDYIeltqWgx2TQDLX3OyZqxzpJ0bPp/U4q75c95mVrneCPwidRj6Cxgf1mzV0tQNlHeF4EPR8QrZZs2AhdL6pC0gOxG9X3NiLFSRDwcEW+JiPnpu7oTWJS+A/nOeURMiB/gfLIeFE8CX2p2PMPE+btkl/TbgIfSz/lk9xc2A9uBHwHdzY51mM/wfuD7afmtZF+gPuC7QEez46sR8+nAlnTe/zcwsx3OOfBl4BfAI8C3gI5WPefATWT3bn6dfnmtrHWOAZH1qHwSeJisB1qrxd5Hdg+h9D3967L6X0qxPwGc10pxV2z/JXDC0ZxzD3tiZma5TZTmLDMzK4CTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OIWYuQdJKkW0auadY63MXXrEEkTY6I15odh9lY8pWIWR0kzU9zR3w7zTdyS3pS/JeSrpb0APBRSUsk/UzSA5K+m8ZAI9X775IekrRF0iJJd0p6UtIfl73HI2n5nZLuS/W3SVqYyv9TWfnfNHGIcTPAScRsNN4GrImIdwAvAJ9K5c9FxCKyJ67/K/CBtL4F+FzZ/r+KiNOB/0s2z8OFZHPGfLnKe/0x8I1UvxfYKekdwH8Azk7lrwEfb+DnMxu1KSNXMbNkR0T8S1r+e7IJoQC+k17PIpv07F+yoayYBvysbP/SeG0PA8dFNl/Mi5IOls+Kl/wM+FKao+XWiNguaTHwW8D96fidtN6gkDbBOImY1a/yBmJp/eX0KmBTRHysxv4H0+tQ2XJp/YjvYkT8g6R7ySb5ukPSH6Xjr4+Iy3LGb9Zwbs4yq9/Jkt6blv8j8M8V2+8BzpZ0CoCk6ZL+XZ43kvRW4KmIuJZsZNt3kQ1UeKGkt6Q63ZJ+I8/xzRrFScSsfk+QzXn/ONkov0fMQR0Rg8AK4CZJ28iapN6e870uAh6R9BBwGtm0pY+R3XO5Kx1/E9C0KWPNwF18zeqSpir+fkSc1uxYzFqJr0TMzCw3X4mYmVluvhIxM7PcnETMzCw3JxEzM8vNScTMzHJzEjEzs9z+P5D5hmJn91XJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['premise'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "5xFFliUaCiwR",
    "outputId": "b7132a6d-24cb-4773-edaa-13d9d7e75af2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['hypothesis'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 2023):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'tunib/electra-ko-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "config.num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "print(model)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 17041,  6093,  2184, 13846, 14447, 11561, 11348,     3, 17041,\n",
      "         6093, 22881, 11301,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "[CLS] 소년이 문 위로 올라가려고 한다 [SEP] 소년이 오르고 있다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# train test split 및 tokenizing \n",
    "# token에 들어가는 문장은 premise와 hypothesis를 concat 한 문장\n",
    "\n",
    "train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['label'])\n",
    "\n",
    "tokenized_train = tokenizer(\n",
    "    list(train_dataset['premise']),\n",
    "    list(train_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=300, # Max_Length = 190\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "tokenized_eval = tokenizer(\n",
    "    list(eval_dataset['premise']),\n",
    "    list(eval_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=300,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(tokenized_train['input_ids'][0])\n",
    "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "\n",
    "    return num_label\n",
    "\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "eval_label = label_to_num(eval_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169976\n",
      "{'input_ids': tensor([    2, 15196, 19937,   480,  6100,  6183, 12745, 11418,   788,  6006,\n",
      "         6285, 23368, 29793,  2923, 20312, 16011, 14387, 18588, 30770,  6148,\n",
      "        13488, 11327,     3, 16011, 15806,  2923, 20654,  6176, 30770,  6148,\n",
      "        13488, 20549, 12269,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(1)}\n",
      "[CLS] 다음날 학교에서 기하학 시험 때문에 낙제할 위기에 처한 서터는 에이미를 만나서 과외를 부탁한다 [SEP] 에이미는 서터에게 과외를 부탁받지 않았다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BERTDataset(tokenized_train, train_label)\n",
    "eval_dataset = BERTDataset(tokenized_eval, eval_label)\n",
    "\n",
    "print(train_dataset.__len__())\n",
    "print(train_dataset.__getitem__(19997))\n",
    "print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  \"\"\" validation을 위한 metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
    "\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_ars = TrainingArguments(\n",
    "    output_dir='result/kakao_backtrans_klue_electra/',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_total_limit=5,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 500,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_ars,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 169976\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18592\n",
      "  Number of trainable parameters = 110619651\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "[Kss]: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msangmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230105_095117-rqpy58oz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/rqpy58oz\" target=\"_blank\">result/kakao_backtrans_klue_electra/</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18592' max='18592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18592/18592 2:45:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.650700</td>\n",
       "      <td>0.514527</td>\n",
       "      <td>0.805201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.513700</td>\n",
       "      <td>0.482215</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.419551</td>\n",
       "      <td>0.842523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.451700</td>\n",
       "      <td>0.399838</td>\n",
       "      <td>0.850947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.379534</td>\n",
       "      <td>0.858007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.379348</td>\n",
       "      <td>0.867279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.377916</td>\n",
       "      <td>0.870597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.365716</td>\n",
       "      <td>0.874126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.364231</td>\n",
       "      <td>0.877609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.337657</td>\n",
       "      <td>0.882621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.390043</td>\n",
       "      <td>0.883398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.885657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.360640</td>\n",
       "      <td>0.887069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.354988</td>\n",
       "      <td>0.888340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>0.357810</td>\n",
       "      <td>0.890999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.425512</td>\n",
       "      <td>0.891634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.445688</td>\n",
       "      <td>0.890458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.420174</td>\n",
       "      <td>0.891776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.392725</td>\n",
       "      <td>0.893917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.893988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.388805</td>\n",
       "      <td>0.894999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.450447</td>\n",
       "      <td>0.892034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.502314</td>\n",
       "      <td>0.893540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.463190</td>\n",
       "      <td>0.893682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.471153</td>\n",
       "      <td>0.893046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.448863</td>\n",
       "      <td>0.893729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.522961</td>\n",
       "      <td>0.894435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.508890</td>\n",
       "      <td>0.897070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.531331</td>\n",
       "      <td>0.896482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.553673</td>\n",
       "      <td>0.895070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.529227</td>\n",
       "      <td>0.896105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.536578</td>\n",
       "      <td>0.896882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.593085</td>\n",
       "      <td>0.896647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.603151</td>\n",
       "      <td>0.896741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.609474</td>\n",
       "      <td>0.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.586573</td>\n",
       "      <td>0.896976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.589523</td>\n",
       "      <td>0.897306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-1000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-1000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-1000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-1500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-1500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-1500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-2000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-2000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-2000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-2500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-2500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-2500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-3000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-3000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-3500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-3500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-1000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-4000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-4000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-1500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-4500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-4500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-2000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-5000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-2500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-5500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-5500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-3000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-6000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-6000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-3500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-6500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-6500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-4000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-7000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-7000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-4500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-7500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-7500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-5500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-8000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-8000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-8500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-8500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-6500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-9000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-9000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-7000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-9500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-9500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-7500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-10000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-10000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-8000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-10500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-10500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-8500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-11000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-11000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-9000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-11500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-11500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-9500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-12000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-12000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-10000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-12500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-12500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-10500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-13000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-13000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-11000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-13500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-13500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-11500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-14000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-14000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-12000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-14500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-14500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-12500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-15000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-15000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-13000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-15500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-15500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-13500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-16000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-16000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-14000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-16500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-16500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-14500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-17000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-17000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-15000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-17500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-17500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-15500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-18000\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-18000/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-18000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-16000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42495\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/kakao_backtrans_klue_electra/checkpoint-18500\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/checkpoint-18500/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in result/kakao_backtrans_klue_electra/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in result/kakao_backtrans_klue_electra/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/kakao_backtrans_klue_electra/checkpoint-16500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/kakao_backtrans_klue_electra/checkpoint-5000 (score: 0.337656706571579).\n",
      "Configuration saved in result/kakao_backtrans_klue_electra/best_model/config.json\n",
      "Model weights saved in result/kakao_backtrans_klue_electra/best_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('result/kakao_backtrans_klue_electra/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file result/kakao_backtrans_klue_electra/best_model/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"result/kakao_backtrans_klue_electra/best_model\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file result/kakao_backtrans_klue_electra/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at result/kakao_backtrans_klue_electra/best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='tunib/electra-ko-base', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Tokenizer_NAME = \"tunib/electra-ko-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
    "\n",
    "MODEL_NAME = 'result/kakao_backtrans_klue_electra/best_model'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(tokenizer.vocab_size)\n",
    "model.to(device)\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n",
      "{'input_ids': tensor([    2,   791, 14921, 23745,  6237,   485, 15213,  2137,   204,  8377,\n",
      "        11304,     3,   791, 14921,  1485,  6020, 11461,  6015, 14521, 13377,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'label': tensor(3)}\n",
      "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다 [SEP] 18일 배를 타고 여행을 떠났습니다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "test_label = label_to_num(test['label'].values)\n",
    "\n",
    "tokenized_test = tokenizer(\n",
    "    list(test['premise']),\n",
    "    list(test['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "test_dataset = BERTDataset(tokenized_test, test_label)\n",
    "\n",
    "print(test_dataset.__len__())\n",
    "print(test_dataset.__getitem__(1665))\n",
    "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 46.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 1, 2, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 0, 1, 0, 0, 1, 1, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 2, 0, 0, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 1, 0, 2, 0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 0, 1, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 0, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 1, 1, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0, 2, 2, 1, 0, 1, 0, 2, 2, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 1, 1, 2, 1, 1, 2, 2, 2, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 1, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 0, 1, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 1, 2, 1, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 2, 1, 2, 2, 1, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 1, 1, 0, 0, 2, 2, 0, 1, 2, 2, 2, 1, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 1, 0, 2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 0, 1, 1, 0, 0, 2, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 1, 2, 2, 2, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 2, 0, 1, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 0, 2, 2, 1, 1, 1, 1, 2, 0, 1, 2, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 1, 0, 2, 2, 2, 0, 0, 1, 1, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 1, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 1, 1, 0, 1, 2, 2, 2, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 2, 1, 0, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 1, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 1, 1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 0, 2, 0, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 0, 1, 0, 1, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 0, 2, 2, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 0, 0, 2, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 0, 1, 1, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_pred = []\n",
    "output_prob = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=data['input_ids'].to(device),\n",
    "            attention_mask=data['attention_mask'].to(device),\n",
    "            token_type_ids=data['token_type_ids'].to(device)\n",
    "        )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'contradiction'], [1, 'neutral'], [2, 'entailment'], [3, 'contradiction'], [4, 'contradiction'], [5, 'neutral'], [6, 'contradiction'], [7, 'entailment'], [8, 'entailment'], [9, 'contradiction'], [10, 'contradiction'], [11, 'entailment'], [12, 'contradiction'], [13, 'entailment'], [14, 'neutral'], [15, 'neutral'], [16, 'entailment'], [17, 'neutral'], [18, 'contradiction'], [19, 'neutral'], [20, 'contradiction'], [21, 'neutral'], [22, 'entailment'], [23, 'entailment'], [24, 'contradiction'], [25, 'neutral'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'entailment'], [30, 'contradiction'], [31, 'entailment'], [32, 'contradiction'], [33, 'neutral'], [34, 'neutral'], [35, 'contradiction'], [36, 'entailment'], [37, 'contradiction'], [38, 'entailment'], [39, 'contradiction'], [40, 'neutral'], [41, 'entailment'], [42, 'contradiction'], [43, 'neutral'], [44, 'neutral'], [45, 'contradiction'], [46, 'neutral'], [47, 'entailment'], [48, 'contradiction'], [49, 'entailment'], [50, 'contradiction'], [51, 'contradiction'], [52, 'entailment'], [53, 'neutral'], [54, 'contradiction'], [55, 'entailment'], [56, 'neutral'], [57, 'neutral'], [58, 'entailment'], [59, 'neutral'], [60, 'entailment'], [61, 'neutral'], [62, 'neutral'], [63, 'neutral'], [64, 'neutral'], [65, 'contradiction'], [66, 'neutral'], [67, 'neutral'], [68, 'neutral'], [69, 'contradiction'], [70, 'entailment'], [71, 'neutral'], [72, 'entailment'], [73, 'contradiction'], [74, 'neutral'], [75, 'neutral'], [76, 'neutral'], [77, 'neutral'], [78, 'neutral'], [79, 'contradiction'], [80, 'contradiction'], [81, 'neutral'], [82, 'contradiction'], [83, 'contradiction'], [84, 'entailment'], [85, 'contradiction'], [86, 'contradiction'], [87, 'contradiction'], [88, 'entailment'], [89, 'neutral'], [90, 'contradiction'], [91, 'neutral'], [92, 'entailment'], [93, 'contradiction'], [94, 'entailment'], [95, 'entailment'], [96, 'contradiction'], [97, 'contradiction'], [98, 'entailment'], [99, 'neutral'], [100, 'neutral'], [101, 'entailment'], [102, 'neutral'], [103, 'entailment'], [104, 'neutral'], [105, 'neutral'], [106, 'neutral'], [107, 'neutral'], [108, 'contradiction'], [109, 'contradiction'], [110, 'contradiction'], [111, 'neutral'], [112, 'contradiction'], [113, 'entailment'], [114, 'neutral'], [115, 'entailment'], [116, 'entailment'], [117, 'contradiction'], [118, 'contradiction'], [119, 'contradiction'], [120, 'contradiction'], [121, 'contradiction'], [122, 'contradiction'], [123, 'neutral'], [124, 'entailment'], [125, 'entailment'], [126, 'entailment'], [127, 'entailment'], [128, 'contradiction'], [129, 'neutral'], [130, 'contradiction'], [131, 'neutral'], [132, 'contradiction'], [133, 'entailment'], [134, 'neutral'], [135, 'entailment'], [136, 'contradiction'], [137, 'neutral'], [138, 'contradiction'], [139, 'contradiction'], [140, 'neutral'], [141, 'neutral'], [142, 'neutral'], [143, 'entailment'], [144, 'neutral'], [145, 'contradiction'], [146, 'entailment'], [147, 'contradiction'], [148, 'neutral'], [149, 'neutral'], [150, 'contradiction'], [151, 'entailment'], [152, 'contradiction'], [153, 'neutral'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'neutral'], [158, 'neutral'], [159, 'contradiction'], [160, 'neutral'], [161, 'entailment'], [162, 'neutral'], [163, 'entailment'], [164, 'neutral'], [165, 'contradiction'], [166, 'neutral'], [167, 'entailment'], [168, 'neutral'], [169, 'entailment'], [170, 'neutral'], [171, 'neutral'], [172, 'entailment'], [173, 'entailment'], [174, 'contradiction'], [175, 'neutral'], [176, 'neutral'], [177, 'neutral'], [178, 'contradiction'], [179, 'neutral'], [180, 'contradiction'], [181, 'neutral'], [182, 'neutral'], [183, 'neutral'], [184, 'neutral'], [185, 'neutral'], [186, 'contradiction'], [187, 'neutral'], [188, 'entailment'], [189, 'contradiction'], [190, 'neutral'], [191, 'neutral'], [192, 'contradiction'], [193, 'entailment'], [194, 'neutral'], [195, 'entailment'], [196, 'neutral'], [197, 'neutral'], [198, 'entailment'], [199, 'neutral'], [200, 'neutral'], [201, 'neutral'], [202, 'entailment'], [203, 'contradiction'], [204, 'contradiction'], [205, 'entailment'], [206, 'entailment'], [207, 'neutral'], [208, 'entailment'], [209, 'neutral'], [210, 'contradiction'], [211, 'contradiction'], [212, 'contradiction'], [213, 'neutral'], [214, 'contradiction'], [215, 'contradiction'], [216, 'contradiction'], [217, 'entailment'], [218, 'contradiction'], [219, 'contradiction'], [220, 'neutral'], [221, 'neutral'], [222, 'entailment'], [223, 'contradiction'], [224, 'neutral'], [225, 'contradiction'], [226, 'contradiction'], [227, 'neutral'], [228, 'contradiction'], [229, 'contradiction'], [230, 'entailment'], [231, 'neutral'], [232, 'entailment'], [233, 'entailment'], [234, 'entailment'], [235, 'neutral'], [236, 'neutral'], [237, 'contradiction'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'contradiction'], [242, 'neutral'], [243, 'neutral'], [244, 'neutral'], [245, 'entailment'], [246, 'neutral'], [247, 'neutral'], [248, 'contradiction'], [249, 'contradiction'], [250, 'entailment'], [251, 'contradiction'], [252, 'neutral'], [253, 'entailment'], [254, 'contradiction'], [255, 'neutral'], [256, 'contradiction'], [257, 'contradiction'], [258, 'entailment'], [259, 'entailment'], [260, 'entailment'], [261, 'entailment'], [262, 'neutral'], [263, 'neutral'], [264, 'neutral'], [265, 'neutral'], [266, 'contradiction'], [267, 'neutral'], [268, 'contradiction'], [269, 'entailment'], [270, 'contradiction'], [271, 'neutral'], [272, 'entailment'], [273, 'entailment'], [274, 'neutral'], [275, 'contradiction'], [276, 'contradiction'], [277, 'contradiction'], [278, 'neutral'], [279, 'neutral'], [280, 'neutral'], [281, 'entailment'], [282, 'entailment'], [283, 'entailment'], [284, 'contradiction'], [285, 'entailment'], [286, 'neutral'], [287, 'contradiction'], [288, 'entailment'], [289, 'neutral'], [290, 'entailment'], [291, 'contradiction'], [292, 'entailment'], [293, 'neutral'], [294, 'entailment'], [295, 'contradiction'], [296, 'contradiction'], [297, 'contradiction'], [298, 'neutral'], [299, 'entailment'], [300, 'entailment'], [301, 'entailment'], [302, 'neutral'], [303, 'entailment'], [304, 'entailment'], [305, 'entailment'], [306, 'contradiction'], [307, 'contradiction'], [308, 'entailment'], [309, 'entailment'], [310, 'neutral'], [311, 'contradiction'], [312, 'contradiction'], [313, 'neutral'], [314, 'neutral'], [315, 'neutral'], [316, 'neutral'], [317, 'neutral'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'neutral'], [322, 'neutral'], [323, 'entailment'], [324, 'contradiction'], [325, 'entailment'], [326, 'contradiction'], [327, 'neutral'], [328, 'contradiction'], [329, 'contradiction'], [330, 'neutral'], [331, 'entailment'], [332, 'neutral'], [333, 'contradiction'], [334, 'contradiction'], [335, 'contradiction'], [336, 'neutral'], [337, 'contradiction'], [338, 'contradiction'], [339, 'entailment'], [340, 'contradiction'], [341, 'neutral'], [342, 'contradiction'], [343, 'contradiction'], [344, 'neutral'], [345, 'entailment'], [346, 'contradiction'], [347, 'contradiction'], [348, 'contradiction'], [349, 'neutral'], [350, 'contradiction'], [351, 'neutral'], [352, 'contradiction'], [353, 'neutral'], [354, 'contradiction'], [355, 'contradiction'], [356, 'neutral'], [357, 'entailment'], [358, 'contradiction'], [359, 'neutral'], [360, 'contradiction'], [361, 'contradiction'], [362, 'contradiction'], [363, 'neutral'], [364, 'contradiction'], [365, 'neutral'], [366, 'neutral'], [367, 'entailment'], [368, 'contradiction'], [369, 'neutral'], [370, 'contradiction'], [371, 'neutral'], [372, 'entailment'], [373, 'neutral'], [374, 'neutral'], [375, 'entailment'], [376, 'entailment'], [377, 'neutral'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'neutral'], [382, 'contradiction'], [383, 'neutral'], [384, 'entailment'], [385, 'contradiction'], [386, 'entailment'], [387, 'entailment'], [388, 'neutral'], [389, 'contradiction'], [390, 'neutral'], [391, 'entailment'], [392, 'contradiction'], [393, 'neutral'], [394, 'contradiction'], [395, 'contradiction'], [396, 'entailment'], [397, 'entailment'], [398, 'contradiction'], [399, 'entailment'], [400, 'contradiction'], [401, 'neutral'], [402, 'contradiction'], [403, 'contradiction'], [404, 'entailment'], [405, 'neutral'], [406, 'neutral'], [407, 'neutral'], [408, 'contradiction'], [409, 'neutral'], [410, 'contradiction'], [411, 'contradiction'], [412, 'contradiction'], [413, 'contradiction'], [414, 'neutral'], [415, 'contradiction'], [416, 'contradiction'], [417, 'entailment'], [418, 'contradiction'], [419, 'contradiction'], [420, 'neutral'], [421, 'neutral'], [422, 'entailment'], [423, 'neutral'], [424, 'entailment'], [425, 'neutral'], [426, 'entailment'], [427, 'contradiction'], [428, 'contradiction'], [429, 'contradiction'], [430, 'entailment'], [431, 'neutral'], [432, 'contradiction'], [433, 'neutral'], [434, 'entailment'], [435, 'neutral'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'entailment'], [442, 'entailment'], [443, 'neutral'], [444, 'contradiction'], [445, 'neutral'], [446, 'neutral'], [447, 'entailment'], [448, 'contradiction'], [449, 'contradiction'], [450, 'contradiction'], [451, 'entailment'], [452, 'entailment'], [453, 'contradiction'], [454, 'contradiction'], [455, 'entailment'], [456, 'neutral'], [457, 'contradiction'], [458, 'neutral'], [459, 'contradiction'], [460, 'entailment'], [461, 'entailment'], [462, 'contradiction'], [463, 'neutral'], [464, 'neutral'], [465, 'contradiction'], [466, 'contradiction'], [467, 'neutral'], [468, 'entailment'], [469, 'neutral'], [470, 'contradiction'], [471, 'neutral'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'neutral'], [476, 'entailment'], [477, 'contradiction'], [478, 'contradiction'], [479, 'contradiction'], [480, 'entailment'], [481, 'entailment'], [482, 'contradiction'], [483, 'contradiction'], [484, 'contradiction'], [485, 'entailment'], [486, 'entailment'], [487, 'neutral'], [488, 'contradiction'], [489, 'entailment'], [490, 'entailment'], [491, 'neutral'], [492, 'neutral'], [493, 'contradiction'], [494, 'entailment'], [495, 'contradiction'], [496, 'entailment'], [497, 'neutral'], [498, 'neutral'], [499, 'entailment'], [500, 'entailment'], [501, 'entailment'], [502, 'neutral'], [503, 'contradiction'], [504, 'contradiction'], [505, 'entailment'], [506, 'neutral'], [507, 'contradiction'], [508, 'entailment'], [509, 'entailment'], [510, 'neutral'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'contradiction'], [515, 'contradiction'], [516, 'neutral'], [517, 'entailment'], [518, 'contradiction'], [519, 'contradiction'], [520, 'neutral'], [521, 'contradiction'], [522, 'contradiction'], [523, 'neutral'], [524, 'neutral'], [525, 'neutral'], [526, 'entailment'], [527, 'entailment'], [528, 'contradiction'], [529, 'entailment'], [530, 'neutral'], [531, 'neutral'], [532, 'contradiction'], [533, 'neutral'], [534, 'neutral'], [535, 'contradiction'], [536, 'contradiction'], [537, 'contradiction'], [538, 'neutral'], [539, 'neutral'], [540, 'neutral'], [541, 'contradiction'], [542, 'contradiction'], [543, 'entailment'], [544, 'contradiction'], [545, 'neutral'], [546, 'contradiction'], [547, 'contradiction'], [548, 'neutral'], [549, 'entailment'], [550, 'neutral'], [551, 'contradiction'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'neutral'], [556, 'neutral'], [557, 'neutral'], [558, 'neutral'], [559, 'contradiction'], [560, 'contradiction'], [561, 'contradiction'], [562, 'neutral'], [563, 'neutral'], [564, 'entailment'], [565, 'neutral'], [566, 'entailment'], [567, 'entailment'], [568, 'neutral'], [569, 'contradiction'], [570, 'entailment'], [571, 'entailment'], [572, 'entailment'], [573, 'contradiction'], [574, 'entailment'], [575, 'contradiction'], [576, 'entailment'], [577, 'neutral'], [578, 'contradiction'], [579, 'neutral'], [580, 'contradiction'], [581, 'entailment'], [582, 'entailment'], [583, 'neutral'], [584, 'entailment'], [585, 'entailment'], [586, 'neutral'], [587, 'entailment'], [588, 'contradiction'], [589, 'entailment'], [590, 'entailment'], [591, 'neutral'], [592, 'contradiction'], [593, 'entailment'], [594, 'contradiction'], [595, 'contradiction'], [596, 'contradiction'], [597, 'neutral'], [598, 'entailment'], [599, 'entailment'], [600, 'contradiction'], [601, 'contradiction'], [602, 'contradiction'], [603, 'entailment'], [604, 'neutral'], [605, 'neutral'], [606, 'contradiction'], [607, 'contradiction'], [608, 'contradiction'], [609, 'contradiction'], [610, 'contradiction'], [611, 'contradiction'], [612, 'neutral'], [613, 'entailment'], [614, 'contradiction'], [615, 'contradiction'], [616, 'neutral'], [617, 'neutral'], [618, 'contradiction'], [619, 'neutral'], [620, 'contradiction'], [621, 'neutral'], [622, 'entailment'], [623, 'contradiction'], [624, 'entailment'], [625, 'contradiction'], [626, 'contradiction'], [627, 'contradiction'], [628, 'neutral'], [629, 'entailment'], [630, 'contradiction'], [631, 'entailment'], [632, 'neutral'], [633, 'entailment'], [634, 'neutral'], [635, 'entailment'], [636, 'contradiction'], [637, 'entailment'], [638, 'entailment'], [639, 'contradiction'], [640, 'neutral'], [641, 'entailment'], [642, 'neutral'], [643, 'entailment'], [644, 'neutral'], [645, 'entailment'], [646, 'neutral'], [647, 'contradiction'], [648, 'contradiction'], [649, 'neutral'], [650, 'entailment'], [651, 'neutral'], [652, 'contradiction'], [653, 'neutral'], [654, 'neutral'], [655, 'neutral'], [656, 'entailment'], [657, 'contradiction'], [658, 'entailment'], [659, 'contradiction'], [660, 'contradiction'], [661, 'contradiction'], [662, 'neutral'], [663, 'neutral'], [664, 'entailment'], [665, 'entailment'], [666, 'neutral'], [667, 'neutral'], [668, 'neutral'], [669, 'neutral'], [670, 'neutral'], [671, 'contradiction'], [672, 'contradiction'], [673, 'contradiction'], [674, 'neutral'], [675, 'entailment'], [676, 'contradiction'], [677, 'neutral'], [678, 'contradiction'], [679, 'contradiction'], [680, 'neutral'], [681, 'contradiction'], [682, 'entailment'], [683, 'contradiction'], [684, 'contradiction'], [685, 'entailment'], [686, 'entailment'], [687, 'contradiction'], [688, 'entailment'], [689, 'entailment'], [690, 'neutral'], [691, 'entailment'], [692, 'entailment'], [693, 'neutral'], [694, 'entailment'], [695, 'contradiction'], [696, 'entailment'], [697, 'entailment'], [698, 'neutral'], [699, 'neutral'], [700, 'neutral'], [701, 'entailment'], [702, 'entailment'], [703, 'neutral'], [704, 'entailment'], [705, 'entailment'], [706, 'contradiction'], [707, 'contradiction'], [708, 'neutral'], [709, 'contradiction'], [710, 'neutral'], [711, 'entailment'], [712, 'neutral'], [713, 'entailment'], [714, 'entailment'], [715, 'entailment'], [716, 'entailment'], [717, 'neutral'], [718, 'entailment'], [719, 'entailment'], [720, 'entailment'], [721, 'neutral'], [722, 'contradiction'], [723, 'contradiction'], [724, 'entailment'], [725, 'contradiction'], [726, 'neutral'], [727, 'contradiction'], [728, 'contradiction'], [729, 'entailment'], [730, 'entailment'], [731, 'neutral'], [732, 'contradiction'], [733, 'neutral'], [734, 'entailment'], [735, 'neutral'], [736, 'contradiction'], [737, 'contradiction'], [738, 'entailment'], [739, 'entailment'], [740, 'neutral'], [741, 'contradiction'], [742, 'entailment'], [743, 'entailment'], [744, 'contradiction'], [745, 'neutral'], [746, 'neutral'], [747, 'contradiction'], [748, 'neutral'], [749, 'contradiction'], [750, 'neutral'], [751, 'contradiction'], [752, 'neutral'], [753, 'entailment'], [754, 'entailment'], [755, 'neutral'], [756, 'neutral'], [757, 'contradiction'], [758, 'neutral'], [759, 'neutral'], [760, 'entailment'], [761, 'neutral'], [762, 'entailment'], [763, 'contradiction'], [764, 'neutral'], [765, 'entailment'], [766, 'neutral'], [767, 'entailment'], [768, 'contradiction'], [769, 'neutral'], [770, 'contradiction'], [771, 'neutral'], [772, 'neutral'], [773, 'contradiction'], [774, 'entailment'], [775, 'neutral'], [776, 'contradiction'], [777, 'neutral'], [778, 'neutral'], [779, 'neutral'], [780, 'entailment'], [781, 'contradiction'], [782, 'contradiction'], [783, 'neutral'], [784, 'entailment'], [785, 'entailment'], [786, 'contradiction'], [787, 'neutral'], [788, 'entailment'], [789, 'contradiction'], [790, 'entailment'], [791, 'neutral'], [792, 'entailment'], [793, 'neutral'], [794, 'neutral'], [795, 'entailment'], [796, 'contradiction'], [797, 'entailment'], [798, 'entailment'], [799, 'neutral'], [800, 'entailment'], [801, 'neutral'], [802, 'entailment'], [803, 'neutral'], [804, 'contradiction'], [805, 'contradiction'], [806, 'entailment'], [807, 'entailment'], [808, 'neutral'], [809, 'contradiction'], [810, 'entailment'], [811, 'contradiction'], [812, 'contradiction'], [813, 'neutral'], [814, 'neutral'], [815, 'neutral'], [816, 'entailment'], [817, 'neutral'], [818, 'neutral'], [819, 'entailment'], [820, 'neutral'], [821, 'neutral'], [822, 'contradiction'], [823, 'neutral'], [824, 'neutral'], [825, 'neutral'], [826, 'contradiction'], [827, 'neutral'], [828, 'contradiction'], [829, 'entailment'], [830, 'entailment'], [831, 'contradiction'], [832, 'contradiction'], [833, 'entailment'], [834, 'neutral'], [835, 'contradiction'], [836, 'entailment'], [837, 'contradiction'], [838, 'neutral'], [839, 'contradiction'], [840, 'neutral'], [841, 'neutral'], [842, 'contradiction'], [843, 'entailment'], [844, 'neutral'], [845, 'neutral'], [846, 'contradiction'], [847, 'contradiction'], [848, 'entailment'], [849, 'neutral'], [850, 'neutral'], [851, 'contradiction'], [852, 'entailment'], [853, 'neutral'], [854, 'contradiction'], [855, 'entailment'], [856, 'entailment'], [857, 'neutral'], [858, 'contradiction'], [859, 'contradiction'], [860, 'contradiction'], [861, 'entailment'], [862, 'contradiction'], [863, 'neutral'], [864, 'entailment'], [865, 'entailment'], [866, 'entailment'], [867, 'neutral'], [868, 'contradiction'], [869, 'neutral'], [870, 'contradiction'], [871, 'contradiction'], [872, 'entailment'], [873, 'entailment'], [874, 'neutral'], [875, 'neutral'], [876, 'entailment'], [877, 'contradiction'], [878, 'neutral'], [879, 'neutral'], [880, 'neutral'], [881, 'contradiction'], [882, 'contradiction'], [883, 'entailment'], [884, 'entailment'], [885, 'entailment'], [886, 'neutral'], [887, 'neutral'], [888, 'entailment'], [889, 'neutral'], [890, 'entailment'], [891, 'entailment'], [892, 'entailment'], [893, 'entailment'], [894, 'contradiction'], [895, 'neutral'], [896, 'entailment'], [897, 'neutral'], [898, 'entailment'], [899, 'entailment'], [900, 'contradiction'], [901, 'contradiction'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'neutral'], [906, 'contradiction'], [907, 'contradiction'], [908, 'contradiction'], [909, 'entailment'], [910, 'neutral'], [911, 'neutral'], [912, 'neutral'], [913, 'entailment'], [914, 'neutral'], [915, 'neutral'], [916, 'contradiction'], [917, 'contradiction'], [918, 'neutral'], [919, 'entailment'], [920, 'neutral'], [921, 'entailment'], [922, 'entailment'], [923, 'entailment'], [924, 'contradiction'], [925, 'contradiction'], [926, 'entailment'], [927, 'entailment'], [928, 'neutral'], [929, 'entailment'], [930, 'neutral'], [931, 'entailment'], [932, 'neutral'], [933, 'neutral'], [934, 'contradiction'], [935, 'contradiction'], [936, 'entailment'], [937, 'contradiction'], [938, 'entailment'], [939, 'contradiction'], [940, 'entailment'], [941, 'entailment'], [942, 'contradiction'], [943, 'neutral'], [944, 'neutral'], [945, 'entailment'], [946, 'entailment'], [947, 'neutral'], [948, 'neutral'], [949, 'entailment'], [950, 'contradiction'], [951, 'neutral'], [952, 'contradiction'], [953, 'contradiction'], [954, 'contradiction'], [955, 'entailment'], [956, 'neutral'], [957, 'entailment'], [958, 'contradiction'], [959, 'contradiction'], [960, 'neutral'], [961, 'contradiction'], [962, 'contradiction'], [963, 'entailment'], [964, 'entailment'], [965, 'neutral'], [966, 'neutral'], [967, 'entailment'], [968, 'entailment'], [969, 'contradiction'], [970, 'entailment'], [971, 'entailment'], [972, 'neutral'], [973, 'contradiction'], [974, 'contradiction'], [975, 'entailment'], [976, 'entailment'], [977, 'neutral'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'neutral'], [982, 'entailment'], [983, 'contradiction'], [984, 'neutral'], [985, 'neutral'], [986, 'contradiction'], [987, 'contradiction'], [988, 'neutral'], [989, 'contradiction'], [990, 'entailment'], [991, 'contradiction'], [992, 'neutral'], [993, 'contradiction'], [994, 'neutral'], [995, 'neutral'], [996, 'neutral'], [997, 'contradiction'], [998, 'entailment'], [999, 'entailment'], [1000, 'neutral'], [1001, 'entailment'], [1002, 'contradiction'], [1003, 'entailment'], [1004, 'neutral'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'neutral'], [1009, 'neutral'], [1010, 'neutral'], [1011, 'entailment'], [1012, 'neutral'], [1013, 'contradiction'], [1014, 'neutral'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'contradiction'], [1019, 'contradiction'], [1020, 'entailment'], [1021, 'neutral'], [1022, 'neutral'], [1023, 'neutral'], [1024, 'entailment'], [1025, 'entailment'], [1026, 'neutral'], [1027, 'neutral'], [1028, 'contradiction'], [1029, 'entailment'], [1030, 'entailment'], [1031, 'neutral'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'neutral'], [1035, 'contradiction'], [1036, 'neutral'], [1037, 'contradiction'], [1038, 'contradiction'], [1039, 'contradiction'], [1040, 'contradiction'], [1041, 'neutral'], [1042, 'contradiction'], [1043, 'entailment'], [1044, 'contradiction'], [1045, 'neutral'], [1046, 'contradiction'], [1047, 'entailment'], [1048, 'neutral'], [1049, 'contradiction'], [1050, 'contradiction'], [1051, 'contradiction'], [1052, 'entailment'], [1053, 'contradiction'], [1054, 'neutral'], [1055, 'entailment'], [1056, 'contradiction'], [1057, 'contradiction'], [1058, 'entailment'], [1059, 'neutral'], [1060, 'neutral'], [1061, 'contradiction'], [1062, 'contradiction'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'neutral'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'neutral'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'neutral'], [1073, 'neutral'], [1074, 'entailment'], [1075, 'contradiction'], [1076, 'entailment'], [1077, 'neutral'], [1078, 'contradiction'], [1079, 'entailment'], [1080, 'neutral'], [1081, 'neutral'], [1082, 'contradiction'], [1083, 'contradiction'], [1084, 'contradiction'], [1085, 'contradiction'], [1086, 'neutral'], [1087, 'entailment'], [1088, 'contradiction'], [1089, 'neutral'], [1090, 'contradiction'], [1091, 'neutral'], [1092, 'contradiction'], [1093, 'contradiction'], [1094, 'neutral'], [1095, 'neutral'], [1096, 'entailment'], [1097, 'neutral'], [1098, 'neutral'], [1099, 'contradiction'], [1100, 'entailment'], [1101, 'contradiction'], [1102, 'contradiction'], [1103, 'entailment'], [1104, 'contradiction'], [1105, 'entailment'], [1106, 'contradiction'], [1107, 'contradiction'], [1108, 'neutral'], [1109, 'entailment'], [1110, 'entailment'], [1111, 'contradiction'], [1112, 'contradiction'], [1113, 'entailment'], [1114, 'neutral'], [1115, 'neutral'], [1116, 'neutral'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'contradiction'], [1120, 'contradiction'], [1121, 'neutral'], [1122, 'neutral'], [1123, 'contradiction'], [1124, 'neutral'], [1125, 'neutral'], [1126, 'entailment'], [1127, 'contradiction'], [1128, 'entailment'], [1129, 'contradiction'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'neutral'], [1133, 'contradiction'], [1134, 'contradiction'], [1135, 'contradiction'], [1136, 'contradiction'], [1137, 'contradiction'], [1138, 'contradiction'], [1139, 'entailment'], [1140, 'contradiction'], [1141, 'neutral'], [1142, 'contradiction'], [1143, 'contradiction'], [1144, 'entailment'], [1145, 'neutral'], [1146, 'entailment'], [1147, 'contradiction'], [1148, 'entailment'], [1149, 'contradiction'], [1150, 'entailment'], [1151, 'contradiction'], [1152, 'contradiction'], [1153, 'neutral'], [1154, 'entailment'], [1155, 'neutral'], [1156, 'neutral'], [1157, 'entailment'], [1158, 'neutral'], [1159, 'neutral'], [1160, 'entailment'], [1161, 'contradiction'], [1162, 'contradiction'], [1163, 'contradiction'], [1164, 'neutral'], [1165, 'entailment'], [1166, 'neutral'], [1167, 'entailment'], [1168, 'neutral'], [1169, 'neutral'], [1170, 'contradiction'], [1171, 'neutral'], [1172, 'contradiction'], [1173, 'neutral'], [1174, 'neutral'], [1175, 'entailment'], [1176, 'neutral'], [1177, 'entailment'], [1178, 'neutral'], [1179, 'contradiction'], [1180, 'neutral'], [1181, 'entailment'], [1182, 'contradiction'], [1183, 'neutral'], [1184, 'contradiction'], [1185, 'neutral'], [1186, 'neutral'], [1187, 'neutral'], [1188, 'entailment'], [1189, 'contradiction'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'neutral'], [1193, 'neutral'], [1194, 'entailment'], [1195, 'entailment'], [1196, 'contradiction'], [1197, 'neutral'], [1198, 'contradiction'], [1199, 'neutral'], [1200, 'entailment'], [1201, 'neutral'], [1202, 'entailment'], [1203, 'neutral'], [1204, 'contradiction'], [1205, 'neutral'], [1206, 'contradiction'], [1207, 'contradiction'], [1208, 'entailment'], [1209, 'contradiction'], [1210, 'neutral'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'contradiction'], [1214, 'neutral'], [1215, 'contradiction'], [1216, 'neutral'], [1217, 'entailment'], [1218, 'neutral'], [1219, 'neutral'], [1220, 'neutral'], [1221, 'contradiction'], [1222, 'neutral'], [1223, 'neutral'], [1224, 'entailment'], [1225, 'contradiction'], [1226, 'contradiction'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'neutral'], [1230, 'contradiction'], [1231, 'contradiction'], [1232, 'entailment'], [1233, 'entailment'], [1234, 'neutral'], [1235, 'entailment'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'neutral'], [1240, 'contradiction'], [1241, 'neutral'], [1242, 'neutral'], [1243, 'contradiction'], [1244, 'entailment'], [1245, 'contradiction'], [1246, 'contradiction'], [1247, 'contradiction'], [1248, 'neutral'], [1249, 'entailment'], [1250, 'neutral'], [1251, 'entailment'], [1252, 'contradiction'], [1253, 'contradiction'], [1254, 'neutral'], [1255, 'contradiction'], [1256, 'contradiction'], [1257, 'entailment'], [1258, 'contradiction'], [1259, 'entailment'], [1260, 'neutral'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'neutral'], [1264, 'neutral'], [1265, 'neutral'], [1266, 'entailment'], [1267, 'contradiction'], [1268, 'contradiction'], [1269, 'contradiction'], [1270, 'contradiction'], [1271, 'entailment'], [1272, 'contradiction'], [1273, 'entailment'], [1274, 'contradiction'], [1275, 'neutral'], [1276, 'neutral'], [1277, 'entailment'], [1278, 'contradiction'], [1279, 'entailment'], [1280, 'contradiction'], [1281, 'entailment'], [1282, 'contradiction'], [1283, 'entailment'], [1284, 'neutral'], [1285, 'entailment'], [1286, 'contradiction'], [1287, 'neutral'], [1288, 'entailment'], [1289, 'neutral'], [1290, 'neutral'], [1291, 'neutral'], [1292, 'neutral'], [1293, 'neutral'], [1294, 'entailment'], [1295, 'contradiction'], [1296, 'contradiction'], [1297, 'neutral'], [1298, 'contradiction'], [1299, 'neutral'], [1300, 'contradiction'], [1301, 'entailment'], [1302, 'entailment'], [1303, 'neutral'], [1304, 'neutral'], [1305, 'neutral'], [1306, 'contradiction'], [1307, 'neutral'], [1308, 'entailment'], [1309, 'contradiction'], [1310, 'neutral'], [1311, 'contradiction'], [1312, 'neutral'], [1313, 'contradiction'], [1314, 'entailment'], [1315, 'neutral'], [1316, 'neutral'], [1317, 'entailment'], [1318, 'neutral'], [1319, 'entailment'], [1320, 'entailment'], [1321, 'entailment'], [1322, 'neutral'], [1323, 'contradiction'], [1324, 'entailment'], [1325, 'neutral'], [1326, 'entailment'], [1327, 'neutral'], [1328, 'neutral'], [1329, 'contradiction'], [1330, 'neutral'], [1331, 'neutral'], [1332, 'contradiction'], [1333, 'neutral'], [1334, 'contradiction'], [1335, 'neutral'], [1336, 'contradiction'], [1337, 'neutral'], [1338, 'entailment'], [1339, 'neutral'], [1340, 'neutral'], [1341, 'contradiction'], [1342, 'entailment'], [1343, 'neutral'], [1344, 'entailment'], [1345, 'contradiction'], [1346, 'contradiction'], [1347, 'entailment'], [1348, 'contradiction'], [1349, 'neutral'], [1350, 'neutral'], [1351, 'neutral'], [1352, 'contradiction'], [1353, 'entailment'], [1354, 'entailment'], [1355, 'contradiction'], [1356, 'contradiction'], [1357, 'contradiction'], [1358, 'entailment'], [1359, 'contradiction'], [1360, 'neutral'], [1361, 'contradiction'], [1362, 'neutral'], [1363, 'neutral'], [1364, 'neutral'], [1365, 'neutral'], [1366, 'contradiction'], [1367, 'contradiction'], [1368, 'entailment'], [1369, 'contradiction'], [1370, 'neutral'], [1371, 'contradiction'], [1372, 'neutral'], [1373, 'contradiction'], [1374, 'contradiction'], [1375, 'neutral'], [1376, 'neutral'], [1377, 'contradiction'], [1378, 'entailment'], [1379, 'entailment'], [1380, 'contradiction'], [1381, 'neutral'], [1382, 'contradiction'], [1383, 'entailment'], [1384, 'contradiction'], [1385, 'entailment'], [1386, 'neutral'], [1387, 'contradiction'], [1388, 'neutral'], [1389, 'contradiction'], [1390, 'neutral'], [1391, 'entailment'], [1392, 'neutral'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'neutral'], [1396, 'entailment'], [1397, 'entailment'], [1398, 'entailment'], [1399, 'neutral'], [1400, 'contradiction'], [1401, 'neutral'], [1402, 'neutral'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'contradiction'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'contradiction'], [1409, 'contradiction'], [1410, 'contradiction'], [1411, 'neutral'], [1412, 'neutral'], [1413, 'entailment'], [1414, 'neutral'], [1415, 'neutral'], [1416, 'neutral'], [1417, 'contradiction'], [1418, 'neutral'], [1419, 'entailment'], [1420, 'entailment'], [1421, 'contradiction'], [1422, 'contradiction'], [1423, 'entailment'], [1424, 'neutral'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'contradiction'], [1428, 'neutral'], [1429, 'neutral'], [1430, 'neutral'], [1431, 'neutral'], [1432, 'neutral'], [1433, 'entailment'], [1434, 'neutral'], [1435, 'neutral'], [1436, 'contradiction'], [1437, 'entailment'], [1438, 'neutral'], [1439, 'contradiction'], [1440, 'contradiction'], [1441, 'entailment'], [1442, 'contradiction'], [1443, 'entailment'], [1444, 'neutral'], [1445, 'contradiction'], [1446, 'contradiction'], [1447, 'neutral'], [1448, 'entailment'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'neutral'], [1452, 'entailment'], [1453, 'neutral'], [1454, 'neutral'], [1455, 'contradiction'], [1456, 'contradiction'], [1457, 'neutral'], [1458, 'neutral'], [1459, 'neutral'], [1460, 'contradiction'], [1461, 'neutral'], [1462, 'contradiction'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'contradiction'], [1466, 'contradiction'], [1467, 'neutral'], [1468, 'neutral'], [1469, 'contradiction'], [1470, 'entailment'], [1471, 'contradiction'], [1472, 'neutral'], [1473, 'contradiction'], [1474, 'entailment'], [1475, 'neutral'], [1476, 'neutral'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'contradiction'], [1480, 'contradiction'], [1481, 'contradiction'], [1482, 'contradiction'], [1483, 'neutral'], [1484, 'entailment'], [1485, 'neutral'], [1486, 'neutral'], [1487, 'contradiction'], [1488, 'contradiction'], [1489, 'entailment'], [1490, 'neutral'], [1491, 'entailment'], [1492, 'neutral'], [1493, 'neutral'], [1494, 'neutral'], [1495, 'entailment'], [1496, 'contradiction'], [1497, 'contradiction'], [1498, 'entailment'], [1499, 'contradiction'], [1500, 'contradiction'], [1501, 'neutral'], [1502, 'entailment'], [1503, 'entailment'], [1504, 'contradiction'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'contradiction'], [1508, 'neutral'], [1509, 'contradiction'], [1510, 'entailment'], [1511, 'contradiction'], [1512, 'contradiction'], [1513, 'neutral'], [1514, 'contradiction'], [1515, 'contradiction'], [1516, 'entailment'], [1517, 'neutral'], [1518, 'neutral'], [1519, 'contradiction'], [1520, 'entailment'], [1521, 'contradiction'], [1522, 'neutral'], [1523, 'entailment'], [1524, 'contradiction'], [1525, 'neutral'], [1526, 'contradiction'], [1527, 'neutral'], [1528, 'neutral'], [1529, 'contradiction'], [1530, 'neutral'], [1531, 'entailment'], [1532, 'contradiction'], [1533, 'contradiction'], [1534, 'neutral'], [1535, 'contradiction'], [1536, 'neutral'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'neutral'], [1540, 'contradiction'], [1541, 'contradiction'], [1542, 'neutral'], [1543, 'neutral'], [1544, 'entailment'], [1545, 'contradiction'], [1546, 'entailment'], [1547, 'contradiction'], [1548, 'neutral'], [1549, 'neutral'], [1550, 'contradiction'], [1551, 'entailment'], [1552, 'neutral'], [1553, 'entailment'], [1554, 'neutral'], [1555, 'neutral'], [1556, 'entailment'], [1557, 'neutral'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'neutral'], [1561, 'entailment'], [1562, 'neutral'], [1563, 'neutral'], [1564, 'contradiction'], [1565, 'entailment'], [1566, 'contradiction'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'contradiction'], [1570, 'entailment'], [1571, 'contradiction'], [1572, 'neutral'], [1573, 'contradiction'], [1574, 'contradiction'], [1575, 'contradiction'], [1576, 'neutral'], [1577, 'neutral'], [1578, 'contradiction'], [1579, 'entailment'], [1580, 'neutral'], [1581, 'contradiction'], [1582, 'contradiction'], [1583, 'entailment'], [1584, 'neutral'], [1585, 'neutral'], [1586, 'neutral'], [1587, 'neutral'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'contradiction'], [1591, 'entailment'], [1592, 'contradiction'], [1593, 'entailment'], [1594, 'neutral'], [1595, 'neutral'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'neutral'], [1599, 'neutral'], [1600, 'contradiction'], [1601, 'contradiction'], [1602, 'contradiction'], [1603, 'neutral'], [1604, 'entailment'], [1605, 'neutral'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'contradiction'], [1609, 'entailment'], [1610, 'neutral'], [1611, 'neutral'], [1612, 'entailment'], [1613, 'neutral'], [1614, 'entailment'], [1615, 'contradiction'], [1616, 'neutral'], [1617, 'contradiction'], [1618, 'neutral'], [1619, 'contradiction'], [1620, 'neutral'], [1621, 'entailment'], [1622, 'contradiction'], [1623, 'neutral'], [1624, 'contradiction'], [1625, 'neutral'], [1626, 'neutral'], [1627, 'contradiction'], [1628, 'contradiction'], [1629, 'neutral'], [1630, 'contradiction'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'neutral'], [1634, 'entailment'], [1635, 'neutral'], [1636, 'entailment'], [1637, 'contradiction'], [1638, 'contradiction'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'neutral'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'contradiction'], [1645, 'neutral'], [1646, 'contradiction'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'contradiction'], [1650, 'contradiction'], [1651, 'entailment'], [1652, 'neutral'], [1653, 'contradiction'], [1654, 'contradiction'], [1655, 'entailment'], [1656, 'neutral'], [1657, 'contradiction'], [1658, 'neutral'], [1659, 'entailment'], [1660, 'entailment'], [1661, 'neutral'], [1662, 'neutral'], [1663, 'neutral'], [1664, 'neutral'], [1665, 'neutral']]\n"
     ]
    }
   ],
   "source": [
    "def num_to_label(label):\n",
    "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
    "    str_label = []\n",
    "\n",
    "    for i, v in enumerate(label):\n",
    "        str_label.append([i,label_dict[v]])\n",
    "    \n",
    "    return str_label\n",
    "\n",
    "answer = num_to_label(pred_answer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index          label\n",
      "0         0  contradiction\n",
      "1         1        neutral\n",
      "2         2     entailment\n",
      "3         3  contradiction\n",
      "4         4  contradiction\n",
      "...     ...            ...\n",
      "1661   1661        neutral\n",
      "1662   1662        neutral\n",
      "1663   1663        neutral\n",
      "1664   1664        neutral\n",
      "1665   1665        neutral\n",
      "\n",
      "[1666 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
    "\n",
    "df.to_csv('kakao_backtrans_electra_submission.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "094f33ed2071450d91c60f15b0331e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "095be4a6f89d4603b8a0b314727bd7a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1e6ccdaaa224d05be7928a5aafaab64",
      "max": 751504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5a393fdf1044e6298a258d4bb8fcd84",
      "value": 751504
     }
    },
    "0bbfd5f0ec2d4436a06bb502f8131f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cde98b9a09144b6b25b121ab70b4ff4",
      "placeholder": "​",
      "style": "IPY_MODEL_21f45f4a718446cea0a2ae70c743ba61",
      "value": "Downloading: 100%"
     }
    },
    "0cde98b9a09144b6b25b121ab70b4ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c3fbc303704c62957bd8c329b8024e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fe9d0f2a6924eba82b3502d43030b61",
       "IPY_MODEL_8902ff1c00df45c78d5b02464ee50756",
       "IPY_MODEL_8fdfe2b3e6e64012ac265a462fbcf328"
      ],
      "layout": "IPY_MODEL_ddd8542cdb7c4844b19cb62fa5e5e146"
     }
    },
    "16cd5a8125f64e618585d262ed0dcc39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1809bf6050194337a8a1efd347bf1f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a91d489ae164c8ca4243d06894962fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c5b91e6ae4d46d0b2f099cd1d4c15cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bbfd5f0ec2d4436a06bb502f8131f49",
       "IPY_MODEL_2613deb06698404396c37a2cc26f5dc4",
       "IPY_MODEL_daa90c709c4b46439770068ba936d25f"
      ],
      "layout": "IPY_MODEL_d66d726b5a104734a7bcfa4d5bfd53b2"
     }
    },
    "1ced7dcc914c47788ca51353a2245f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25ef02ee9d634d79b632eb0a5ad0f6fa",
       "IPY_MODEL_095be4a6f89d4603b8a0b314727bd7a4",
       "IPY_MODEL_c3e047157c734a5fbf6a6c8dc27c5913"
      ],
      "layout": "IPY_MODEL_16cd5a8125f64e618585d262ed0dcc39"
     }
    },
    "1d38cc6507084d34a2d41ada6a37b83e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f45f4a718446cea0a2ae70c743ba61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25ef02ee9d634d79b632eb0a5ad0f6fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3560910251ab4451ba5df9bf0953e999",
      "placeholder": "​",
      "style": "IPY_MODEL_c0ef75dc157d4b2a9c881661aa39347c",
      "value": "Downloading: 100%"
     }
    },
    "2613deb06698404396c37a2cc26f5dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3882a8be8ec44b9fb9595d4239c46930",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6e6cbbc9d0e443ca58cdcfe2c44f49e",
      "value": 375
     }
    },
    "27848cf6c21243f99f6421c294e2844f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c17f7168c24bcfbfb6cacf9d8a2b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd3c31a170a431ca04bbeeb641f6590": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341d1f2f2ec34446bcc1049dafda1c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3560910251ab4451ba5df9bf0953e999": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3882a8be8ec44b9fb9595d4239c46930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa68625b6364fdcb47c203b43277941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bebe6d4ba11479c8d6b952c786d5393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f4bd07499745d09d398568221a49aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a046ee54d1d485e84835c858f31be0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c07c3365e984f3596c00edb9cd2c184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cdf8336d32747629b01a6550240c6fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d26fc2e49c4bfaa89415d44a0606ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b541face9d74d2eae19066c55320567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afd8616825be40a8a52b1df11d73c64d",
      "placeholder": "​",
      "style": "IPY_MODEL_341d1f2f2ec34446bcc1049dafda1c82",
      "value": "Downloading: 100%"
     }
    },
    "5fe9d0f2a6924eba82b3502d43030b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3f1a17e1bd642e9b17fa94aff662eda",
      "placeholder": "​",
      "style": "IPY_MODEL_6c7eed7e50f34a1584a9639f26c277fe",
      "value": "Downloading: 100%"
     }
    },
    "683388a3551c4cfc922c56cba867d04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6860bf24436f4e098c668a285fd06f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b541face9d74d2eae19066c55320567",
       "IPY_MODEL_fbabe1a9a00a419b8c5f54375e80d952",
       "IPY_MODEL_f207ba49d03d4d11abd8a50c624eb7c8"
      ],
      "layout": "IPY_MODEL_3aa68625b6364fdcb47c203b43277941"
     }
    },
    "6be5e8971a294d58b173245f74bf1975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cd3c31a170a431ca04bbeeb641f6590",
      "placeholder": "​",
      "style": "IPY_MODEL_77abc577d69e4ca69ff1afe8c3a37d43",
      "value": "Downloading: 100%"
     }
    },
    "6c7eed7e50f34a1584a9639f26c277fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "704b74d3a9a040e9a11e57234af566ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73c789717a3745a9b431931ce845432b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77abc577d69e4ca69ff1afe8c3a37d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7af67cc2ae4b4c3abb9e7a208ecc9fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cb35513245c4927858d1ad05062340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8242b29066ed4717b957c897adba8533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8437c6dcd988498fb32f3d0557bb2385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_accc4b1e20d149aab8385df3109eb92f",
       "IPY_MODEL_9579ee57512f4bfbae9eeaac961ef7cb",
       "IPY_MODEL_a3591cd1d9f04511b42b45cde368fbc7"
      ],
      "layout": "IPY_MODEL_1d38cc6507084d34a2d41ada6a37b83e"
     }
    },
    "86daa3417a4147c4acc5b2cb0aff4935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6be5e8971a294d58b173245f74bf1975",
       "IPY_MODEL_ebdfb09f0319470db6ef22d68916b111",
       "IPY_MODEL_c0c048b2bc734c2a9a05a3195b29b136"
      ],
      "layout": "IPY_MODEL_f2b21dab53e944a58572bbdd6c9c94b0"
     }
    },
    "8902ff1c00df45c78d5b02464ee50756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c17f7168c24bcfbfb6cacf9d8a2b24",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1809bf6050194337a8a1efd347bf1f88",
      "value": 173
     }
    },
    "8fdfe2b3e6e64012ac265a462fbcf328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c40ba97a8a66488cb7b62cf85aead2b5",
      "placeholder": "​",
      "style": "IPY_MODEL_e8da32862f9049ceb6796662fcd4444f",
      "value": " 173/173 [00:00&lt;00:00, 3.16kB/s]"
     }
    },
    "9251c8da568641daacabf3e198c79290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9579ee57512f4bfbae9eeaac961ef7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_094f33ed2071450d91c60f15b0331e8c",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cb35513245c4927858d1ad05062340d",
      "value": 248477
     }
    },
    "a3591cd1d9f04511b42b45cde368fbc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f4bd07499745d09d398568221a49aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e03141fe0ca24aa888dc4ce1734ef897",
      "value": " 248k/248k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "accc4b1e20d149aab8385df3109eb92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c07c3365e984f3596c00edb9cd2c184",
      "placeholder": "​",
      "style": "IPY_MODEL_b18b9e54b8bb47a7ac0d5d4db9cc0946",
      "value": "Downloading: 100%"
     }
    },
    "afd8616825be40a8a52b1df11d73c64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18b9e54b8bb47a7ac0d5d4db9cc0946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1e6ccdaaa224d05be7928a5aafaab64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0c048b2bc734c2a9a05a3195b29b136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9251c8da568641daacabf3e198c79290",
      "placeholder": "​",
      "style": "IPY_MODEL_1a91d489ae164c8ca4243d06894962fa",
      "value": " 1.35G/1.35G [00:20&lt;00:00, 73.7MB/s]"
     }
    },
    "c0ef75dc157d4b2a9c881661aa39347c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3e047157c734a5fbf6a6c8dc27c5913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a046ee54d1d485e84835c858f31be0c",
      "placeholder": "​",
      "style": "IPY_MODEL_57d26fc2e49c4bfaa89415d44a0606ec",
      "value": " 752k/752k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "c40ba97a8a66488cb7b62cf85aead2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a393fdf1044e6298a258d4bb8fcd84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d66d726b5a104734a7bcfa4d5bfd53b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa90c709c4b46439770068ba936d25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cdf8336d32747629b01a6550240c6fe",
      "placeholder": "​",
      "style": "IPY_MODEL_8242b29066ed4717b957c897adba8533",
      "value": " 375/375 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "ddd8542cdb7c4844b19cb62fa5e5e146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e03141fe0ca24aa888dc4ce1734ef897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8da32862f9049ceb6796662fcd4444f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebdfb09f0319470db6ef22d68916b111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c789717a3745a9b431931ce845432b",
      "max": 1346930258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_704b74d3a9a040e9a11e57234af566ea",
      "value": 1346930258
     }
    },
    "f207ba49d03d4d11abd8a50c624eb7c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bebe6d4ba11479c8d6b952c786d5393",
      "placeholder": "​",
      "style": "IPY_MODEL_683388a3551c4cfc922c56cba867d04c",
      "value": " 547/547 [00:00&lt;00:00, 9.70kB/s]"
     }
    },
    "f2b21dab53e944a58572bbdd6c9c94b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f1a17e1bd642e9b17fa94aff662eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6e6cbbc9d0e443ca58cdcfe2c44f49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbabe1a9a00a419b8c5f54375e80d952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27848cf6c21243f99f6421c294e2844f",
      "max": 547,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7af67cc2ae4b4c3abb9e7a208ecc9fd5",
      "value": 547
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
