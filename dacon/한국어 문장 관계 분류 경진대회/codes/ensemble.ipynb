{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f28008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast, BartModel\n",
    "from itertools import combinations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e509002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test_data.csv',encoding='utf-8')\n",
    "test['premise'] = test['premise'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "test['hypothesis'] = test['hypothesis'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3933302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 2023):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325d0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "\n",
    "    return num_label\n",
    "\n",
    "test_label = label_to_num(test['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3ccb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prob(model_str,weight_address):\n",
    "\n",
    "    Tokenizer_NAME = model_str\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
    "\n",
    "    MODEL_NAME = weight_address\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "    model.resize_token_embeddings(tokenizer.vocab_size)\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    tokenized_test = tokenizer(\n",
    "        list(test['premise']),\n",
    "        list(test['hypothesis']),\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=128,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    test_dataset = BERTDataset(tokenized_test, test_label)\n",
    "    \n",
    "    dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    output_pred = []\n",
    "    output_prob = []\n",
    "\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device)\n",
    "            )\n",
    "        logits = outputs[0]\n",
    "        prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        result = np.argmax(logits, axis=-1)\n",
    "\n",
    "        output_pred.append(result)\n",
    "        output_prob.append(prob)\n",
    "\n",
    "    pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "    df = pd.DataFrame(output_prob)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55de10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:07<00:00, 14.74it/s]\n"
     ]
    }
   ],
   "source": [
    "Large_data_roberta_hyperparameter = make_prob(\"klue/roberta-large\",\n",
    "                                              'result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c0ff02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:07<00:00, 14.49it/s]\n"
     ]
    }
   ],
   "source": [
    "Roberta_Large_Concat = make_prob(\"klue/roberta-large\",\n",
    "                                 \"result/Roberta_Large_Concat/checkpoint-4000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "94e6e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 42.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# ko_electra_with_kakao_backtrans_klue_data = make_prob(\"tunib/electra-ko-base\",\n",
    "#                                                       \"result/kakao_backtrans_klue_electra/checkpoint-5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7f415791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 36.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# ko_electra_concat = make_prob(\"snunlp/KR-ELECTRA-discriminator\",\n",
    "#                               \"result/Kr_Electra_Concat/checkpoint-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19efda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:07<00:00, 14.71it/s]\n"
     ]
    }
   ],
   "source": [
    "simple_roberta_tune = make_prob(\"klue/roberta-large\",\n",
    "                                \"result/simple_roberta_tune/run-12/checkpoint-4000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b792269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:07<00:00, 14.73it/s]\n"
     ]
    }
   ],
   "source": [
    "simple_roberta_more_epoch = make_prob(\"klue/roberta-large\",\n",
    "                                      \"result/simple_roberta_more_epoch/checkpoint-5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "97f59eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 42.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# pure_test_electra = make_prob(\"tunib/electra-ko-base\",\n",
    "#                               \"result/pure_test_electra/checkpoint-4500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af23391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 44.53it/s]\n"
     ]
    }
   ],
   "source": [
    "use_more_data = make_prob(\"tunib/electra-ko-base\",\n",
    "                              \"result/many_data_electra/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3eddeee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 43.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# electra_hyperparameter_tune = make_prob(\"tunib/electra-ko-base\",\n",
    "#                               \"result/electra_hyperparameter_tune/run-2/checkpoint-7200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4324f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list = [Large_data_roberta_hyperparameter,\n",
    "             simple_roberta_tune,\n",
    "             simple_roberta_more_epoch,\n",
    "             use_more_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8876d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(lists,combination):\n",
    "    voted_list = []\n",
    "    label_idx = { \"entailment\": 0, \"contradiction\": 1,  'neutral':2}\n",
    "    for p in combinations(lists,combination):\n",
    "        df = pd.DataFrame(np.zeros(shape=(1666,3), dtype=float))\n",
    "        submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "        for i in p:\n",
    "            df += i\n",
    "        df = df/len(p)\n",
    "        result = [np.argmax(val) for val in np.array(df)]\n",
    "        out = [list(label_idx.keys())[_] for _ in result] \n",
    "        submission['label'] = out\n",
    "        voted_list.append(submission)\n",
    "    return voted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "616d7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting(prob_list,4)[0].to_csv(\"full_soft_voted.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "716580db",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_3 = soft_voting(prob_list,3)\n",
    "\n",
    "for i in range(len(combination_3)):\n",
    "    combination_3[i].to_csv(\"soft_voted/combination_{}th_soft_voted.csv\".format(i),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35161bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
