{
    "pipeline_setting": {
        "train": true,
        "test": false,
        "checkpoint_dir": "./saved/model/",
        "load_pretrained": false,
        "resume": true,
        "state_dict": "fold4_microsoft-deberta-v3-large_state_dict.pth",
        "before_best": 0.6277,
        "name": "DeBERTaTrainer",
        "loop": "train_loop",
        "dataset": "NERDataset",
        "model_arch": "DeBERTaModel",
        "model": "microsoft/deberta-v3-large",
        "pooling": "SubSequenceGEMPooling"
    },
    "common_settings": {
        "wandb": true,
        "optuna": false,
        "competition": "FBP2",
        "seed": 42,
        "n_gpu": 1,
        "gpu_id": 0,
        "num_workers": 4
    },
    "data_settings": {
        "n_folds": 5,
        "max_len": 2048,
        "epochs": 5,
        "batch_size": 8,
        "val_batch_size": 8
    },
    "gradient_settings": {
        "amp_scaler": true,
        "gradient_checkpoint": true,
        "clipping_grad": true,
        "n_gradient_accumulation_steps": 1,
        "max_grad_norm": 1000
    },
    "loss_options": {
        "loss_fn": "CrossEntropyLoss",
        "reduction": "mean"
    },
    "metrics_options": {
        "metrics": "ConfusionMatrixMetrics"
    },
    "optimizer_options": {
        "optimizer": "AdamW",
        "llrd": true,
        "layerwise_lr": 5e-5,
        "layerwise_lr_decay": 0.9,
        "layerwise_weight_decay": 1e-2,
        "layerwise_adam_epsilon": 1e-6,
        "layerwise_use_bertadam": false,
        "betas": [0.9, 0.999]
    },
    "scheduler_options": {
        "scheduler": "cosine_annealing",
        "batch_scheduler": true,
        "num_cycles": 1,
        "warmup_ratio": 0.1
    },
    "swa_options": {
        "swa": false,
        "swa_lr": 5e-6,
        "anneal_epochs": 1,
        "anneal_strategy": "cos"
    },
    "model_utils": {
        "init_weight": "normal",
        "stop_mode": "max",
        "freeze": true,
        "num_freeze": 4,
        "reinit": true,
        "num_reinit": 5,
        "awp": false,
        "nth_awp_start_epoch": 2,
        "awp_eps": 1e-2,
        "awp_lr": 1e-4
    }
}
