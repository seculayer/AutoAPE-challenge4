{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  5 12:50:38 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   37C    P0    65W / 300W |  25874MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   49C    P0    92W / 300W |  22515MiB / 32510MiB |     82%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     18663      C   .../envs/test_env/bin/python    25871MiB |\r\n",
      "|    1   N/A  N/A      8898      C   .../envs/test_env/bin/python     1093MiB |\r\n",
      "|    1   N/A  N/A     18663      C   .../envs/test_env/bin/python    21419MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/centos/psw/KSRC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_bVw3BzS66Gp"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast, BartModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159475 entries, 0 to 159474\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   premise     159475 non-null  object\n",
      " 1   hypothesis  159475 non-null  object\n",
      " 2   label       159475 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "kakao_train = pd.read_csv('data/with_kakao_train.csv',encoding='utf-8')\n",
    "kakao_train = kakao_train.drop(['Unnamed: 0',\"index\"], axis=1)\n",
    "kakao_train.to_csv('data/with_kakao_train.csv',encoding='utf-8')\n",
    "kakao_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52996 entries, 0 to 52995\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   premise     52996 non-null  object\n",
      " 1   hypothesis  52996 non-null  object\n",
      " 2   label       52996 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "backtrans_df = pd.read_csv('data/backtrans_df',encoding='utf-8')\n",
    "backtrans_hyp_df = pd.read_csv('data/backtrans_hyp_df',encoding='utf-8')\n",
    "backtrans = pd.DataFrame({'premise':backtrans_df['premise'],\"hypothesis\":backtrans_hyp_df['hyphothesis'],'label':backtrans_df['label']})\n",
    "backtrans.info()\n",
    "backtrans.to_csv('data/backtrans.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bullyong(df):\n",
    "    df['premise'] = df['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "    df['hypothesis'] = df['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test_data.csv',encoding='utf-8')\n",
    "\n",
    "kakao_train = bullyong(kakao_train)\n",
    "backtrans = bullyong(backtrans)\n",
    "test = bullyong(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6FpW8SM7lwW",
    "outputId": "e779fb75-c660-4224-8296-fb17f2facfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52996 entries, 0 to 52995\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   premise     52996 non-null  object\n",
      " 1   hypothesis  52996 non-null  object\n",
      " 2   label       52996 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159475 entries, 0 to 159474\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   premise     159475 non-null  object\n",
      " 1   hypothesis  159475 non-null  object\n",
      " 2   label       159475 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1666 entries, 0 to 1665\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       1666 non-null   int64 \n",
      " 1   premise     1666 non-null   object\n",
      " 2   hypothesis  1666 non-null   object\n",
      " 3   label       1666 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 52.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 결측치는 없음\n",
    "\n",
    "print(backtrans.info(), end='\\n\\n')\n",
    "print(kakao_train.info(), end='\\n\\n')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 2023):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'tunib/electra-ko-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "config.num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "print(model)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 180576 entries, 85621 to 17512\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   premise     180576 non-null  object\n",
      " 1   hypothesis  180576 non-null  object\n",
      " 2   label       180576 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.5+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31895 entries, 144111 to 151902\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   premise     31895 non-null  object\n",
      " 1   hypothesis  31895 non-null  object\n",
      " 2   label       31895 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 996.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "backtrans_dataset = train_test_split(backtrans, shuffle=True)\n",
    "pd.concat([backtrans_dataset[0], backtrans_dataset[1]], axis = 0)\n",
    "\n",
    "train_dataset, eval_dataset = train_test_split(kakao_train, test_size=0.2, shuffle=True, stratify=kakao_train['label'])\n",
    "train_dataset = pd.concat([train_dataset,backtrans],axis=0)\n",
    "train_dataset = train_test_split(train_dataset, shuffle=True)\n",
    "train_dataset = pd.concat([train_dataset[0], train_dataset[1]], axis = 0)\n",
    "\n",
    "print(train_dataset.info(), end='\\n\\n')\n",
    "print(eval_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2,  1312, 14208, 19413,  6155, 18077, 24389, 17911,  6037, 16904,\n",
      "        11301,     3, 14717,  3190,  6220,  6184,  6296, 12550, 11306, 11774,\n",
      "         1312, 14208, 18077, 24389, 17911,  6037, 16904, 11301,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "[CLS] 두 아이가 방치된 더블 유모차에서 자고 있다 [SEP] 엄마가 식료품점 안에 있는 동안 두 아이가 더블 유모차에서 자고 있다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# train test split 및 tokenizing \n",
    "# token에 들어가는 문장은 premise와 hypothesis를 concat 한 문장\n",
    "\n",
    "# train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['label'])\n",
    "\n",
    "tokenized_train = tokenizer(\n",
    "    list(train_dataset['premise']),\n",
    "    list(train_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=300, # Max_Length = 190\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "tokenized_eval = tokenizer(\n",
    "    list(eval_dataset['premise']),\n",
    "    list(eval_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=300,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(tokenized_train['input_ids'][0])\n",
    "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "\n",
    "    return num_label\n",
    "\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "eval_label = label_to_num(eval_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180576\n",
      "{'input_ids': tensor([    2, 25638, 11298, 12851, 11299, 30813,     3, 27905, 12816, 12679,\n",
      "        11327,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n",
      "[CLS] 길거리에서 청소하는 남자들 [SEP] 남자들이 길을 정리한다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BERTDataset(tokenized_train, train_label)\n",
    "eval_dataset = BERTDataset(tokenized_eval, eval_label)\n",
    "\n",
    "print(train_dataset.__len__())\n",
    "print(train_dataset.__getitem__(19997))\n",
    "print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  \"\"\" validation을 위한 metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
    "\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_ars = TrainingArguments(\n",
    "    output_dir='result/pure_test_electra/',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_total_limit=5,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 500,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_ars,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 180576\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19754\n",
      "  Number of trainable parameters = 110619651\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msangmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230105_131713-1dioqd3y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/1dioqd3y\" target=\"_blank\">result/pure_test_electra/</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19754' max='19754' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19754/19754 2:33:28, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.655300</td>\n",
       "      <td>0.495499</td>\n",
       "      <td>0.810252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.450783</td>\n",
       "      <td>0.825553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.404127</td>\n",
       "      <td>0.847186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.443500</td>\n",
       "      <td>0.419895</td>\n",
       "      <td>0.847437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.390962</td>\n",
       "      <td>0.857094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>0.439535</td>\n",
       "      <td>0.858160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.277700</td>\n",
       "      <td>0.403291</td>\n",
       "      <td>0.861953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>0.376189</td>\n",
       "      <td>0.866531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.362412</td>\n",
       "      <td>0.868443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>0.387676</td>\n",
       "      <td>0.869447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.365366</td>\n",
       "      <td>0.873428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.404789</td>\n",
       "      <td>0.871923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.393620</td>\n",
       "      <td>0.874777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.466030</td>\n",
       "      <td>0.872833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.439497</td>\n",
       "      <td>0.871829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.428299</td>\n",
       "      <td>0.877097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.439982</td>\n",
       "      <td>0.877003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.457287</td>\n",
       "      <td>0.872613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.875216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.478270</td>\n",
       "      <td>0.875310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.485593</td>\n",
       "      <td>0.878288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.433175</td>\n",
       "      <td>0.878664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.875749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.498490</td>\n",
       "      <td>0.876564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.536482</td>\n",
       "      <td>0.875529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.567345</td>\n",
       "      <td>0.874526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.543482</td>\n",
       "      <td>0.876187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.546073</td>\n",
       "      <td>0.878351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.609797</td>\n",
       "      <td>0.877003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.594871</td>\n",
       "      <td>0.875874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.566273</td>\n",
       "      <td>0.877442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.878006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.610772</td>\n",
       "      <td>0.876062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.695938</td>\n",
       "      <td>0.877410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.664525</td>\n",
       "      <td>0.879260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.755335</td>\n",
       "      <td>0.877034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.723671</td>\n",
       "      <td>0.877912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.717255</td>\n",
       "      <td>0.878633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.745466</td>\n",
       "      <td>0.878884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-1000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-1000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-1000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-1500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-1500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-1500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-2000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-2000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-2000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-2500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-2500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-2500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-3000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-3000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-3500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-3500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-1000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-4000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-4000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-1500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-4500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-4500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-2000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-5000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-5000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-2500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-5500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-5500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-3000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-6000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-6000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-3500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-6500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-6500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-4000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-7000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-7000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-5000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-7500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-7500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-5500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-8000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-8000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-8500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-8500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-6500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-9000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-9000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-7000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-9500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-9500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-7500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-10000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-10000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-10000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in result/pure_test_electra/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-8000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-10500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-10500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-8500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-11000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-11000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-9000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-11500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-11500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-9500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-12000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-12000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-10000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-12500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-12500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-10500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-13000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-13000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-11000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-13500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-13500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-11500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-14000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-14000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-12000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-14500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-14500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-12500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-15000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-15000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-13000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-15500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-15500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-13500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-16000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-16000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-14000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-16500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-16500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-14500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-17000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-17000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-15000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-17500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-17500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-15500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-18000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-18000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-16000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-18500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-18500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-16500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-19000\n",
      "Configuration saved in result/pure_test_electra/checkpoint-19000/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-17000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/pure_test_electra/checkpoint-19500\n",
      "Configuration saved in result/pure_test_electra/checkpoint-19500/config.json\n",
      "Model weights saved in result/pure_test_electra/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in result/pure_test_electra/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in result/pure_test_electra/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/pure_test_electra/checkpoint-17500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/pure_test_electra/checkpoint-4500 (score: 0.36241215467453003).\n",
      "Configuration saved in result/pure_test_electra/best_model/config.json\n",
      "Model weights saved in result/pure_test_electra/best_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('result/pure_test_electra/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file result/pure_test_electra/best_model/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"result/pure_test_electra/best_model\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file result/pure_test_electra/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at result/pure_test_electra/best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='tunib/electra-ko-base', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Tokenizer_NAME = \"tunib/electra-ko-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
    "\n",
    "MODEL_NAME = 'result/pure_test_electra/best_model'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(tokenizer.vocab_size)\n",
    "model.to(device)\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n",
      "{'input_ids': tensor([    2,   791, 14921, 23745,  6237,   485, 15213,  2137,   204,  8377,\n",
      "        11304,     3,   791, 14921,  1485,  6020, 11461,  6015, 14521, 13377,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'label': tensor(3)}\n",
      "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다 [SEP] 18일 배를 타고 여행을 떠났습니다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "test_label = label_to_num(test['label'].values)\n",
    "\n",
    "tokenized_test = tokenizer(\n",
    "    list(test['premise']),\n",
    "    list(test['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "test_dataset = BERTDataset(tokenized_test, test_label)\n",
    "\n",
    "print(test_dataset.__len__())\n",
    "print(test_dataset.__getitem__(1665))\n",
    "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 44.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 1, 2, 0, 1, 0, 1, 1, 1, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 0, 0, 1, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 1, 1, 2, 1, 0, 2, 0, 0, 1, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 1, 2, 1, 2, 0, 1, 0, 2, 1, 2, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 0, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 1, 0, 2, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 2, 1, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 1, 1, 1, 0, 2, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 2, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 2, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 2, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 1, 1, 1, 1, 0, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 0, 0, 1, 2, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2, 2, 0, 2, 1, 0, 2, 2, 1, 1, 2, 1, 0, 0, 1, 1, 0, 2, 2, 0, 1, 2, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 1, 0, 1, 2, 2, 2, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 2, 0, 2, 2, 2, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 0, 0, 1, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 1, 0, 2, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0, 1, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 2, 0, 1, 0, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 0, 1, 1, 0, 0, 1, 2, 1, 2, 2, 1, 0, 1, 0, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 0, 0, 1, 1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 0, 2, 2, 0, 0, 2, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_pred = []\n",
    "output_prob = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=data['input_ids'].to(device),\n",
    "            attention_mask=data['attention_mask'].to(device),\n",
    "            token_type_ids=data['token_type_ids'].to(device)\n",
    "        )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'contradiction'], [1, 'neutral'], [2, 'entailment'], [3, 'contradiction'], [4, 'contradiction'], [5, 'neutral'], [6, 'contradiction'], [7, 'entailment'], [8, 'entailment'], [9, 'contradiction'], [10, 'contradiction'], [11, 'entailment'], [12, 'contradiction'], [13, 'entailment'], [14, 'neutral'], [15, 'neutral'], [16, 'entailment'], [17, 'neutral'], [18, 'contradiction'], [19, 'neutral'], [20, 'neutral'], [21, 'neutral'], [22, 'contradiction'], [23, 'entailment'], [24, 'contradiction'], [25, 'contradiction'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'entailment'], [30, 'contradiction'], [31, 'entailment'], [32, 'contradiction'], [33, 'neutral'], [34, 'neutral'], [35, 'contradiction'], [36, 'entailment'], [37, 'contradiction'], [38, 'entailment'], [39, 'contradiction'], [40, 'neutral'], [41, 'entailment'], [42, 'neutral'], [43, 'neutral'], [44, 'neutral'], [45, 'contradiction'], [46, 'neutral'], [47, 'entailment'], [48, 'contradiction'], [49, 'entailment'], [50, 'contradiction'], [51, 'contradiction'], [52, 'contradiction'], [53, 'neutral'], [54, 'entailment'], [55, 'neutral'], [56, 'neutral'], [57, 'neutral'], [58, 'contradiction'], [59, 'entailment'], [60, 'entailment'], [61, 'neutral'], [62, 'neutral'], [63, 'neutral'], [64, 'neutral'], [65, 'contradiction'], [66, 'neutral'], [67, 'neutral'], [68, 'neutral'], [69, 'contradiction'], [70, 'entailment'], [71, 'neutral'], [72, 'entailment'], [73, 'entailment'], [74, 'neutral'], [75, 'neutral'], [76, 'entailment'], [77, 'neutral'], [78, 'neutral'], [79, 'contradiction'], [80, 'neutral'], [81, 'neutral'], [82, 'contradiction'], [83, 'contradiction'], [84, 'entailment'], [85, 'contradiction'], [86, 'neutral'], [87, 'contradiction'], [88, 'entailment'], [89, 'neutral'], [90, 'contradiction'], [91, 'neutral'], [92, 'entailment'], [93, 'contradiction'], [94, 'entailment'], [95, 'entailment'], [96, 'contradiction'], [97, 'contradiction'], [98, 'entailment'], [99, 'neutral'], [100, 'neutral'], [101, 'entailment'], [102, 'neutral'], [103, 'entailment'], [104, 'neutral'], [105, 'entailment'], [106, 'neutral'], [107, 'neutral'], [108, 'contradiction'], [109, 'contradiction'], [110, 'contradiction'], [111, 'neutral'], [112, 'contradiction'], [113, 'entailment'], [114, 'neutral'], [115, 'entailment'], [116, 'entailment'], [117, 'contradiction'], [118, 'contradiction'], [119, 'neutral'], [120, 'contradiction'], [121, 'contradiction'], [122, 'contradiction'], [123, 'neutral'], [124, 'entailment'], [125, 'contradiction'], [126, 'entailment'], [127, 'contradiction'], [128, 'contradiction'], [129, 'neutral'], [130, 'entailment'], [131, 'neutral'], [132, 'contradiction'], [133, 'entailment'], [134, 'neutral'], [135, 'entailment'], [136, 'contradiction'], [137, 'neutral'], [138, 'contradiction'], [139, 'contradiction'], [140, 'neutral'], [141, 'neutral'], [142, 'neutral'], [143, 'entailment'], [144, 'neutral'], [145, 'entailment'], [146, 'entailment'], [147, 'contradiction'], [148, 'neutral'], [149, 'neutral'], [150, 'contradiction'], [151, 'entailment'], [152, 'contradiction'], [153, 'neutral'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'contradiction'], [158, 'neutral'], [159, 'contradiction'], [160, 'neutral'], [161, 'entailment'], [162, 'contradiction'], [163, 'entailment'], [164, 'neutral'], [165, 'contradiction'], [166, 'neutral'], [167, 'entailment'], [168, 'neutral'], [169, 'entailment'], [170, 'neutral'], [171, 'neutral'], [172, 'contradiction'], [173, 'entailment'], [174, 'neutral'], [175, 'contradiction'], [176, 'neutral'], [177, 'neutral'], [178, 'contradiction'], [179, 'contradiction'], [180, 'contradiction'], [181, 'neutral'], [182, 'neutral'], [183, 'contradiction'], [184, 'neutral'], [185, 'neutral'], [186, 'contradiction'], [187, 'neutral'], [188, 'entailment'], [189, 'contradiction'], [190, 'neutral'], [191, 'entailment'], [192, 'contradiction'], [193, 'entailment'], [194, 'neutral'], [195, 'entailment'], [196, 'entailment'], [197, 'neutral'], [198, 'entailment'], [199, 'neutral'], [200, 'neutral'], [201, 'neutral'], [202, 'entailment'], [203, 'contradiction'], [204, 'contradiction'], [205, 'entailment'], [206, 'entailment'], [207, 'neutral'], [208, 'entailment'], [209, 'neutral'], [210, 'contradiction'], [211, 'contradiction'], [212, 'contradiction'], [213, 'neutral'], [214, 'contradiction'], [215, 'contradiction'], [216, 'contradiction'], [217, 'entailment'], [218, 'contradiction'], [219, 'contradiction'], [220, 'neutral'], [221, 'neutral'], [222, 'entailment'], [223, 'contradiction'], [224, 'neutral'], [225, 'contradiction'], [226, 'contradiction'], [227, 'neutral'], [228, 'contradiction'], [229, 'contradiction'], [230, 'entailment'], [231, 'neutral'], [232, 'contradiction'], [233, 'entailment'], [234, 'entailment'], [235, 'neutral'], [236, 'neutral'], [237, 'contradiction'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'contradiction'], [242, 'neutral'], [243, 'neutral'], [244, 'neutral'], [245, 'entailment'], [246, 'neutral'], [247, 'neutral'], [248, 'contradiction'], [249, 'contradiction'], [250, 'entailment'], [251, 'contradiction'], [252, 'neutral'], [253, 'entailment'], [254, 'contradiction'], [255, 'neutral'], [256, 'contradiction'], [257, 'contradiction'], [258, 'entailment'], [259, 'entailment'], [260, 'entailment'], [261, 'entailment'], [262, 'neutral'], [263, 'neutral'], [264, 'neutral'], [265, 'neutral'], [266, 'contradiction'], [267, 'entailment'], [268, 'neutral'], [269, 'entailment'], [270, 'contradiction'], [271, 'neutral'], [272, 'entailment'], [273, 'entailment'], [274, 'entailment'], [275, 'contradiction'], [276, 'contradiction'], [277, 'contradiction'], [278, 'neutral'], [279, 'neutral'], [280, 'neutral'], [281, 'entailment'], [282, 'entailment'], [283, 'entailment'], [284, 'contradiction'], [285, 'entailment'], [286, 'contradiction'], [287, 'contradiction'], [288, 'entailment'], [289, 'neutral'], [290, 'entailment'], [291, 'contradiction'], [292, 'entailment'], [293, 'contradiction'], [294, 'entailment'], [295, 'contradiction'], [296, 'contradiction'], [297, 'contradiction'], [298, 'neutral'], [299, 'entailment'], [300, 'neutral'], [301, 'entailment'], [302, 'neutral'], [303, 'entailment'], [304, 'contradiction'], [305, 'entailment'], [306, 'neutral'], [307, 'contradiction'], [308, 'entailment'], [309, 'entailment'], [310, 'neutral'], [311, 'contradiction'], [312, 'contradiction'], [313, 'neutral'], [314, 'neutral'], [315, 'neutral'], [316, 'neutral'], [317, 'neutral'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'neutral'], [322, 'neutral'], [323, 'neutral'], [324, 'contradiction'], [325, 'entailment'], [326, 'contradiction'], [327, 'contradiction'], [328, 'contradiction'], [329, 'contradiction'], [330, 'neutral'], [331, 'entailment'], [332, 'neutral'], [333, 'contradiction'], [334, 'contradiction'], [335, 'contradiction'], [336, 'entailment'], [337, 'contradiction'], [338, 'contradiction'], [339, 'neutral'], [340, 'contradiction'], [341, 'neutral'], [342, 'contradiction'], [343, 'contradiction'], [344, 'neutral'], [345, 'entailment'], [346, 'contradiction'], [347, 'contradiction'], [348, 'contradiction'], [349, 'neutral'], [350, 'contradiction'], [351, 'entailment'], [352, 'contradiction'], [353, 'neutral'], [354, 'neutral'], [355, 'entailment'], [356, 'neutral'], [357, 'entailment'], [358, 'contradiction'], [359, 'neutral'], [360, 'contradiction'], [361, 'contradiction'], [362, 'neutral'], [363, 'neutral'], [364, 'contradiction'], [365, 'neutral'], [366, 'neutral'], [367, 'entailment'], [368, 'contradiction'], [369, 'neutral'], [370, 'contradiction'], [371, 'contradiction'], [372, 'entailment'], [373, 'neutral'], [374, 'neutral'], [375, 'entailment'], [376, 'entailment'], [377, 'neutral'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'neutral'], [382, 'contradiction'], [383, 'neutral'], [384, 'entailment'], [385, 'neutral'], [386, 'entailment'], [387, 'entailment'], [388, 'neutral'], [389, 'contradiction'], [390, 'neutral'], [391, 'entailment'], [392, 'contradiction'], [393, 'neutral'], [394, 'contradiction'], [395, 'neutral'], [396, 'neutral'], [397, 'entailment'], [398, 'contradiction'], [399, 'entailment'], [400, 'contradiction'], [401, 'entailment'], [402, 'contradiction'], [403, 'contradiction'], [404, 'entailment'], [405, 'neutral'], [406, 'neutral'], [407, 'neutral'], [408, 'contradiction'], [409, 'neutral'], [410, 'contradiction'], [411, 'contradiction'], [412, 'contradiction'], [413, 'contradiction'], [414, 'neutral'], [415, 'contradiction'], [416, 'contradiction'], [417, 'entailment'], [418, 'neutral'], [419, 'contradiction'], [420, 'neutral'], [421, 'neutral'], [422, 'entailment'], [423, 'neutral'], [424, 'entailment'], [425, 'neutral'], [426, 'neutral'], [427, 'contradiction'], [428, 'contradiction'], [429, 'contradiction'], [430, 'entailment'], [431, 'neutral'], [432, 'contradiction'], [433, 'contradiction'], [434, 'entailment'], [435, 'neutral'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'entailment'], [442, 'entailment'], [443, 'neutral'], [444, 'contradiction'], [445, 'neutral'], [446, 'neutral'], [447, 'entailment'], [448, 'contradiction'], [449, 'neutral'], [450, 'contradiction'], [451, 'entailment'], [452, 'entailment'], [453, 'contradiction'], [454, 'contradiction'], [455, 'entailment'], [456, 'neutral'], [457, 'contradiction'], [458, 'neutral'], [459, 'contradiction'], [460, 'entailment'], [461, 'entailment'], [462, 'contradiction'], [463, 'neutral'], [464, 'contradiction'], [465, 'contradiction'], [466, 'contradiction'], [467, 'neutral'], [468, 'entailment'], [469, 'contradiction'], [470, 'contradiction'], [471, 'neutral'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'neutral'], [476, 'entailment'], [477, 'contradiction'], [478, 'contradiction'], [479, 'contradiction'], [480, 'entailment'], [481, 'entailment'], [482, 'entailment'], [483, 'entailment'], [484, 'entailment'], [485, 'entailment'], [486, 'entailment'], [487, 'neutral'], [488, 'entailment'], [489, 'entailment'], [490, 'entailment'], [491, 'neutral'], [492, 'neutral'], [493, 'neutral'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'neutral'], [498, 'neutral'], [499, 'entailment'], [500, 'entailment'], [501, 'entailment'], [502, 'neutral'], [503, 'contradiction'], [504, 'contradiction'], [505, 'entailment'], [506, 'entailment'], [507, 'contradiction'], [508, 'entailment'], [509, 'entailment'], [510, 'contradiction'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'contradiction'], [515, 'contradiction'], [516, 'neutral'], [517, 'entailment'], [518, 'contradiction'], [519, 'contradiction'], [520, 'neutral'], [521, 'contradiction'], [522, 'contradiction'], [523, 'neutral'], [524, 'neutral'], [525, 'contradiction'], [526, 'entailment'], [527, 'entailment'], [528, 'contradiction'], [529, 'entailment'], [530, 'contradiction'], [531, 'neutral'], [532, 'contradiction'], [533, 'neutral'], [534, 'neutral'], [535, 'contradiction'], [536, 'contradiction'], [537, 'contradiction'], [538, 'contradiction'], [539, 'neutral'], [540, 'neutral'], [541, 'contradiction'], [542, 'contradiction'], [543, 'entailment'], [544, 'contradiction'], [545, 'neutral'], [546, 'contradiction'], [547, 'entailment'], [548, 'neutral'], [549, 'entailment'], [550, 'neutral'], [551, 'contradiction'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'neutral'], [556, 'entailment'], [557, 'contradiction'], [558, 'neutral'], [559, 'contradiction'], [560, 'entailment'], [561, 'contradiction'], [562, 'neutral'], [563, 'neutral'], [564, 'entailment'], [565, 'neutral'], [566, 'entailment'], [567, 'entailment'], [568, 'neutral'], [569, 'contradiction'], [570, 'entailment'], [571, 'entailment'], [572, 'contradiction'], [573, 'contradiction'], [574, 'entailment'], [575, 'contradiction'], [576, 'entailment'], [577, 'neutral'], [578, 'contradiction'], [579, 'neutral'], [580, 'contradiction'], [581, 'entailment'], [582, 'entailment'], [583, 'neutral'], [584, 'entailment'], [585, 'entailment'], [586, 'neutral'], [587, 'entailment'], [588, 'neutral'], [589, 'entailment'], [590, 'entailment'], [591, 'neutral'], [592, 'contradiction'], [593, 'entailment'], [594, 'contradiction'], [595, 'contradiction'], [596, 'contradiction'], [597, 'neutral'], [598, 'entailment'], [599, 'entailment'], [600, 'contradiction'], [601, 'neutral'], [602, 'contradiction'], [603, 'entailment'], [604, 'neutral'], [605, 'neutral'], [606, 'contradiction'], [607, 'contradiction'], [608, 'contradiction'], [609, 'contradiction'], [610, 'contradiction'], [611, 'contradiction'], [612, 'contradiction'], [613, 'entailment'], [614, 'contradiction'], [615, 'contradiction'], [616, 'neutral'], [617, 'neutral'], [618, 'contradiction'], [619, 'neutral'], [620, 'contradiction'], [621, 'neutral'], [622, 'entailment'], [623, 'contradiction'], [624, 'entailment'], [625, 'contradiction'], [626, 'contradiction'], [627, 'contradiction'], [628, 'neutral'], [629, 'entailment'], [630, 'entailment'], [631, 'entailment'], [632, 'neutral'], [633, 'entailment'], [634, 'neutral'], [635, 'contradiction'], [636, 'contradiction'], [637, 'entailment'], [638, 'entailment'], [639, 'contradiction'], [640, 'neutral'], [641, 'entailment'], [642, 'neutral'], [643, 'entailment'], [644, 'neutral'], [645, 'entailment'], [646, 'neutral'], [647, 'contradiction'], [648, 'contradiction'], [649, 'neutral'], [650, 'entailment'], [651, 'neutral'], [652, 'contradiction'], [653, 'neutral'], [654, 'neutral'], [655, 'neutral'], [656, 'entailment'], [657, 'contradiction'], [658, 'entailment'], [659, 'contradiction'], [660, 'neutral'], [661, 'contradiction'], [662, 'neutral'], [663, 'neutral'], [664, 'neutral'], [665, 'entailment'], [666, 'contradiction'], [667, 'neutral'], [668, 'neutral'], [669, 'neutral'], [670, 'neutral'], [671, 'contradiction'], [672, 'neutral'], [673, 'contradiction'], [674, 'neutral'], [675, 'entailment'], [676, 'contradiction'], [677, 'neutral'], [678, 'contradiction'], [679, 'contradiction'], [680, 'neutral'], [681, 'contradiction'], [682, 'entailment'], [683, 'contradiction'], [684, 'contradiction'], [685, 'contradiction'], [686, 'entailment'], [687, 'contradiction'], [688, 'contradiction'], [689, 'entailment'], [690, 'neutral'], [691, 'entailment'], [692, 'entailment'], [693, 'neutral'], [694, 'entailment'], [695, 'entailment'], [696, 'entailment'], [697, 'contradiction'], [698, 'entailment'], [699, 'entailment'], [700, 'neutral'], [701, 'entailment'], [702, 'entailment'], [703, 'neutral'], [704, 'contradiction'], [705, 'entailment'], [706, 'contradiction'], [707, 'contradiction'], [708, 'neutral'], [709, 'contradiction'], [710, 'neutral'], [711, 'entailment'], [712, 'neutral'], [713, 'entailment'], [714, 'contradiction'], [715, 'entailment'], [716, 'neutral'], [717, 'neutral'], [718, 'entailment'], [719, 'entailment'], [720, 'entailment'], [721, 'neutral'], [722, 'neutral'], [723, 'contradiction'], [724, 'entailment'], [725, 'contradiction'], [726, 'contradiction'], [727, 'contradiction'], [728, 'contradiction'], [729, 'entailment'], [730, 'entailment'], [731, 'neutral'], [732, 'entailment'], [733, 'neutral'], [734, 'entailment'], [735, 'neutral'], [736, 'contradiction'], [737, 'contradiction'], [738, 'neutral'], [739, 'entailment'], [740, 'neutral'], [741, 'contradiction'], [742, 'entailment'], [743, 'entailment'], [744, 'contradiction'], [745, 'neutral'], [746, 'neutral'], [747, 'contradiction'], [748, 'neutral'], [749, 'contradiction'], [750, 'neutral'], [751, 'contradiction'], [752, 'neutral'], [753, 'neutral'], [754, 'entailment'], [755, 'neutral'], [756, 'entailment'], [757, 'contradiction'], [758, 'neutral'], [759, 'neutral'], [760, 'entailment'], [761, 'neutral'], [762, 'entailment'], [763, 'contradiction'], [764, 'neutral'], [765, 'entailment'], [766, 'neutral'], [767, 'entailment'], [768, 'contradiction'], [769, 'entailment'], [770, 'contradiction'], [771, 'neutral'], [772, 'entailment'], [773, 'contradiction'], [774, 'entailment'], [775, 'neutral'], [776, 'contradiction'], [777, 'entailment'], [778, 'neutral'], [779, 'neutral'], [780, 'entailment'], [781, 'neutral'], [782, 'contradiction'], [783, 'neutral'], [784, 'entailment'], [785, 'entailment'], [786, 'contradiction'], [787, 'neutral'], [788, 'entailment'], [789, 'contradiction'], [790, 'entailment'], [791, 'contradiction'], [792, 'entailment'], [793, 'neutral'], [794, 'neutral'], [795, 'entailment'], [796, 'contradiction'], [797, 'entailment'], [798, 'entailment'], [799, 'neutral'], [800, 'entailment'], [801, 'contradiction'], [802, 'entailment'], [803, 'neutral'], [804, 'contradiction'], [805, 'contradiction'], [806, 'entailment'], [807, 'contradiction'], [808, 'contradiction'], [809, 'contradiction'], [810, 'entailment'], [811, 'contradiction'], [812, 'contradiction'], [813, 'contradiction'], [814, 'neutral'], [815, 'neutral'], [816, 'entailment'], [817, 'neutral'], [818, 'neutral'], [819, 'entailment'], [820, 'neutral'], [821, 'contradiction'], [822, 'entailment'], [823, 'neutral'], [824, 'neutral'], [825, 'contradiction'], [826, 'contradiction'], [827, 'neutral'], [828, 'contradiction'], [829, 'entailment'], [830, 'entailment'], [831, 'contradiction'], [832, 'contradiction'], [833, 'entailment'], [834, 'neutral'], [835, 'neutral'], [836, 'entailment'], [837, 'contradiction'], [838, 'neutral'], [839, 'contradiction'], [840, 'contradiction'], [841, 'entailment'], [842, 'contradiction'], [843, 'entailment'], [844, 'neutral'], [845, 'neutral'], [846, 'contradiction'], [847, 'contradiction'], [848, 'entailment'], [849, 'neutral'], [850, 'neutral'], [851, 'contradiction'], [852, 'entailment'], [853, 'neutral'], [854, 'contradiction'], [855, 'entailment'], [856, 'entailment'], [857, 'neutral'], [858, 'contradiction'], [859, 'contradiction'], [860, 'contradiction'], [861, 'entailment'], [862, 'contradiction'], [863, 'neutral'], [864, 'entailment'], [865, 'entailment'], [866, 'entailment'], [867, 'neutral'], [868, 'contradiction'], [869, 'neutral'], [870, 'neutral'], [871, 'contradiction'], [872, 'entailment'], [873, 'entailment'], [874, 'neutral'], [875, 'contradiction'], [876, 'entailment'], [877, 'contradiction'], [878, 'neutral'], [879, 'neutral'], [880, 'neutral'], [881, 'neutral'], [882, 'contradiction'], [883, 'entailment'], [884, 'entailment'], [885, 'neutral'], [886, 'neutral'], [887, 'neutral'], [888, 'entailment'], [889, 'neutral'], [890, 'entailment'], [891, 'contradiction'], [892, 'entailment'], [893, 'entailment'], [894, 'contradiction'], [895, 'neutral'], [896, 'entailment'], [897, 'neutral'], [898, 'entailment'], [899, 'entailment'], [900, 'neutral'], [901, 'contradiction'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'neutral'], [906, 'contradiction'], [907, 'contradiction'], [908, 'contradiction'], [909, 'neutral'], [910, 'neutral'], [911, 'contradiction'], [912, 'neutral'], [913, 'entailment'], [914, 'neutral'], [915, 'neutral'], [916, 'contradiction'], [917, 'contradiction'], [918, 'neutral'], [919, 'entailment'], [920, 'neutral'], [921, 'entailment'], [922, 'entailment'], [923, 'contradiction'], [924, 'contradiction'], [925, 'contradiction'], [926, 'entailment'], [927, 'entailment'], [928, 'neutral'], [929, 'contradiction'], [930, 'neutral'], [931, 'entailment'], [932, 'neutral'], [933, 'neutral'], [934, 'contradiction'], [935, 'contradiction'], [936, 'entailment'], [937, 'contradiction'], [938, 'entailment'], [939, 'neutral'], [940, 'entailment'], [941, 'entailment'], [942, 'contradiction'], [943, 'contradiction'], [944, 'neutral'], [945, 'entailment'], [946, 'neutral'], [947, 'neutral'], [948, 'neutral'], [949, 'entailment'], [950, 'contradiction'], [951, 'contradiction'], [952, 'contradiction'], [953, 'contradiction'], [954, 'contradiction'], [955, 'entailment'], [956, 'neutral'], [957, 'entailment'], [958, 'contradiction'], [959, 'contradiction'], [960, 'neutral'], [961, 'contradiction'], [962, 'contradiction'], [963, 'contradiction'], [964, 'entailment'], [965, 'entailment'], [966, 'contradiction'], [967, 'entailment'], [968, 'entailment'], [969, 'contradiction'], [970, 'entailment'], [971, 'entailment'], [972, 'neutral'], [973, 'contradiction'], [974, 'contradiction'], [975, 'entailment'], [976, 'entailment'], [977, 'neutral'], [978, 'neutral'], [979, 'entailment'], [980, 'entailment'], [981, 'neutral'], [982, 'entailment'], [983, 'contradiction'], [984, 'neutral'], [985, 'neutral'], [986, 'contradiction'], [987, 'contradiction'], [988, 'neutral'], [989, 'contradiction'], [990, 'entailment'], [991, 'entailment'], [992, 'neutral'], [993, 'contradiction'], [994, 'neutral'], [995, 'entailment'], [996, 'neutral'], [997, 'entailment'], [998, 'entailment'], [999, 'entailment'], [1000, 'neutral'], [1001, 'entailment'], [1002, 'contradiction'], [1003, 'entailment'], [1004, 'neutral'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'neutral'], [1009, 'neutral'], [1010, 'neutral'], [1011, 'entailment'], [1012, 'neutral'], [1013, 'contradiction'], [1014, 'neutral'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'contradiction'], [1019, 'contradiction'], [1020, 'entailment'], [1021, 'neutral'], [1022, 'neutral'], [1023, 'contradiction'], [1024, 'entailment'], [1025, 'entailment'], [1026, 'neutral'], [1027, 'contradiction'], [1028, 'contradiction'], [1029, 'contradiction'], [1030, 'entailment'], [1031, 'neutral'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'neutral'], [1035, 'contradiction'], [1036, 'neutral'], [1037, 'contradiction'], [1038, 'contradiction'], [1039, 'contradiction'], [1040, 'entailment'], [1041, 'neutral'], [1042, 'contradiction'], [1043, 'entailment'], [1044, 'contradiction'], [1045, 'neutral'], [1046, 'contradiction'], [1047, 'entailment'], [1048, 'entailment'], [1049, 'contradiction'], [1050, 'entailment'], [1051, 'contradiction'], [1052, 'entailment'], [1053, 'contradiction'], [1054, 'neutral'], [1055, 'entailment'], [1056, 'contradiction'], [1057, 'contradiction'], [1058, 'entailment'], [1059, 'neutral'], [1060, 'contradiction'], [1061, 'contradiction'], [1062, 'contradiction'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'neutral'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'neutral'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'neutral'], [1073, 'neutral'], [1074, 'entailment'], [1075, 'contradiction'], [1076, 'entailment'], [1077, 'neutral'], [1078, 'contradiction'], [1079, 'entailment'], [1080, 'neutral'], [1081, 'contradiction'], [1082, 'contradiction'], [1083, 'contradiction'], [1084, 'contradiction'], [1085, 'contradiction'], [1086, 'neutral'], [1087, 'entailment'], [1088, 'contradiction'], [1089, 'neutral'], [1090, 'entailment'], [1091, 'neutral'], [1092, 'contradiction'], [1093, 'contradiction'], [1094, 'neutral'], [1095, 'contradiction'], [1096, 'entailment'], [1097, 'neutral'], [1098, 'neutral'], [1099, 'contradiction'], [1100, 'entailment'], [1101, 'contradiction'], [1102, 'contradiction'], [1103, 'entailment'], [1104, 'contradiction'], [1105, 'entailment'], [1106, 'contradiction'], [1107, 'contradiction'], [1108, 'entailment'], [1109, 'entailment'], [1110, 'entailment'], [1111, 'contradiction'], [1112, 'contradiction'], [1113, 'contradiction'], [1114, 'neutral'], [1115, 'neutral'], [1116, 'neutral'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'contradiction'], [1120, 'contradiction'], [1121, 'neutral'], [1122, 'neutral'], [1123, 'contradiction'], [1124, 'neutral'], [1125, 'contradiction'], [1126, 'entailment'], [1127, 'contradiction'], [1128, 'entailment'], [1129, 'neutral'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'neutral'], [1133, 'contradiction'], [1134, 'contradiction'], [1135, 'contradiction'], [1136, 'contradiction'], [1137, 'contradiction'], [1138, 'contradiction'], [1139, 'entailment'], [1140, 'contradiction'], [1141, 'neutral'], [1142, 'contradiction'], [1143, 'contradiction'], [1144, 'entailment'], [1145, 'neutral'], [1146, 'entailment'], [1147, 'contradiction'], [1148, 'entailment'], [1149, 'contradiction'], [1150, 'entailment'], [1151, 'contradiction'], [1152, 'neutral'], [1153, 'entailment'], [1154, 'entailment'], [1155, 'neutral'], [1156, 'neutral'], [1157, 'entailment'], [1158, 'neutral'], [1159, 'neutral'], [1160, 'entailment'], [1161, 'contradiction'], [1162, 'contradiction'], [1163, 'contradiction'], [1164, 'neutral'], [1165, 'entailment'], [1166, 'neutral'], [1167, 'entailment'], [1168, 'neutral'], [1169, 'neutral'], [1170, 'contradiction'], [1171, 'neutral'], [1172, 'contradiction'], [1173, 'neutral'], [1174, 'neutral'], [1175, 'contradiction'], [1176, 'neutral'], [1177, 'entailment'], [1178, 'contradiction'], [1179, 'contradiction'], [1180, 'entailment'], [1181, 'entailment'], [1182, 'contradiction'], [1183, 'neutral'], [1184, 'contradiction'], [1185, 'neutral'], [1186, 'neutral'], [1187, 'contradiction'], [1188, 'entailment'], [1189, 'contradiction'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'contradiction'], [1193, 'neutral'], [1194, 'entailment'], [1195, 'entailment'], [1196, 'contradiction'], [1197, 'neutral'], [1198, 'contradiction'], [1199, 'neutral'], [1200, 'entailment'], [1201, 'neutral'], [1202, 'entailment'], [1203, 'neutral'], [1204, 'contradiction'], [1205, 'neutral'], [1206, 'contradiction'], [1207, 'contradiction'], [1208, 'entailment'], [1209, 'contradiction'], [1210, 'neutral'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'contradiction'], [1214, 'neutral'], [1215, 'contradiction'], [1216, 'neutral'], [1217, 'entailment'], [1218, 'neutral'], [1219, 'neutral'], [1220, 'neutral'], [1221, 'contradiction'], [1222, 'contradiction'], [1223, 'neutral'], [1224, 'entailment'], [1225, 'contradiction'], [1226, 'contradiction'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'neutral'], [1230, 'contradiction'], [1231, 'contradiction'], [1232, 'entailment'], [1233, 'contradiction'], [1234, 'contradiction'], [1235, 'neutral'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'neutral'], [1240, 'contradiction'], [1241, 'neutral'], [1242, 'neutral'], [1243, 'neutral'], [1244, 'entailment'], [1245, 'entailment'], [1246, 'contradiction'], [1247, 'contradiction'], [1248, 'neutral'], [1249, 'entailment'], [1250, 'neutral'], [1251, 'entailment'], [1252, 'contradiction'], [1253, 'contradiction'], [1254, 'neutral'], [1255, 'contradiction'], [1256, 'entailment'], [1257, 'entailment'], [1258, 'contradiction'], [1259, 'entailment'], [1260, 'neutral'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'neutral'], [1264, 'neutral'], [1265, 'neutral'], [1266, 'entailment'], [1267, 'contradiction'], [1268, 'contradiction'], [1269, 'contradiction'], [1270, 'contradiction'], [1271, 'entailment'], [1272, 'contradiction'], [1273, 'entailment'], [1274, 'contradiction'], [1275, 'neutral'], [1276, 'entailment'], [1277, 'entailment'], [1278, 'contradiction'], [1279, 'entailment'], [1280, 'contradiction'], [1281, 'entailment'], [1282, 'contradiction'], [1283, 'entailment'], [1284, 'neutral'], [1285, 'entailment'], [1286, 'contradiction'], [1287, 'neutral'], [1288, 'entailment'], [1289, 'neutral'], [1290, 'neutral'], [1291, 'neutral'], [1292, 'neutral'], [1293, 'neutral'], [1294, 'entailment'], [1295, 'contradiction'], [1296, 'contradiction'], [1297, 'neutral'], [1298, 'contradiction'], [1299, 'neutral'], [1300, 'contradiction'], [1301, 'entailment'], [1302, 'entailment'], [1303, 'neutral'], [1304, 'neutral'], [1305, 'neutral'], [1306, 'contradiction'], [1307, 'neutral'], [1308, 'entailment'], [1309, 'contradiction'], [1310, 'contradiction'], [1311, 'contradiction'], [1312, 'contradiction'], [1313, 'contradiction'], [1314, 'entailment'], [1315, 'neutral'], [1316, 'entailment'], [1317, 'entailment'], [1318, 'neutral'], [1319, 'entailment'], [1320, 'entailment'], [1321, 'entailment'], [1322, 'neutral'], [1323, 'contradiction'], [1324, 'entailment'], [1325, 'neutral'], [1326, 'contradiction'], [1327, 'neutral'], [1328, 'neutral'], [1329, 'contradiction'], [1330, 'neutral'], [1331, 'neutral'], [1332, 'contradiction'], [1333, 'neutral'], [1334, 'contradiction'], [1335, 'neutral'], [1336, 'contradiction'], [1337, 'neutral'], [1338, 'entailment'], [1339, 'neutral'], [1340, 'entailment'], [1341, 'contradiction'], [1342, 'entailment'], [1343, 'neutral'], [1344, 'entailment'], [1345, 'contradiction'], [1346, 'contradiction'], [1347, 'entailment'], [1348, 'contradiction'], [1349, 'neutral'], [1350, 'neutral'], [1351, 'contradiction'], [1352, 'neutral'], [1353, 'entailment'], [1354, 'entailment'], [1355, 'contradiction'], [1356, 'contradiction'], [1357, 'contradiction'], [1358, 'entailment'], [1359, 'contradiction'], [1360, 'neutral'], [1361, 'contradiction'], [1362, 'neutral'], [1363, 'neutral'], [1364, 'neutral'], [1365, 'neutral'], [1366, 'contradiction'], [1367, 'contradiction'], [1368, 'entailment'], [1369, 'contradiction'], [1370, 'neutral'], [1371, 'contradiction'], [1372, 'neutral'], [1373, 'contradiction'], [1374, 'neutral'], [1375, 'neutral'], [1376, 'neutral'], [1377, 'contradiction'], [1378, 'entailment'], [1379, 'entailment'], [1380, 'contradiction'], [1381, 'contradiction'], [1382, 'neutral'], [1383, 'entailment'], [1384, 'contradiction'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'contradiction'], [1388, 'entailment'], [1389, 'contradiction'], [1390, 'entailment'], [1391, 'entailment'], [1392, 'neutral'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'neutral'], [1396, 'entailment'], [1397, 'entailment'], [1398, 'entailment'], [1399, 'contradiction'], [1400, 'contradiction'], [1401, 'neutral'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'contradiction'], [1405, 'contradiction'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'contradiction'], [1409, 'contradiction'], [1410, 'contradiction'], [1411, 'neutral'], [1412, 'neutral'], [1413, 'entailment'], [1414, 'neutral'], [1415, 'neutral'], [1416, 'neutral'], [1417, 'contradiction'], [1418, 'neutral'], [1419, 'entailment'], [1420, 'entailment'], [1421, 'neutral'], [1422, 'contradiction'], [1423, 'entailment'], [1424, 'contradiction'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'contradiction'], [1428, 'neutral'], [1429, 'neutral'], [1430, 'entailment'], [1431, 'neutral'], [1432, 'neutral'], [1433, 'entailment'], [1434, 'neutral'], [1435, 'neutral'], [1436, 'contradiction'], [1437, 'neutral'], [1438, 'neutral'], [1439, 'contradiction'], [1440, 'contradiction'], [1441, 'entailment'], [1442, 'contradiction'], [1443, 'entailment'], [1444, 'neutral'], [1445, 'contradiction'], [1446, 'contradiction'], [1447, 'contradiction'], [1448, 'contradiction'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'neutral'], [1452, 'entailment'], [1453, 'neutral'], [1454, 'neutral'], [1455, 'contradiction'], [1456, 'contradiction'], [1457, 'neutral'], [1458, 'neutral'], [1459, 'neutral'], [1460, 'contradiction'], [1461, 'neutral'], [1462, 'contradiction'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'contradiction'], [1466, 'contradiction'], [1467, 'neutral'], [1468, 'neutral'], [1469, 'contradiction'], [1470, 'entailment'], [1471, 'contradiction'], [1472, 'neutral'], [1473, 'contradiction'], [1474, 'entailment'], [1475, 'neutral'], [1476, 'neutral'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'contradiction'], [1480, 'contradiction'], [1481, 'contradiction'], [1482, 'contradiction'], [1483, 'neutral'], [1484, 'entailment'], [1485, 'neutral'], [1486, 'neutral'], [1487, 'contradiction'], [1488, 'contradiction'], [1489, 'entailment'], [1490, 'neutral'], [1491, 'entailment'], [1492, 'neutral'], [1493, 'neutral'], [1494, 'neutral'], [1495, 'entailment'], [1496, 'contradiction'], [1497, 'contradiction'], [1498, 'entailment'], [1499, 'contradiction'], [1500, 'contradiction'], [1501, 'neutral'], [1502, 'contradiction'], [1503, 'entailment'], [1504, 'contradiction'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'entailment'], [1508, 'neutral'], [1509, 'contradiction'], [1510, 'contradiction'], [1511, 'contradiction'], [1512, 'contradiction'], [1513, 'neutral'], [1514, 'contradiction'], [1515, 'contradiction'], [1516, 'entailment'], [1517, 'neutral'], [1518, 'contradiction'], [1519, 'contradiction'], [1520, 'entailment'], [1521, 'contradiction'], [1522, 'neutral'], [1523, 'entailment'], [1524, 'contradiction'], [1525, 'neutral'], [1526, 'contradiction'], [1527, 'neutral'], [1528, 'neutral'], [1529, 'contradiction'], [1530, 'neutral'], [1531, 'entailment'], [1532, 'contradiction'], [1533, 'contradiction'], [1534, 'neutral'], [1535, 'contradiction'], [1536, 'neutral'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'neutral'], [1540, 'contradiction'], [1541, 'entailment'], [1542, 'neutral'], [1543, 'neutral'], [1544, 'entailment'], [1545, 'contradiction'], [1546, 'contradiction'], [1547, 'neutral'], [1548, 'neutral'], [1549, 'contradiction'], [1550, 'entailment'], [1551, 'entailment'], [1552, 'neutral'], [1553, 'entailment'], [1554, 'neutral'], [1555, 'neutral'], [1556, 'entailment'], [1557, 'neutral'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'neutral'], [1561, 'entailment'], [1562, 'neutral'], [1563, 'neutral'], [1564, 'contradiction'], [1565, 'entailment'], [1566, 'contradiction'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'contradiction'], [1570, 'entailment'], [1571, 'entailment'], [1572, 'neutral'], [1573, 'contradiction'], [1574, 'contradiction'], [1575, 'contradiction'], [1576, 'neutral'], [1577, 'contradiction'], [1578, 'contradiction'], [1579, 'entailment'], [1580, 'neutral'], [1581, 'contradiction'], [1582, 'contradiction'], [1583, 'entailment'], [1584, 'neutral'], [1585, 'neutral'], [1586, 'neutral'], [1587, 'entailment'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'contradiction'], [1591, 'entailment'], [1592, 'contradiction'], [1593, 'entailment'], [1594, 'neutral'], [1595, 'neutral'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'neutral'], [1599, 'neutral'], [1600, 'contradiction'], [1601, 'contradiction'], [1602, 'contradiction'], [1603, 'neutral'], [1604, 'entailment'], [1605, 'neutral'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'contradiction'], [1609, 'entailment'], [1610, 'neutral'], [1611, 'neutral'], [1612, 'entailment'], [1613, 'neutral'], [1614, 'entailment'], [1615, 'contradiction'], [1616, 'neutral'], [1617, 'contradiction'], [1618, 'contradiction'], [1619, 'contradiction'], [1620, 'neutral'], [1621, 'entailment'], [1622, 'contradiction'], [1623, 'neutral'], [1624, 'contradiction'], [1625, 'neutral'], [1626, 'neutral'], [1627, 'entailment'], [1628, 'contradiction'], [1629, 'neutral'], [1630, 'contradiction'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'neutral'], [1634, 'neutral'], [1635, 'neutral'], [1636, 'entailment'], [1637, 'contradiction'], [1638, 'contradiction'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'contradiction'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'contradiction'], [1645, 'neutral'], [1646, 'contradiction'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'contradiction'], [1650, 'contradiction'], [1651, 'entailment'], [1652, 'neutral'], [1653, 'contradiction'], [1654, 'contradiction'], [1655, 'entailment'], [1656, 'neutral'], [1657, 'neutral'], [1658, 'neutral'], [1659, 'entailment'], [1660, 'entailment'], [1661, 'neutral'], [1662, 'entailment'], [1663, 'neutral'], [1664, 'neutral'], [1665, 'entailment']]\n"
     ]
    }
   ],
   "source": [
    "def num_to_label(label):\n",
    "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
    "    str_label = []\n",
    "\n",
    "    for i, v in enumerate(label):\n",
    "        str_label.append([i,label_dict[v]])\n",
    "    \n",
    "    return str_label\n",
    "\n",
    "answer = num_to_label(pred_answer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index          label\n",
      "0         0  contradiction\n",
      "1         1        neutral\n",
      "2         2     entailment\n",
      "3         3  contradiction\n",
      "4         4  contradiction\n",
      "...     ...            ...\n",
      "1661   1661        neutral\n",
      "1662   1662     entailment\n",
      "1663   1663        neutral\n",
      "1664   1664        neutral\n",
      "1665   1665     entailment\n",
      "\n",
      "[1666 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
    "\n",
    "df.to_csv('pure_test_electra.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "094f33ed2071450d91c60f15b0331e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "095be4a6f89d4603b8a0b314727bd7a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1e6ccdaaa224d05be7928a5aafaab64",
      "max": 751504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5a393fdf1044e6298a258d4bb8fcd84",
      "value": 751504
     }
    },
    "0bbfd5f0ec2d4436a06bb502f8131f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cde98b9a09144b6b25b121ab70b4ff4",
      "placeholder": "​",
      "style": "IPY_MODEL_21f45f4a718446cea0a2ae70c743ba61",
      "value": "Downloading: 100%"
     }
    },
    "0cde98b9a09144b6b25b121ab70b4ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c3fbc303704c62957bd8c329b8024e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fe9d0f2a6924eba82b3502d43030b61",
       "IPY_MODEL_8902ff1c00df45c78d5b02464ee50756",
       "IPY_MODEL_8fdfe2b3e6e64012ac265a462fbcf328"
      ],
      "layout": "IPY_MODEL_ddd8542cdb7c4844b19cb62fa5e5e146"
     }
    },
    "16cd5a8125f64e618585d262ed0dcc39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1809bf6050194337a8a1efd347bf1f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a91d489ae164c8ca4243d06894962fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c5b91e6ae4d46d0b2f099cd1d4c15cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bbfd5f0ec2d4436a06bb502f8131f49",
       "IPY_MODEL_2613deb06698404396c37a2cc26f5dc4",
       "IPY_MODEL_daa90c709c4b46439770068ba936d25f"
      ],
      "layout": "IPY_MODEL_d66d726b5a104734a7bcfa4d5bfd53b2"
     }
    },
    "1ced7dcc914c47788ca51353a2245f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25ef02ee9d634d79b632eb0a5ad0f6fa",
       "IPY_MODEL_095be4a6f89d4603b8a0b314727bd7a4",
       "IPY_MODEL_c3e047157c734a5fbf6a6c8dc27c5913"
      ],
      "layout": "IPY_MODEL_16cd5a8125f64e618585d262ed0dcc39"
     }
    },
    "1d38cc6507084d34a2d41ada6a37b83e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f45f4a718446cea0a2ae70c743ba61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25ef02ee9d634d79b632eb0a5ad0f6fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3560910251ab4451ba5df9bf0953e999",
      "placeholder": "​",
      "style": "IPY_MODEL_c0ef75dc157d4b2a9c881661aa39347c",
      "value": "Downloading: 100%"
     }
    },
    "2613deb06698404396c37a2cc26f5dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3882a8be8ec44b9fb9595d4239c46930",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6e6cbbc9d0e443ca58cdcfe2c44f49e",
      "value": 375
     }
    },
    "27848cf6c21243f99f6421c294e2844f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c17f7168c24bcfbfb6cacf9d8a2b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd3c31a170a431ca04bbeeb641f6590": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341d1f2f2ec34446bcc1049dafda1c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3560910251ab4451ba5df9bf0953e999": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3882a8be8ec44b9fb9595d4239c46930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa68625b6364fdcb47c203b43277941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bebe6d4ba11479c8d6b952c786d5393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f4bd07499745d09d398568221a49aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a046ee54d1d485e84835c858f31be0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c07c3365e984f3596c00edb9cd2c184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cdf8336d32747629b01a6550240c6fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d26fc2e49c4bfaa89415d44a0606ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b541face9d74d2eae19066c55320567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afd8616825be40a8a52b1df11d73c64d",
      "placeholder": "​",
      "style": "IPY_MODEL_341d1f2f2ec34446bcc1049dafda1c82",
      "value": "Downloading: 100%"
     }
    },
    "5fe9d0f2a6924eba82b3502d43030b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3f1a17e1bd642e9b17fa94aff662eda",
      "placeholder": "​",
      "style": "IPY_MODEL_6c7eed7e50f34a1584a9639f26c277fe",
      "value": "Downloading: 100%"
     }
    },
    "683388a3551c4cfc922c56cba867d04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6860bf24436f4e098c668a285fd06f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b541face9d74d2eae19066c55320567",
       "IPY_MODEL_fbabe1a9a00a419b8c5f54375e80d952",
       "IPY_MODEL_f207ba49d03d4d11abd8a50c624eb7c8"
      ],
      "layout": "IPY_MODEL_3aa68625b6364fdcb47c203b43277941"
     }
    },
    "6be5e8971a294d58b173245f74bf1975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cd3c31a170a431ca04bbeeb641f6590",
      "placeholder": "​",
      "style": "IPY_MODEL_77abc577d69e4ca69ff1afe8c3a37d43",
      "value": "Downloading: 100%"
     }
    },
    "6c7eed7e50f34a1584a9639f26c277fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "704b74d3a9a040e9a11e57234af566ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73c789717a3745a9b431931ce845432b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77abc577d69e4ca69ff1afe8c3a37d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7af67cc2ae4b4c3abb9e7a208ecc9fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cb35513245c4927858d1ad05062340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8242b29066ed4717b957c897adba8533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8437c6dcd988498fb32f3d0557bb2385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_accc4b1e20d149aab8385df3109eb92f",
       "IPY_MODEL_9579ee57512f4bfbae9eeaac961ef7cb",
       "IPY_MODEL_a3591cd1d9f04511b42b45cde368fbc7"
      ],
      "layout": "IPY_MODEL_1d38cc6507084d34a2d41ada6a37b83e"
     }
    },
    "86daa3417a4147c4acc5b2cb0aff4935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6be5e8971a294d58b173245f74bf1975",
       "IPY_MODEL_ebdfb09f0319470db6ef22d68916b111",
       "IPY_MODEL_c0c048b2bc734c2a9a05a3195b29b136"
      ],
      "layout": "IPY_MODEL_f2b21dab53e944a58572bbdd6c9c94b0"
     }
    },
    "8902ff1c00df45c78d5b02464ee50756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c17f7168c24bcfbfb6cacf9d8a2b24",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1809bf6050194337a8a1efd347bf1f88",
      "value": 173
     }
    },
    "8fdfe2b3e6e64012ac265a462fbcf328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c40ba97a8a66488cb7b62cf85aead2b5",
      "placeholder": "​",
      "style": "IPY_MODEL_e8da32862f9049ceb6796662fcd4444f",
      "value": " 173/173 [00:00&lt;00:00, 3.16kB/s]"
     }
    },
    "9251c8da568641daacabf3e198c79290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9579ee57512f4bfbae9eeaac961ef7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_094f33ed2071450d91c60f15b0331e8c",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cb35513245c4927858d1ad05062340d",
      "value": 248477
     }
    },
    "a3591cd1d9f04511b42b45cde368fbc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f4bd07499745d09d398568221a49aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e03141fe0ca24aa888dc4ce1734ef897",
      "value": " 248k/248k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "accc4b1e20d149aab8385df3109eb92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c07c3365e984f3596c00edb9cd2c184",
      "placeholder": "​",
      "style": "IPY_MODEL_b18b9e54b8bb47a7ac0d5d4db9cc0946",
      "value": "Downloading: 100%"
     }
    },
    "afd8616825be40a8a52b1df11d73c64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18b9e54b8bb47a7ac0d5d4db9cc0946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1e6ccdaaa224d05be7928a5aafaab64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0c048b2bc734c2a9a05a3195b29b136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9251c8da568641daacabf3e198c79290",
      "placeholder": "​",
      "style": "IPY_MODEL_1a91d489ae164c8ca4243d06894962fa",
      "value": " 1.35G/1.35G [00:20&lt;00:00, 73.7MB/s]"
     }
    },
    "c0ef75dc157d4b2a9c881661aa39347c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3e047157c734a5fbf6a6c8dc27c5913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a046ee54d1d485e84835c858f31be0c",
      "placeholder": "​",
      "style": "IPY_MODEL_57d26fc2e49c4bfaa89415d44a0606ec",
      "value": " 752k/752k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "c40ba97a8a66488cb7b62cf85aead2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a393fdf1044e6298a258d4bb8fcd84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d66d726b5a104734a7bcfa4d5bfd53b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa90c709c4b46439770068ba936d25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cdf8336d32747629b01a6550240c6fe",
      "placeholder": "​",
      "style": "IPY_MODEL_8242b29066ed4717b957c897adba8533",
      "value": " 375/375 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "ddd8542cdb7c4844b19cb62fa5e5e146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e03141fe0ca24aa888dc4ce1734ef897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8da32862f9049ceb6796662fcd4444f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebdfb09f0319470db6ef22d68916b111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c789717a3745a9b431931ce845432b",
      "max": 1346930258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_704b74d3a9a040e9a11e57234af566ea",
      "value": 1346930258
     }
    },
    "f207ba49d03d4d11abd8a50c624eb7c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bebe6d4ba11479c8d6b952c786d5393",
      "placeholder": "​",
      "style": "IPY_MODEL_683388a3551c4cfc922c56cba867d04c",
      "value": " 547/547 [00:00&lt;00:00, 9.70kB/s]"
     }
    },
    "f2b21dab53e944a58572bbdd6c9c94b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f1a17e1bd642e9b17fa94aff662eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6e6cbbc9d0e443ca58cdcfe2c44f49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbabe1a9a00a419b8c5f54375e80d952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27848cf6c21243f99f6421c294e2844f",
      "max": 547,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7af67cc2ae4b4c3abb9e7a208ecc9fd5",
      "value": 547
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
