{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 10 17:44:21 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   53C    P0   244W / 300W |  14725MiB / 32510MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   64C    P0   297W / 300W |  31578MiB / 32510MiB |     76%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2060      C   .../envs/test_env/bin/python    13695MiB |\r\n",
      "|    0   N/A  N/A     65391      C   .../envs/test_env/bin/python     1027MiB |\r\n",
      "|    1   N/A  N/A      2060      C   .../envs/test_env/bin/python     9673MiB |\r\n",
      "|    1   N/A  N/A      7312      C   .../envs/test_env/bin/python      841MiB |\r\n",
      "|    1   N/A  N/A    101633      C   .../envs/test_env/bin/python    21061MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/centos/psw/KSRC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_bVw3BzS66Gp"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast, BartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K7aUlj6L7eAH",
    "outputId": "575cdb6d-f613-45e8-82d4-146d2a0c2761",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159470</th>\n",
       "      <td>159470</td>\n",
       "      <td>같은 방향으로 보이는 숲이 우거진 지역에 의상을 입은 사람들이 모여 있다.</td>\n",
       "      <td>사람들은 의상을 입는다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159471</th>\n",
       "      <td>159471</td>\n",
       "      <td>검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.</td>\n",
       "      <td>하이힐을 신은 남자</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159472</th>\n",
       "      <td>159472</td>\n",
       "      <td>검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.</td>\n",
       "      <td>서 있는 소녀</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159473</th>\n",
       "      <td>159473</td>\n",
       "      <td>검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.</td>\n",
       "      <td>사진 촬영 준비를 하고 있는 소녀</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159474</th>\n",
       "      <td>159474</td>\n",
       "      <td>한 남자가 유람선을 배경으로 부두에서 포즈를 취하고 있다.</td>\n",
       "      <td>포즈를 취하는 인간.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                    premise          hypothesis  \\\n",
       "159470  159470  같은 방향으로 보이는 숲이 우거진 지역에 의상을 입은 사람들이 모여 있다.        사람들은 의상을 입는다   \n",
       "159471  159471      검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.          하이힐을 신은 남자   \n",
       "159472  159472      검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.             서 있는 소녀   \n",
       "159473  159473      검은 원피스에 커다란 흰 활을 든 소녀가 카메라를 등지고 서 있다.  사진 촬영 준비를 하고 있는 소녀   \n",
       "159474  159474           한 남자가 유람선을 배경으로 부두에서 포즈를 취하고 있다.         포즈를 취하는 인간.   \n",
       "\n",
       "                label  \n",
       "159470     entailment  \n",
       "159471  contradiction  \n",
       "159472     entailment  \n",
       "159473        neutral  \n",
       "159474     entailment  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dpath = '/content/drive/My Drive/Seculayer/KSRC/'\n",
    "train = pd.read_csv('data/with_kakao_train.csv',encoding='utf-8')\n",
    "train = train.rename(columns={'Unnamed: 0':\"index\"})\n",
    "test = pd.read_csv('data/test_data.csv',encoding='utf-8')\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "yv3YDRoOHPoX",
    "outputId": "0883bafc-6b61-4dd4-c270-51516ed832f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2      2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불 용어 처리 \n",
    "\n",
    "train['premise'] = train['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['premise'] = test['premise'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "hCfxgISsHvZl",
    "outputId": "43f42d44-7632-48bd-d175-3c42d7029276"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            premise  \\\n",
       "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2      2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                               hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다        neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hypothesis'] = train['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['hypothesis'] = test['hypothesis'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159325 entries, 0 to 159474\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   index       159325 non-null  int64 \n",
      " 1   premise     159325 non-null  object\n",
      " 2   hypothesis  159325 non-null  object\n",
      " 3   label       159325 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train['length'] = train['premise'].apply(lambda x: len(x))\n",
    "train = train.loc[train['length']<105]\n",
    "train.drop('length',axis=1,inplace=True)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6FpW8SM7lwW",
    "outputId": "e779fb75-c660-4224-8296-fb17f2facfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159475 entries, 0 to 159474\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   index       159475 non-null  int64 \n",
      " 1   premise     159475 non-null  object\n",
      " 2   hypothesis  159475 non-null  object\n",
      " 3   label       159475 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1666 entries, 0 to 1665\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       1666 non-null   int64 \n",
      " 1   premise     1666 non-null   object\n",
      " 2   hypothesis  1666 non-null   object\n",
      " 3   label       1666 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 52.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 결측치는 없음\n",
    "\n",
    "print(train.info(), end='\\n\\n')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4L1jeCl72DF",
    "outputId": "b5c8ce74-4bce-4603-a0f6-e8cbcd527b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label: \n",
      "entailment       53618\n",
      "contradiction    53468\n",
      "neutral          52389\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Label: ', train['label'].value_counts(), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9SAoqqNmAU3x",
    "outputId": "cbe32eff-2df0-4a4f-9d17-50537c24cd33"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data imbalance는 사실상 존재하지 않음 \n",
    "\n",
    "sns.countplot(data=train,x='label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T6hQolMqAkji"
   },
   "outputs": [],
   "source": [
    "max_premise = np.max(train['premise'].str.len())\n",
    "max_hypothesis = np.max(train['hypothesis'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AApuxsJBcYi",
    "outputId": "744f3bd4-e74b-40cf-defb-abfd64225d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max premise = 104 \n",
      "max hypothesis = 102\n"
     ]
    }
   ],
   "source": [
    "print('max premise =',max_premise,\"\\nmax hypothesis =\",max_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['premise'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "5xFFliUaCiwR",
    "outputId": "b7132a6d-24cb-4773-edaa-13d9d7e75af2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['hypothesis'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 2023):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (18): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (19): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (20): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (21): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (22): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (23): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'klue/roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "config.num_labels = 3\n",
    "# config.learning_rate = 2.5e-05\n",
    "# config.warmup_ratio = 0.09\n",
    "# config.weight_decay = 0.007\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "print(model)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  6120,  2031,  2170,  2318,  9325,  2250,  2270,  2052,  2241,\n",
      "         4819,  1325,  3677,  2470, 12447,  2170,  3979,  2069,  5072,  2259,\n",
      "         1767,  2170,  3641,  2069, 10822,  2259, 27567,  1415,  2259,  4175,\n",
      "        15351, 10031,  2069,  3681,  2200,  3855,  2052,  5837,  2205,  2062,\n",
      "            2,  6120,  2031,  2073,  9325,  2250,  2270,  2069,  1889,  2015,\n",
      "         2090,  2097,  5873,  3855,  2069,  3605,     2,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1])\n",
      "[CLS] 대학생들에게 수강신청이란 취업 시 필요한 학점에 영향을 미치는 탓에 시간을 다투는 총성 없는 전쟁이나 다름없을 정도로 경쟁이 치열하다 [SEP] 대학생들은 수강신청을 하기위해 엄청난 경쟁을 한다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# train test split 및 tokenizing \n",
    "# token에 들어가는 문장은 premise와 hypothesis를 concat 한 문장\n",
    "\n",
    "train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['label'])\n",
    "\n",
    "tokenized_train = tokenizer(\n",
    "    list(train_dataset['premise']),\n",
    "    list(train_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=210, # Max_Length = 190\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "tokenized_eval = tokenizer(\n",
    "    list(eval_dataset['premise']),\n",
    "    list(eval_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=210,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(tokenized_train['input_ids'][0])\n",
    "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "\n",
    "    return num_label\n",
    "\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "eval_label = label_to_num(eval_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BERTDataset(tokenized_train, train_label)\n",
    "eval_dataset = BERTDataset(tokenized_eval, eval_label)\n",
    "\n",
    "# print(train_dataset.__len__())\n",
    "# print(train_dataset.__getitem__(19997))\n",
    "# print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  \"\"\" validation을 위한 metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
    "\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, \n",
    "                                                              config=config)\n",
    "\n",
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 3e-5, 0.00004, log=True),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0, 0.6),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 0.01),\n",
    "#         \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "#         \"seed\": trial.suggest_int(\"seed\", 20, 40),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
    "    }\n",
    "\n",
    "# def my_hp_space(trial):\n",
    "#     return {\n",
    "#         \"learning_rate\":  trial.suggest_categorical(\"learning_rate\", [0.00001,0.00002, 0.00003,0.00004,0.00005]),\n",
    "#         \"warmup_ratio\":  trial.suggest_categorical(\"warmup_ratio\", [0,0.1, 0.2,0.6]),\n",
    "#         \"weight_decay\":  trial.suggest_categorical(\"weight_decay\", [0, 0.01]),\n",
    "# #         \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "# #         \"seed\": trial.suggest_int(\"seed\", 20, 40),\n",
    "#         \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8,16, 32]),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "training_ars = TrainingArguments(\n",
    "    output_dir='result/Large_data_roberta_hyperparameter_tune/',\n",
    "    num_train_epochs=7,\n",
    "    save_total_limit=5,\n",
    "    save_steps=800,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 800,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_ars,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-10 17:51:14,594]\u001b[0m A new study created in memory with name: no-name-c8bfaf27-2359-4955-acd7-d5fa22ea63b5\u001b[0m\n",
      "Trial: {'learning_rate': 3.734045079463956e-05, 'warmup_ratio': 0.10348143988560894, 'weight_decay': 0.00850552720218451, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msangmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_175122-3vszhbld</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/3vszhbld\" target=\"_blank\">fearless-shadow-63</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4800/27888 1:02:54 < 5:02:44, 1.27 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.866400</td>\n",
       "      <td>0.496066</td>\n",
       "      <td>0.820901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.462724</td>\n",
       "      <td>0.826267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.436528</td>\n",
       "      <td>0.833924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.445254</td>\n",
       "      <td>0.828684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.460900</td>\n",
       "      <td>0.493826</td>\n",
       "      <td>0.847325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>0.479550</td>\n",
       "      <td>0.839510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-4800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-800] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/Large_data_roberta_hyperparameter_tune/run-0/checkpoint-2400 (score: 0.43652838468551636).\n",
      "\u001b[32m[I 2023-01-10 18:54:23,504]\u001b[0m Trial 0 finished with value: 0.8395104346461635 and parameters: {'learning_rate': 3.734045079463956e-05, 'warmup_ratio': 0.10348143988560894, 'weight_decay': 0.00850552720218451, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8395104346461635.\u001b[0m\n",
      "Trial: {'learning_rate': 3.3825891939545736e-05, 'warmup_ratio': 0.0008532364473335718, 'weight_decay': 0.00409033045764917, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ccb9e4bd8e48ca855cd31afdfd2c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▂▄▃█▆</td></tr><tr><td>eval/loss</td><td>█▄▁▂█▆</td></tr><tr><td>eval/runtime</td><td>▁█▇▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>█▁▂▇██</td></tr><tr><td>eval/steps_per_second</td><td>█▁▂▇██</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▃▃▄▄▅▅▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▃▃▄▄▅▅▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▄▅▇███▇</td></tr><tr><td>train/loss</td><td>█▃▂▃▂▃▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83951</td></tr><tr><td>eval/loss</td><td>0.47955</td></tr><tr><td>eval/runtime</td><td>222.7979</td></tr><tr><td>eval/samples_per_second</td><td>143.022</td></tr><tr><td>eval/steps_per_second</td><td>8.941</td></tr><tr><td>train/epoch</td><td>1.2</td></tr><tr><td>train/global_step</td><td>4800</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.3896</td></tr><tr><td>train/total_flos</td><td>2.7393880070037264e+16</td></tr><tr><td>train/train_loss</td><td>0.51572</td></tr><tr><td>train/train_runtime</td><td>3783.9601</td></tr><tr><td>train/train_samples_per_second</td><td>235.79</td></tr><tr><td>train/train_steps_per_second</td><td>7.37</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fearless-shadow-63</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/3vszhbld\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/3vszhbld</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230110_175122-3vszhbld/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffbbe32e2f54ca2b73c2a6c8cc58177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016734620742499828, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_185436-srtpwxsr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/srtpwxsr\" target=\"_blank\">fanciful-dream-64</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6400' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6400/27888 1:17:49 < 4:21:21, 1.37 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.119200</td>\n",
       "      <td>1.099078</td>\n",
       "      <td>0.336200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.110400</td>\n",
       "      <td>1.104791</td>\n",
       "      <td>0.335290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.109300</td>\n",
       "      <td>1.099001</td>\n",
       "      <td>0.335290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.104900</td>\n",
       "      <td>1.099627</td>\n",
       "      <td>0.335290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.103900</td>\n",
       "      <td>1.098942</td>\n",
       "      <td>0.336200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.104900</td>\n",
       "      <td>1.099608</td>\n",
       "      <td>0.335290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>1.100648</td>\n",
       "      <td>0.336200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.102800</td>\n",
       "      <td>1.103821</td>\n",
       "      <td>0.336200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-5600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-5600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-5600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-5600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-5600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-1600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-6400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-6400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-6400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-6400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-6400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-2400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/Large_data_roberta_hyperparameter_tune/run-1/checkpoint-4000 (score: 1.0989421606063843).\n",
      "\u001b[32m[I 2023-01-10 20:12:27,235]\u001b[0m Trial 1 finished with value: 0.3361995920288718 and parameters: {'learning_rate': 3.3825891939545736e-05, 'warmup_ratio': 0.0008532364473335718, 'weight_decay': 0.00409033045764917, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8395104346461635.\u001b[0m\n",
      "Trial: {'learning_rate': 3.768936425282347e-05, 'warmup_ratio': 0.4722076565224357, 'weight_decay': 0.0039901578118491845, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421808e82131440aa0d0a02a34e23adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▁▁█▁██</td></tr><tr><td>eval/loss</td><td>▁█▁▂▁▂▃▇</td></tr><tr><td>eval/runtime</td><td>▁▄▆▄▃▃▆█</td></tr><tr><td>eval/samples_per_second</td><td>█▅▃▅▆▆▃▁</td></tr><tr><td>eval/steps_per_second</td><td>█▅▃▅▆▆▃▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▅▅▄▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▃▂▂▁▂▁▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.3362</td></tr><tr><td>eval/loss</td><td>1.10382</td></tr><tr><td>eval/runtime</td><td>225.234</td></tr><tr><td>eval/samples_per_second</td><td>141.475</td></tr><tr><td>eval/steps_per_second</td><td>8.844</td></tr><tr><td>train/epoch</td><td>1.61</td></tr><tr><td>train/global_step</td><td>6400</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.1028</td></tr><tr><td>train/total_flos</td><td>3.652683828889166e+16</td></tr><tr><td>train/train_loss</td><td>1.10713</td></tr><tr><td>train/train_runtime</td><td>4678.4936</td></tr><tr><td>train/train_samples_per_second</td><td>190.707</td></tr><tr><td>train/train_steps_per_second</td><td>5.961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-dream-64</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/srtpwxsr\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/srtpwxsr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230110_185436-srtpwxsr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87186a6caccc463d89547168286e71d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016777951456606387, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_201237-e24ngzk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/e24ngzk5\" target=\"_blank\">deep-leaf-65</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6400' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6400/27888 1:18:03 < 4:22:11, 1.37 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.080200</td>\n",
       "      <td>0.572703</td>\n",
       "      <td>0.790962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.436672</td>\n",
       "      <td>0.836121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.401359</td>\n",
       "      <td>0.851247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.389589</td>\n",
       "      <td>0.858308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.379875</td>\n",
       "      <td>0.858999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.398831</td>\n",
       "      <td>0.865526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.401767</td>\n",
       "      <td>0.856018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.389967</td>\n",
       "      <td>0.861070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-5600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-5600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-5600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-5600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-5600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-1600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-6400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-6400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-6400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-6400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-6400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-2400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/Large_data_roberta_hyperparameter_tune/run-2/checkpoint-4000 (score: 0.3798747956752777).\n",
      "\u001b[32m[I 2023-01-10 21:30:43,500]\u001b[0m Trial 2 finished with value: 0.8610701396516555 and parameters: {'learning_rate': 3.768936425282347e-05, 'warmup_ratio': 0.4722076565224357, 'weight_decay': 0.0039901578118491845, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 0.8610701396516555.\u001b[0m\n",
      "Trial: {'learning_rate': 3.0301883965385675e-05, 'warmup_ratio': 0.4979655853767051, 'weight_decay': 0.0036690214868301796, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bd9fc848814716b1719cf2cc5c7454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇▇█▇█</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁▂▂▁</td></tr><tr><td>eval/runtime</td><td>▂▂▂▁▁▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▇██▇▆▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▇██▇▆▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.86107</td></tr><tr><td>eval/loss</td><td>0.38997</td></tr><tr><td>eval/runtime</td><td>229.0138</td></tr><tr><td>eval/samples_per_second</td><td>139.14</td></tr><tr><td>eval/steps_per_second</td><td>8.698</td></tr><tr><td>train/epoch</td><td>1.61</td></tr><tr><td>train/global_step</td><td>6400</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.3555</td></tr><tr><td>train/total_flos</td><td>3.652683828889166e+16</td></tr><tr><td>train/train_loss</td><td>0.48018</td></tr><tr><td>train/train_runtime</td><td>4691.8891</td></tr><tr><td>train/train_samples_per_second</td><td>190.162</td></tr><tr><td>train/train_steps_per_second</td><td>5.944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">deep-leaf-65</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/e24ngzk5\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/e24ngzk5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230110_201237-e24ngzk5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44148840c52404f9aa06f1ec7ada9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667891480028629, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_213054-1n2smlpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/1n2smlpg\" target=\"_blank\">dry-sunset-66</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9600' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9600/27888 1:57:08 < 3:43:11, 1.37 it/s, Epoch 2/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>0.604908</td>\n",
       "      <td>0.772289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.451097</td>\n",
       "      <td>0.829970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.411332</td>\n",
       "      <td>0.845787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.386361</td>\n",
       "      <td>0.857430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.391881</td>\n",
       "      <td>0.857555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.392767</td>\n",
       "      <td>0.865683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.383658</td>\n",
       "      <td>0.859909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.390745</td>\n",
       "      <td>0.867472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.357610</td>\n",
       "      <td>0.869167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.395267</td>\n",
       "      <td>0.872682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.438918</td>\n",
       "      <td>0.865683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.386808</td>\n",
       "      <td>0.871897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-5600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-5600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-5600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-5600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-5600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-1600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-6400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-6400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-6400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-6400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-6400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-2400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-3200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-8800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-4800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-9600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-9600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-9600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-5600] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200 (score: 0.3576100170612335).\n",
      "\u001b[32m[I 2023-01-10 23:28:04,946]\u001b[0m Trial 3 finished with value: 0.8718970657461165 and parameters: {'learning_rate': 3.0301883965385675e-05, 'warmup_ratio': 0.4979655853767051, 'weight_decay': 0.0036690214868301796, 'per_device_train_batch_size': 16}. Best is trial 3 with value: 0.8718970657461165.\u001b[0m\n",
      "Trial: {'learning_rate': 3.2151243863123215e-05, 'warmup_ratio': 0.5415516211575774, 'weight_decay': 0.001426440004371059, 'per_device_train_batch_size': 32}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13944\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ef50a603504bef89b85ca9b20df8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇▇█▇█████</td></tr><tr><td>eval/loss</td><td>█▄▃▂▂▂▂▂▁▂▃▂</td></tr><tr><td>eval/runtime</td><td>▄▇▄▂▁▁▁▅▃▄█▄</td></tr><tr><td>eval/samples_per_second</td><td>▅▂▅▇███▄▆▅▁▅</td></tr><tr><td>eval/steps_per_second</td><td>▅▂▅▇███▄▆▅▁▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>▁▁▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/loss</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8719</td></tr><tr><td>eval/loss</td><td>0.38681</td></tr><tr><td>eval/runtime</td><td>226.0199</td></tr><tr><td>eval/samples_per_second</td><td>140.983</td></tr><tr><td>eval/steps_per_second</td><td>8.813</td></tr><tr><td>train/epoch</td><td>2.41</td></tr><tr><td>train/global_step</td><td>9600</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.3007</td></tr><tr><td>train/total_flos</td><td>5.478776014007453e+16</td></tr><tr><td>train/train_loss</td><td>0.43673</td></tr><tr><td>train/train_runtime</td><td>7036.7889</td></tr><tr><td>train/train_samples_per_second</td><td>126.794</td></tr><tr><td>train/train_steps_per_second</td><td>3.963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dry-sunset-66</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/1n2smlpg\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/1n2smlpg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230110_213054-1n2smlpg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be419972237b417fab9e632491d79d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016689748441179594, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_232816-21ievutu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/21ievutu\" target=\"_blank\">confused-sponge-67</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5600' max='13944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5600/13944 1:29:48 < 2:13:52, 1.04 it/s, Epoch 2/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.976800</td>\n",
       "      <td>0.480739</td>\n",
       "      <td>0.819488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.419206</td>\n",
       "      <td>0.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.386592</td>\n",
       "      <td>0.862890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.372479</td>\n",
       "      <td>0.866248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.386592</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.385763</td>\n",
       "      <td>0.868508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.373767</td>\n",
       "      <td>0.871458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-4800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-5600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-5600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-5600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-5600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-5600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-1600] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/Large_data_roberta_hyperparameter_tune/run-4/checkpoint-3200 (score: 0.3724788427352905).\n",
      "\u001b[32m[I 2023-01-11 00:58:07,926]\u001b[0m Trial 4 finished with value: 0.8714577122234426 and parameters: {'learning_rate': 3.2151243863123215e-05, 'warmup_ratio': 0.5415516211575774, 'weight_decay': 0.001426440004371059, 'per_device_train_batch_size': 32}. Best is trial 3 with value: 0.8718970657461165.\u001b[0m\n",
      "Trial: {'learning_rate': 3.0147369451452834e-05, 'warmup_ratio': 0.28204863810689534, 'weight_decay': 0.008818302624230214, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b979bceaff545fbbc936fe9217157de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇█▇▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▂▂▁</td></tr><tr><td>eval/runtime</td><td>▁▂▂▃█▃▃</td></tr><tr><td>eval/samples_per_second</td><td>█▇▇▆▁▆▆</td></tr><tr><td>eval/steps_per_second</td><td>█▇▇▆▁▆▆</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▃▄▄▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.87146</td></tr><tr><td>eval/loss</td><td>0.37377</td></tr><tr><td>eval/runtime</td><td>226.3664</td></tr><tr><td>eval/samples_per_second</td><td>140.767</td></tr><tr><td>eval/steps_per_second</td><td>8.8</td></tr><tr><td>train/epoch</td><td>2.81</td></tr><tr><td>train/global_step</td><td>5600</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.2933</td></tr><tr><td>train/total_flos</td><td>6.392071835892893e+16</td></tr><tr><td>train/train_loss</td><td>0.42147</td></tr><tr><td>train/train_runtime</td><td>5398.5059</td></tr><tr><td>train/train_samples_per_second</td><td>165.272</td></tr><tr><td>train/train_steps_per_second</td><td>2.583</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">confused-sponge-67</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/21ievutu\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/21ievutu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230110_232816-21ievutu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8e63e79a1444618dbde84f0f96da4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666955289741357, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230111_005819-2s54gyp6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/2s54gyp6\" target=\"_blank\">breezy-fog-68</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4800/27888 58:16 < 4:40:24, 1.37 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.042200</td>\n",
       "      <td>0.541110</td>\n",
       "      <td>0.803170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.430383</td>\n",
       "      <td>0.840044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.472100</td>\n",
       "      <td>0.396350</td>\n",
       "      <td>0.853789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.433200</td>\n",
       "      <td>0.385165</td>\n",
       "      <td>0.858120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.387815</td>\n",
       "      <td>0.862012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.416441</td>\n",
       "      <td>0.864679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-5/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-11 01:56:37,948]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 3.3459797821302464e-05, 'warmup_ratio': 0.34666973991058997, 'weight_decay': 0.005436824907438928, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇██</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁▂</td></tr><tr><td>eval/runtime</td><td>▁█▅█▅▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁▄▁▄▅</td></tr><tr><td>eval/steps_per_second</td><td>█▁▃▁▄▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▃▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▃▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.86468</td></tr><tr><td>eval/loss</td><td>0.41644</td></tr><tr><td>eval/runtime</td><td>225.4734</td></tr><tr><td>eval/samples_per_second</td><td>141.325</td></tr><tr><td>eval/steps_per_second</td><td>8.835</td></tr><tr><td>train/epoch</td><td>1.2</td></tr><tr><td>train/global_step</td><td>4800</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.3406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">breezy-fog-68</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/2s54gyp6\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/2s54gyp6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230111_005819-2s54gyp6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f1eea780f94545b835fe64e9f4b8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668417491018772, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230111_015649-24cyivvj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/24cyivvj\" target=\"_blank\">decent-energy-69</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4800/27888 58:20 < 4:40:43, 1.37 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.054300</td>\n",
       "      <td>0.550178</td>\n",
       "      <td>0.799529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.507700</td>\n",
       "      <td>0.429740</td>\n",
       "      <td>0.838757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.473600</td>\n",
       "      <td>0.396394</td>\n",
       "      <td>0.853099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.385331</td>\n",
       "      <td>0.858528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.392591</td>\n",
       "      <td>0.858434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.343000</td>\n",
       "      <td>0.399133</td>\n",
       "      <td>0.861792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-6/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-11 02:55:13,062]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 3.458715986674017e-05, 'warmup_ratio': 0.042726570895637896, 'weight_decay': 0.008416964630325773, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf145761e6294576b07ec419327b47d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇███</td></tr><tr><td>eval/loss</td><td>█▃▁▁▁▂</td></tr><tr><td>eval/runtime</td><td>▁▇▇▆▆█</td></tr><tr><td>eval/samples_per_second</td><td>█▂▂▃▃▁</td></tr><tr><td>eval/steps_per_second</td><td>█▂▂▃▃▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▃▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▃▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▄▄▅▆▇█</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.86179</td></tr><tr><td>eval/loss</td><td>0.39913</td></tr><tr><td>eval/runtime</td><td>226.3162</td></tr><tr><td>eval/samples_per_second</td><td>140.799</td></tr><tr><td>eval/steps_per_second</td><td>8.802</td></tr><tr><td>train/epoch</td><td>1.2</td></tr><tr><td>train/global_step</td><td>4800</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.343</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">decent-energy-69</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/24cyivvj\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/24cyivvj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230111_015649-24cyivvj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8325075e874c1ca099df598c9d8ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016695064616700013, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230111_025523-5suc2nkh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/5suc2nkh\" target=\"_blank\">true-dust-70</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1600/27888 19:17 < 5:17:23, 1.38 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.489521</td>\n",
       "      <td>0.815409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.478979</td>\n",
       "      <td>0.818390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-7/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-7/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-7/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-7/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-7/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-11 03:14:43,382]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 3.4308372681859187e-05, 'warmup_ratio': 0.11368653278847671, 'weight_decay': 0.006850187860244073, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f057aa765bb409fabfb407a56c8236f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▃▄▇█</td></tr><tr><td>train/global_step</td><td>▁▃▄▇█</td></tr><tr><td>train/learning_rate</td><td>▁▆█</td></tr><tr><td>train/loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81839</td></tr><tr><td>eval/loss</td><td>0.47898</td></tr><tr><td>eval/runtime</td><td>225.6643</td></tr><tr><td>eval/samples_per_second</td><td>141.205</td></tr><tr><td>eval/steps_per_second</td><td>8.827</td></tr><tr><td>train/epoch</td><td>0.4</td></tr><tr><td>train/global_step</td><td>1600</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.5322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-dust-70</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/5suc2nkh\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/5suc2nkh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230111_025523-5suc2nkh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471ead4de3cc4924818d3c9dd4c361b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01671322366843621, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230111_031453-bkj21q2i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/bkj21q2i\" target=\"_blank\">resilient-shadow-71</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2400' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2400/27888 29:04 < 5:09:07, 1.37 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.894900</td>\n",
       "      <td>0.484332</td>\n",
       "      <td>0.822846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.415417</td>\n",
       "      <td>0.841582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.477400</td>\n",
       "      <td>0.459133</td>\n",
       "      <td>0.833705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-8/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-11 03:44:00,848]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 3.4771271419951425e-05, 'warmup_ratio': 0.3396413401420749, 'weight_decay': 0.0035747695907716636, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27888\n",
      "  Number of trainable parameters = 336659459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c994ddf2f0944908251db48a199428e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▅</td></tr><tr><td>eval/loss</td><td>█▁▅</td></tr><tr><td>eval/runtime</td><td>█▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁██</td></tr><tr><td>eval/steps_per_second</td><td>▁██</td></tr><tr><td>train/epoch</td><td>▁▂▃▅▅▇█</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▅▇█</td></tr><tr><td>train/learning_rate</td><td>▁▃▆█</td></tr><tr><td>train/loss</td><td>█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8337</td></tr><tr><td>eval/loss</td><td>0.45913</td></tr><tr><td>eval/runtime</td><td>226.1924</td></tr><tr><td>eval/samples_per_second</td><td>140.876</td></tr><tr><td>eval/steps_per_second</td><td>8.807</td></tr><tr><td>train/epoch</td><td>0.6</td></tr><tr><td>train/global_step</td><td>2400</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.4774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">resilient-shadow-71</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/bkj21q2i\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/bkj21q2i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230111_031453-bkj21q2i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22c3bfd9b8b4a48be5d78b854a8cf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01669952174027761, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230111_034411-3hpfu392</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/3hpfu392\" target=\"_blank\">noble-silence-72</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='27888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4800/27888 58:12 < 4:40:05, 1.37 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.045600</td>\n",
       "      <td>0.544509</td>\n",
       "      <td>0.801318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.505400</td>\n",
       "      <td>0.431221</td>\n",
       "      <td>0.838883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.852691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.385428</td>\n",
       "      <td>0.858622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.383845</td>\n",
       "      <td>0.859062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.477663</td>\n",
       "      <td>0.852973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-800\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-800/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-1600\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-1600/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-1600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-2400\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-2400/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-3200\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-3200/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-3200/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-3200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta_hyperparameter_tune/run-9/checkpoint-4000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-11 04:42:26,359]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='3', objective=0.8718970657461165, hyperparameters={'learning_rate': 3.0301883965385675e-05, 'warmup_ratio': 0.4979655853767051, 'weight_decay': 0.0036690214868301796, 'per_device_train_batch_size': 16})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.hyperparameter_search(direction='maximize',\n",
    "                             backend='optuna',\n",
    "                             n_trials=10,\n",
    "                             hp_space=my_hp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127460\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13944\n",
      "  Number of trainable parameters = 336659459\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msangmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_132651-y2l1ua0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/y2l1ua0g\" target=\"_blank\">result/Large_data_roberta/</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12001' max='13944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12001/13944 4:11:27 < 40:43, 0.80 it/s, Epoch 6.02/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.559950</td>\n",
       "      <td>0.790460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>0.482720</td>\n",
       "      <td>0.820022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.471710</td>\n",
       "      <td>0.831822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.458030</td>\n",
       "      <td>0.844532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.455192</td>\n",
       "      <td>0.847074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.371900</td>\n",
       "      <td>0.459506</td>\n",
       "      <td>0.842398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.398900</td>\n",
       "      <td>0.449689</td>\n",
       "      <td>0.846823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.462132</td>\n",
       "      <td>0.849239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.468862</td>\n",
       "      <td>0.855139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.414123</td>\n",
       "      <td>0.859313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.421173</td>\n",
       "      <td>0.863675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.574655</td>\n",
       "      <td>0.857744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.439579</td>\n",
       "      <td>0.864585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.473406</td>\n",
       "      <td>0.864271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.455115</td>\n",
       "      <td>0.859124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.480610</td>\n",
       "      <td>0.865495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.448538</td>\n",
       "      <td>0.866531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.519533</td>\n",
       "      <td>0.870453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.542756</td>\n",
       "      <td>0.865087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.548962</td>\n",
       "      <td>0.869292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.553490</td>\n",
       "      <td>0.869198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.542255</td>\n",
       "      <td>0.871332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.514826</td>\n",
       "      <td>0.873027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1746' max='1992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1746/1992 03:16 < 00:27, 8.89 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-1000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-1000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-1000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-1500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-1500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-1500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-2000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-2000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-2000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-2500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-2500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-2500/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-3000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-3000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-3500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-3500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-1000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-4000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-4000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-1500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-4500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-4500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-2000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-5000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-5000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-2500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-5500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-5500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-3000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-6000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-6000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-3500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-6500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-6500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-4000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-7000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-7000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-4500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-7500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-7500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-5500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-8000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-8000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-8500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-8500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-6500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-9000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-9000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-7000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-9500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-9500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-7500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-10000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-10000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in result/Large_data_roberta/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-8000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-10500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-10500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-8500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-11000\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-11000/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-9000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/Large_data_roberta/checkpoint-11500\n",
      "Configuration saved in result/Large_data_roberta/checkpoint-11500/config.json\n",
      "Model weights saved in result/Large_data_roberta/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in result/Large_data_roberta/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in result/Large_data_roberta/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [result/Large_data_roberta/checkpoint-9500] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31865\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "# trainer.train()\n",
    "# model.save_pretrained('result/Large_data_roberta/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/centos/.cache/huggingface/hub/models--klue--roberta-large/snapshots/5193b95701189160c45d02a1033a4ea55bdbe259/tokenizer_config.json\n",
      "loading configuration file result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Tokenizer_NAME = \"klue/roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
    "\n",
    "MODEL_NAME = 'result/Large_data_roberta_hyperparameter_tune/run-3/checkpoint-7200'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(tokenizer.vocab_size)\n",
    "model.to(device)\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n",
      "{'input_ids': tensor([    0,   720,  3994,  2052, 10428,  2775,   647,  3657,  2119,  1085,\n",
      "            3,     2,   720,  3994,  2052,   911,  2075,  3669,  2119,  3926,\n",
      "         2088,  1513,  2359, 13964,     2,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(3)}\n",
      "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다 [SEP] 18일 배를 타고 여행을 떠났습니다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "test_label = label_to_num(test['label'].values)\n",
    "\n",
    "tokenized_test = tokenizer(\n",
    "    list(test['premise']),\n",
    "    list(test['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "test_dataset = BERTDataset(tokenized_test, test_label)\n",
    "\n",
    "print(test_dataset.__len__())\n",
    "print(test_dataset.__getitem__(1665))\n",
    "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:07<00:00, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 1, 1, 2, 2, 0, 0, 2, 1, 0, 1, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 2, 0, 0, 0, 2, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 2, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 1, 1, 0, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 0, 2, 1, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 0, 2, 0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 0, 0, 1, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 0, 2, 1, 0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 1, 0, 2, 2, 1, 0, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 1, 2, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 2, 0, 1, 0, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 1, 2, 1, 2, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 1, 2, 2, 2, 2, 1, 0, 0, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 2, 1, 1, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 2, 2, 2, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 2, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 0, 2, 0, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 2, 2, 0, 1, 0, 0, 1, 2, 0, 0, 1, 2, 1, 0, 0, 1, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 1, 2, 1, 0, 2, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 1, 1, 2, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0, 2, 2, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 1, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 1, 0, 0, 2, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 2, 0, 2, 2, 1, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 2, 0, 2, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 2, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 0, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 0, 0, 0, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, 1, 1, 0, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_pred = []\n",
    "output_prob = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=data['input_ids'].to(device),\n",
    "            attention_mask=data['attention_mask'].to(device),\n",
    "            token_type_ids=data['token_type_ids'].to(device)\n",
    "        )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "pred_answer ,output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'contradiction'], [1, 'neutral'], [2, 'entailment'], [3, 'contradiction'], [4, 'contradiction'], [5, 'neutral'], [6, 'neutral'], [7, 'entailment'], [8, 'entailment'], [9, 'neutral'], [10, 'contradiction'], [11, 'entailment'], [12, 'contradiction'], [13, 'entailment'], [14, 'neutral'], [15, 'neutral'], [16, 'neutral'], [17, 'neutral'], [18, 'contradiction'], [19, 'neutral'], [20, 'neutral'], [21, 'neutral'], [22, 'neutral'], [23, 'entailment'], [24, 'contradiction'], [25, 'neutral'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'neutral'], [30, 'contradiction'], [31, 'contradiction'], [32, 'contradiction'], [33, 'neutral'], [34, 'neutral'], [35, 'contradiction'], [36, 'contradiction'], [37, 'contradiction'], [38, 'entailment'], [39, 'contradiction'], [40, 'neutral'], [41, 'entailment'], [42, 'contradiction'], [43, 'neutral'], [44, 'neutral'], [45, 'contradiction'], [46, 'neutral'], [47, 'entailment'], [48, 'contradiction'], [49, 'entailment'], [50, 'neutral'], [51, 'contradiction'], [52, 'contradiction'], [53, 'neutral'], [54, 'neutral'], [55, 'entailment'], [56, 'neutral'], [57, 'neutral'], [58, 'neutral'], [59, 'neutral'], [60, 'entailment'], [61, 'neutral'], [62, 'neutral'], [63, 'neutral'], [64, 'neutral'], [65, 'contradiction'], [66, 'neutral'], [67, 'neutral'], [68, 'neutral'], [69, 'contradiction'], [70, 'entailment'], [71, 'neutral'], [72, 'entailment'], [73, 'contradiction'], [74, 'neutral'], [75, 'neutral'], [76, 'entailment'], [77, 'neutral'], [78, 'neutral'], [79, 'neutral'], [80, 'contradiction'], [81, 'contradiction'], [82, 'contradiction'], [83, 'entailment'], [84, 'entailment'], [85, 'contradiction'], [86, 'neutral'], [87, 'contradiction'], [88, 'entailment'], [89, 'neutral'], [90, 'contradiction'], [91, 'neutral'], [92, 'entailment'], [93, 'contradiction'], [94, 'entailment'], [95, 'neutral'], [96, 'contradiction'], [97, 'contradiction'], [98, 'entailment'], [99, 'neutral'], [100, 'neutral'], [101, 'entailment'], [102, 'neutral'], [103, 'entailment'], [104, 'neutral'], [105, 'entailment'], [106, 'neutral'], [107, 'neutral'], [108, 'contradiction'], [109, 'entailment'], [110, 'contradiction'], [111, 'neutral'], [112, 'contradiction'], [113, 'entailment'], [114, 'neutral'], [115, 'contradiction'], [116, 'contradiction'], [117, 'contradiction'], [118, 'contradiction'], [119, 'contradiction'], [120, 'contradiction'], [121, 'contradiction'], [122, 'contradiction'], [123, 'neutral'], [124, 'entailment'], [125, 'entailment'], [126, 'entailment'], [127, 'contradiction'], [128, 'contradiction'], [129, 'neutral'], [130, 'contradiction'], [131, 'neutral'], [132, 'contradiction'], [133, 'entailment'], [134, 'neutral'], [135, 'entailment'], [136, 'entailment'], [137, 'neutral'], [138, 'contradiction'], [139, 'contradiction'], [140, 'neutral'], [141, 'neutral'], [142, 'neutral'], [143, 'entailment'], [144, 'neutral'], [145, 'contradiction'], [146, 'entailment'], [147, 'contradiction'], [148, 'neutral'], [149, 'neutral'], [150, 'contradiction'], [151, 'entailment'], [152, 'contradiction'], [153, 'neutral'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'neutral'], [158, 'neutral'], [159, 'contradiction'], [160, 'entailment'], [161, 'entailment'], [162, 'neutral'], [163, 'entailment'], [164, 'neutral'], [165, 'contradiction'], [166, 'neutral'], [167, 'entailment'], [168, 'neutral'], [169, 'entailment'], [170, 'neutral'], [171, 'neutral'], [172, 'entailment'], [173, 'neutral'], [174, 'neutral'], [175, 'neutral'], [176, 'neutral'], [177, 'neutral'], [178, 'contradiction'], [179, 'contradiction'], [180, 'contradiction'], [181, 'neutral'], [182, 'neutral'], [183, 'neutral'], [184, 'neutral'], [185, 'neutral'], [186, 'contradiction'], [187, 'neutral'], [188, 'entailment'], [189, 'contradiction'], [190, 'entailment'], [191, 'entailment'], [192, 'contradiction'], [193, 'entailment'], [194, 'neutral'], [195, 'entailment'], [196, 'neutral'], [197, 'neutral'], [198, 'entailment'], [199, 'neutral'], [200, 'neutral'], [201, 'neutral'], [202, 'entailment'], [203, 'contradiction'], [204, 'contradiction'], [205, 'entailment'], [206, 'neutral'], [207, 'neutral'], [208, 'entailment'], [209, 'neutral'], [210, 'contradiction'], [211, 'contradiction'], [212, 'contradiction'], [213, 'neutral'], [214, 'contradiction'], [215, 'contradiction'], [216, 'contradiction'], [217, 'entailment'], [218, 'contradiction'], [219, 'contradiction'], [220, 'neutral'], [221, 'neutral'], [222, 'entailment'], [223, 'contradiction'], [224, 'neutral'], [225, 'neutral'], [226, 'contradiction'], [227, 'neutral'], [228, 'contradiction'], [229, 'neutral'], [230, 'entailment'], [231, 'neutral'], [232, 'entailment'], [233, 'entailment'], [234, 'entailment'], [235, 'neutral'], [236, 'neutral'], [237, 'contradiction'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'contradiction'], [242, 'neutral'], [243, 'neutral'], [244, 'neutral'], [245, 'entailment'], [246, 'neutral'], [247, 'neutral'], [248, 'contradiction'], [249, 'neutral'], [250, 'entailment'], [251, 'contradiction'], [252, 'neutral'], [253, 'entailment'], [254, 'neutral'], [255, 'neutral'], [256, 'contradiction'], [257, 'contradiction'], [258, 'entailment'], [259, 'entailment'], [260, 'contradiction'], [261, 'entailment'], [262, 'neutral'], [263, 'neutral'], [264, 'neutral'], [265, 'neutral'], [266, 'entailment'], [267, 'neutral'], [268, 'neutral'], [269, 'entailment'], [270, 'neutral'], [271, 'neutral'], [272, 'entailment'], [273, 'entailment'], [274, 'neutral'], [275, 'contradiction'], [276, 'contradiction'], [277, 'contradiction'], [278, 'neutral'], [279, 'neutral'], [280, 'neutral'], [281, 'entailment'], [282, 'entailment'], [283, 'entailment'], [284, 'contradiction'], [285, 'entailment'], [286, 'neutral'], [287, 'contradiction'], [288, 'entailment'], [289, 'neutral'], [290, 'entailment'], [291, 'contradiction'], [292, 'entailment'], [293, 'contradiction'], [294, 'entailment'], [295, 'contradiction'], [296, 'contradiction'], [297, 'contradiction'], [298, 'neutral'], [299, 'entailment'], [300, 'neutral'], [301, 'entailment'], [302, 'neutral'], [303, 'entailment'], [304, 'contradiction'], [305, 'entailment'], [306, 'neutral'], [307, 'contradiction'], [308, 'contradiction'], [309, 'entailment'], [310, 'entailment'], [311, 'contradiction'], [312, 'contradiction'], [313, 'neutral'], [314, 'neutral'], [315, 'neutral'], [316, 'neutral'], [317, 'neutral'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'neutral'], [322, 'neutral'], [323, 'entailment'], [324, 'contradiction'], [325, 'neutral'], [326, 'contradiction'], [327, 'neutral'], [328, 'contradiction'], [329, 'contradiction'], [330, 'neutral'], [331, 'entailment'], [332, 'entailment'], [333, 'contradiction'], [334, 'contradiction'], [335, 'contradiction'], [336, 'entailment'], [337, 'contradiction'], [338, 'contradiction'], [339, 'neutral'], [340, 'contradiction'], [341, 'neutral'], [342, 'contradiction'], [343, 'contradiction'], [344, 'neutral'], [345, 'entailment'], [346, 'contradiction'], [347, 'contradiction'], [348, 'contradiction'], [349, 'neutral'], [350, 'contradiction'], [351, 'neutral'], [352, 'contradiction'], [353, 'neutral'], [354, 'neutral'], [355, 'contradiction'], [356, 'neutral'], [357, 'entailment'], [358, 'contradiction'], [359, 'neutral'], [360, 'contradiction'], [361, 'contradiction'], [362, 'neutral'], [363, 'neutral'], [364, 'contradiction'], [365, 'neutral'], [366, 'neutral'], [367, 'entailment'], [368, 'contradiction'], [369, 'neutral'], [370, 'contradiction'], [371, 'contradiction'], [372, 'entailment'], [373, 'neutral'], [374, 'neutral'], [375, 'entailment'], [376, 'entailment'], [377, 'neutral'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'neutral'], [382, 'contradiction'], [383, 'neutral'], [384, 'entailment'], [385, 'neutral'], [386, 'entailment'], [387, 'entailment'], [388, 'neutral'], [389, 'contradiction'], [390, 'neutral'], [391, 'entailment'], [392, 'contradiction'], [393, 'contradiction'], [394, 'contradiction'], [395, 'contradiction'], [396, 'entailment'], [397, 'neutral'], [398, 'contradiction'], [399, 'entailment'], [400, 'contradiction'], [401, 'neutral'], [402, 'contradiction'], [403, 'contradiction'], [404, 'entailment'], [405, 'neutral'], [406, 'neutral'], [407, 'neutral'], [408, 'contradiction'], [409, 'neutral'], [410, 'contradiction'], [411, 'contradiction'], [412, 'contradiction'], [413, 'contradiction'], [414, 'neutral'], [415, 'contradiction'], [416, 'contradiction'], [417, 'entailment'], [418, 'neutral'], [419, 'contradiction'], [420, 'neutral'], [421, 'neutral'], [422, 'entailment'], [423, 'neutral'], [424, 'entailment'], [425, 'neutral'], [426, 'neutral'], [427, 'contradiction'], [428, 'contradiction'], [429, 'contradiction'], [430, 'entailment'], [431, 'neutral'], [432, 'contradiction'], [433, 'neutral'], [434, 'entailment'], [435, 'neutral'], [436, 'neutral'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'entailment'], [442, 'entailment'], [443, 'neutral'], [444, 'contradiction'], [445, 'neutral'], [446, 'neutral'], [447, 'entailment'], [448, 'neutral'], [449, 'contradiction'], [450, 'contradiction'], [451, 'entailment'], [452, 'entailment'], [453, 'contradiction'], [454, 'contradiction'], [455, 'entailment'], [456, 'neutral'], [457, 'contradiction'], [458, 'neutral'], [459, 'contradiction'], [460, 'entailment'], [461, 'entailment'], [462, 'contradiction'], [463, 'neutral'], [464, 'contradiction'], [465, 'contradiction'], [466, 'contradiction'], [467, 'neutral'], [468, 'entailment'], [469, 'neutral'], [470, 'contradiction'], [471, 'contradiction'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'contradiction'], [476, 'entailment'], [477, 'contradiction'], [478, 'entailment'], [479, 'contradiction'], [480, 'entailment'], [481, 'entailment'], [482, 'contradiction'], [483, 'entailment'], [484, 'neutral'], [485, 'contradiction'], [486, 'entailment'], [487, 'neutral'], [488, 'contradiction'], [489, 'entailment'], [490, 'entailment'], [491, 'neutral'], [492, 'neutral'], [493, 'neutral'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'neutral'], [498, 'neutral'], [499, 'contradiction'], [500, 'entailment'], [501, 'entailment'], [502, 'neutral'], [503, 'contradiction'], [504, 'contradiction'], [505, 'entailment'], [506, 'neutral'], [507, 'contradiction'], [508, 'entailment'], [509, 'contradiction'], [510, 'neutral'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'entailment'], [515, 'contradiction'], [516, 'neutral'], [517, 'entailment'], [518, 'contradiction'], [519, 'contradiction'], [520, 'neutral'], [521, 'neutral'], [522, 'contradiction'], [523, 'neutral'], [524, 'neutral'], [525, 'contradiction'], [526, 'entailment'], [527, 'entailment'], [528, 'contradiction'], [529, 'entailment'], [530, 'neutral'], [531, 'neutral'], [532, 'contradiction'], [533, 'entailment'], [534, 'neutral'], [535, 'contradiction'], [536, 'contradiction'], [537, 'contradiction'], [538, 'neutral'], [539, 'neutral'], [540, 'neutral'], [541, 'contradiction'], [542, 'contradiction'], [543, 'entailment'], [544, 'contradiction'], [545, 'neutral'], [546, 'contradiction'], [547, 'entailment'], [548, 'neutral'], [549, 'entailment'], [550, 'neutral'], [551, 'contradiction'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'neutral'], [556, 'contradiction'], [557, 'neutral'], [558, 'neutral'], [559, 'contradiction'], [560, 'contradiction'], [561, 'contradiction'], [562, 'neutral'], [563, 'neutral'], [564, 'entailment'], [565, 'neutral'], [566, 'entailment'], [567, 'entailment'], [568, 'neutral'], [569, 'contradiction'], [570, 'entailment'], [571, 'entailment'], [572, 'entailment'], [573, 'contradiction'], [574, 'entailment'], [575, 'contradiction'], [576, 'entailment'], [577, 'neutral'], [578, 'contradiction'], [579, 'neutral'], [580, 'contradiction'], [581, 'entailment'], [582, 'entailment'], [583, 'neutral'], [584, 'entailment'], [585, 'entailment'], [586, 'neutral'], [587, 'entailment'], [588, 'contradiction'], [589, 'entailment'], [590, 'entailment'], [591, 'neutral'], [592, 'contradiction'], [593, 'entailment'], [594, 'contradiction'], [595, 'contradiction'], [596, 'contradiction'], [597, 'neutral'], [598, 'entailment'], [599, 'entailment'], [600, 'contradiction'], [601, 'neutral'], [602, 'contradiction'], [603, 'entailment'], [604, 'neutral'], [605, 'neutral'], [606, 'contradiction'], [607, 'contradiction'], [608, 'contradiction'], [609, 'contradiction'], [610, 'contradiction'], [611, 'entailment'], [612, 'neutral'], [613, 'entailment'], [614, 'contradiction'], [615, 'contradiction'], [616, 'neutral'], [617, 'neutral'], [618, 'contradiction'], [619, 'neutral'], [620, 'contradiction'], [621, 'neutral'], [622, 'entailment'], [623, 'contradiction'], [624, 'contradiction'], [625, 'contradiction'], [626, 'contradiction'], [627, 'contradiction'], [628, 'neutral'], [629, 'entailment'], [630, 'contradiction'], [631, 'entailment'], [632, 'neutral'], [633, 'entailment'], [634, 'neutral'], [635, 'entailment'], [636, 'contradiction'], [637, 'entailment'], [638, 'entailment'], [639, 'neutral'], [640, 'contradiction'], [641, 'entailment'], [642, 'contradiction'], [643, 'entailment'], [644, 'neutral'], [645, 'entailment'], [646, 'neutral'], [647, 'contradiction'], [648, 'contradiction'], [649, 'neutral'], [650, 'entailment'], [651, 'contradiction'], [652, 'contradiction'], [653, 'entailment'], [654, 'neutral'], [655, 'neutral'], [656, 'entailment'], [657, 'contradiction'], [658, 'entailment'], [659, 'contradiction'], [660, 'neutral'], [661, 'contradiction'], [662, 'neutral'], [663, 'neutral'], [664, 'entailment'], [665, 'contradiction'], [666, 'contradiction'], [667, 'entailment'], [668, 'neutral'], [669, 'neutral'], [670, 'neutral'], [671, 'contradiction'], [672, 'neutral'], [673, 'contradiction'], [674, 'neutral'], [675, 'entailment'], [676, 'neutral'], [677, 'neutral'], [678, 'contradiction'], [679, 'contradiction'], [680, 'neutral'], [681, 'contradiction'], [682, 'entailment'], [683, 'contradiction'], [684, 'neutral'], [685, 'contradiction'], [686, 'entailment'], [687, 'neutral'], [688, 'entailment'], [689, 'entailment'], [690, 'neutral'], [691, 'entailment'], [692, 'entailment'], [693, 'neutral'], [694, 'entailment'], [695, 'entailment'], [696, 'entailment'], [697, 'contradiction'], [698, 'entailment'], [699, 'entailment'], [700, 'contradiction'], [701, 'entailment'], [702, 'entailment'], [703, 'neutral'], [704, 'entailment'], [705, 'entailment'], [706, 'contradiction'], [707, 'contradiction'], [708, 'neutral'], [709, 'contradiction'], [710, 'neutral'], [711, 'entailment'], [712, 'neutral'], [713, 'entailment'], [714, 'entailment'], [715, 'entailment'], [716, 'contradiction'], [717, 'neutral'], [718, 'neutral'], [719, 'entailment'], [720, 'entailment'], [721, 'neutral'], [722, 'neutral'], [723, 'contradiction'], [724, 'entailment'], [725, 'contradiction'], [726, 'neutral'], [727, 'contradiction'], [728, 'contradiction'], [729, 'entailment'], [730, 'entailment'], [731, 'neutral'], [732, 'entailment'], [733, 'neutral'], [734, 'entailment'], [735, 'neutral'], [736, 'contradiction'], [737, 'neutral'], [738, 'entailment'], [739, 'entailment'], [740, 'neutral'], [741, 'contradiction'], [742, 'entailment'], [743, 'entailment'], [744, 'contradiction'], [745, 'neutral'], [746, 'neutral'], [747, 'contradiction'], [748, 'neutral'], [749, 'neutral'], [750, 'neutral'], [751, 'contradiction'], [752, 'neutral'], [753, 'entailment'], [754, 'entailment'], [755, 'neutral'], [756, 'entailment'], [757, 'contradiction'], [758, 'neutral'], [759, 'neutral'], [760, 'entailment'], [761, 'neutral'], [762, 'entailment'], [763, 'contradiction'], [764, 'neutral'], [765, 'entailment'], [766, 'neutral'], [767, 'entailment'], [768, 'contradiction'], [769, 'neutral'], [770, 'contradiction'], [771, 'neutral'], [772, 'entailment'], [773, 'contradiction'], [774, 'entailment'], [775, 'neutral'], [776, 'contradiction'], [777, 'entailment'], [778, 'neutral'], [779, 'neutral'], [780, 'entailment'], [781, 'neutral'], [782, 'contradiction'], [783, 'neutral'], [784, 'entailment'], [785, 'entailment'], [786, 'contradiction'], [787, 'contradiction'], [788, 'entailment'], [789, 'contradiction'], [790, 'entailment'], [791, 'neutral'], [792, 'entailment'], [793, 'neutral'], [794, 'neutral'], [795, 'entailment'], [796, 'contradiction'], [797, 'entailment'], [798, 'entailment'], [799, 'neutral'], [800, 'entailment'], [801, 'neutral'], [802, 'entailment'], [803, 'neutral'], [804, 'contradiction'], [805, 'contradiction'], [806, 'entailment'], [807, 'entailment'], [808, 'contradiction'], [809, 'contradiction'], [810, 'entailment'], [811, 'contradiction'], [812, 'contradiction'], [813, 'neutral'], [814, 'neutral'], [815, 'neutral'], [816, 'entailment'], [817, 'neutral'], [818, 'neutral'], [819, 'entailment'], [820, 'neutral'], [821, 'neutral'], [822, 'contradiction'], [823, 'neutral'], [824, 'neutral'], [825, 'neutral'], [826, 'contradiction'], [827, 'neutral'], [828, 'contradiction'], [829, 'entailment'], [830, 'entailment'], [831, 'contradiction'], [832, 'contradiction'], [833, 'entailment'], [834, 'neutral'], [835, 'contradiction'], [836, 'entailment'], [837, 'contradiction'], [838, 'neutral'], [839, 'contradiction'], [840, 'contradiction'], [841, 'neutral'], [842, 'contradiction'], [843, 'entailment'], [844, 'neutral'], [845, 'neutral'], [846, 'contradiction'], [847, 'contradiction'], [848, 'entailment'], [849, 'neutral'], [850, 'neutral'], [851, 'contradiction'], [852, 'entailment'], [853, 'neutral'], [854, 'contradiction'], [855, 'entailment'], [856, 'entailment'], [857, 'neutral'], [858, 'contradiction'], [859, 'entailment'], [860, 'contradiction'], [861, 'neutral'], [862, 'contradiction'], [863, 'neutral'], [864, 'neutral'], [865, 'entailment'], [866, 'entailment'], [867, 'contradiction'], [868, 'contradiction'], [869, 'neutral'], [870, 'contradiction'], [871, 'neutral'], [872, 'entailment'], [873, 'entailment'], [874, 'neutral'], [875, 'contradiction'], [876, 'entailment'], [877, 'contradiction'], [878, 'neutral'], [879, 'neutral'], [880, 'neutral'], [881, 'neutral'], [882, 'contradiction'], [883, 'entailment'], [884, 'entailment'], [885, 'contradiction'], [886, 'neutral'], [887, 'neutral'], [888, 'entailment'], [889, 'neutral'], [890, 'entailment'], [891, 'contradiction'], [892, 'entailment'], [893, 'entailment'], [894, 'contradiction'], [895, 'neutral'], [896, 'entailment'], [897, 'neutral'], [898, 'entailment'], [899, 'entailment'], [900, 'contradiction'], [901, 'neutral'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'neutral'], [906, 'contradiction'], [907, 'contradiction'], [908, 'entailment'], [909, 'entailment'], [910, 'neutral'], [911, 'neutral'], [912, 'neutral'], [913, 'entailment'], [914, 'neutral'], [915, 'neutral'], [916, 'contradiction'], [917, 'contradiction'], [918, 'neutral'], [919, 'entailment'], [920, 'neutral'], [921, 'entailment'], [922, 'entailment'], [923, 'entailment'], [924, 'neutral'], [925, 'contradiction'], [926, 'entailment'], [927, 'entailment'], [928, 'entailment'], [929, 'entailment'], [930, 'neutral'], [931, 'entailment'], [932, 'neutral'], [933, 'neutral'], [934, 'contradiction'], [935, 'contradiction'], [936, 'entailment'], [937, 'contradiction'], [938, 'entailment'], [939, 'contradiction'], [940, 'entailment'], [941, 'entailment'], [942, 'contradiction'], [943, 'contradiction'], [944, 'neutral'], [945, 'entailment'], [946, 'entailment'], [947, 'neutral'], [948, 'neutral'], [949, 'entailment'], [950, 'contradiction'], [951, 'neutral'], [952, 'contradiction'], [953, 'contradiction'], [954, 'contradiction'], [955, 'neutral'], [956, 'neutral'], [957, 'entailment'], [958, 'contradiction'], [959, 'contradiction'], [960, 'neutral'], [961, 'contradiction'], [962, 'contradiction'], [963, 'contradiction'], [964, 'entailment'], [965, 'entailment'], [966, 'contradiction'], [967, 'entailment'], [968, 'entailment'], [969, 'contradiction'], [970, 'entailment'], [971, 'entailment'], [972, 'neutral'], [973, 'contradiction'], [974, 'contradiction'], [975, 'entailment'], [976, 'entailment'], [977, 'neutral'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'neutral'], [982, 'entailment'], [983, 'contradiction'], [984, 'neutral'], [985, 'neutral'], [986, 'contradiction'], [987, 'contradiction'], [988, 'neutral'], [989, 'contradiction'], [990, 'entailment'], [991, 'entailment'], [992, 'neutral'], [993, 'contradiction'], [994, 'neutral'], [995, 'neutral'], [996, 'neutral'], [997, 'contradiction'], [998, 'entailment'], [999, 'entailment'], [1000, 'neutral'], [1001, 'entailment'], [1002, 'contradiction'], [1003, 'neutral'], [1004, 'neutral'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'neutral'], [1009, 'neutral'], [1010, 'neutral'], [1011, 'entailment'], [1012, 'neutral'], [1013, 'contradiction'], [1014, 'neutral'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'contradiction'], [1019, 'contradiction'], [1020, 'entailment'], [1021, 'neutral'], [1022, 'neutral'], [1023, 'contradiction'], [1024, 'entailment'], [1025, 'neutral'], [1026, 'neutral'], [1027, 'neutral'], [1028, 'contradiction'], [1029, 'contradiction'], [1030, 'entailment'], [1031, 'neutral'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'neutral'], [1035, 'contradiction'], [1036, 'neutral'], [1037, 'contradiction'], [1038, 'contradiction'], [1039, 'contradiction'], [1040, 'contradiction'], [1041, 'neutral'], [1042, 'contradiction'], [1043, 'entailment'], [1044, 'contradiction'], [1045, 'neutral'], [1046, 'neutral'], [1047, 'contradiction'], [1048, 'entailment'], [1049, 'contradiction'], [1050, 'entailment'], [1051, 'contradiction'], [1052, 'entailment'], [1053, 'contradiction'], [1054, 'neutral'], [1055, 'entailment'], [1056, 'contradiction'], [1057, 'neutral'], [1058, 'entailment'], [1059, 'neutral'], [1060, 'contradiction'], [1061, 'contradiction'], [1062, 'contradiction'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'neutral'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'neutral'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'neutral'], [1073, 'neutral'], [1074, 'entailment'], [1075, 'contradiction'], [1076, 'entailment'], [1077, 'neutral'], [1078, 'contradiction'], [1079, 'entailment'], [1080, 'neutral'], [1081, 'contradiction'], [1082, 'contradiction'], [1083, 'contradiction'], [1084, 'neutral'], [1085, 'contradiction'], [1086, 'neutral'], [1087, 'entailment'], [1088, 'contradiction'], [1089, 'neutral'], [1090, 'entailment'], [1091, 'neutral'], [1092, 'contradiction'], [1093, 'contradiction'], [1094, 'neutral'], [1095, 'neutral'], [1096, 'entailment'], [1097, 'neutral'], [1098, 'neutral'], [1099, 'contradiction'], [1100, 'entailment'], [1101, 'contradiction'], [1102, 'entailment'], [1103, 'entailment'], [1104, 'neutral'], [1105, 'entailment'], [1106, 'contradiction'], [1107, 'contradiction'], [1108, 'entailment'], [1109, 'contradiction'], [1110, 'contradiction'], [1111, 'contradiction'], [1112, 'contradiction'], [1113, 'contradiction'], [1114, 'neutral'], [1115, 'neutral'], [1116, 'neutral'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'contradiction'], [1120, 'contradiction'], [1121, 'entailment'], [1122, 'neutral'], [1123, 'contradiction'], [1124, 'neutral'], [1125, 'neutral'], [1126, 'entailment'], [1127, 'contradiction'], [1128, 'neutral'], [1129, 'contradiction'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'contradiction'], [1133, 'contradiction'], [1134, 'contradiction'], [1135, 'contradiction'], [1136, 'contradiction'], [1137, 'contradiction'], [1138, 'contradiction'], [1139, 'entailment'], [1140, 'entailment'], [1141, 'contradiction'], [1142, 'contradiction'], [1143, 'contradiction'], [1144, 'entailment'], [1145, 'neutral'], [1146, 'entailment'], [1147, 'neutral'], [1148, 'entailment'], [1149, 'contradiction'], [1150, 'entailment'], [1151, 'contradiction'], [1152, 'neutral'], [1153, 'entailment'], [1154, 'entailment'], [1155, 'neutral'], [1156, 'neutral'], [1157, 'entailment'], [1158, 'neutral'], [1159, 'neutral'], [1160, 'entailment'], [1161, 'contradiction'], [1162, 'contradiction'], [1163, 'neutral'], [1164, 'neutral'], [1165, 'entailment'], [1166, 'neutral'], [1167, 'entailment'], [1168, 'neutral'], [1169, 'neutral'], [1170, 'contradiction'], [1171, 'neutral'], [1172, 'contradiction'], [1173, 'neutral'], [1174, 'neutral'], [1175, 'entailment'], [1176, 'neutral'], [1177, 'neutral'], [1178, 'neutral'], [1179, 'contradiction'], [1180, 'neutral'], [1181, 'entailment'], [1182, 'contradiction'], [1183, 'neutral'], [1184, 'entailment'], [1185, 'neutral'], [1186, 'neutral'], [1187, 'neutral'], [1188, 'entailment'], [1189, 'contradiction'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'contradiction'], [1193, 'neutral'], [1194, 'entailment'], [1195, 'entailment'], [1196, 'contradiction'], [1197, 'neutral'], [1198, 'contradiction'], [1199, 'entailment'], [1200, 'entailment'], [1201, 'contradiction'], [1202, 'entailment'], [1203, 'neutral'], [1204, 'neutral'], [1205, 'neutral'], [1206, 'contradiction'], [1207, 'contradiction'], [1208, 'entailment'], [1209, 'contradiction'], [1210, 'neutral'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'contradiction'], [1214, 'neutral'], [1215, 'contradiction'], [1216, 'neutral'], [1217, 'entailment'], [1218, 'neutral'], [1219, 'neutral'], [1220, 'neutral'], [1221, 'contradiction'], [1222, 'contradiction'], [1223, 'neutral'], [1224, 'entailment'], [1225, 'contradiction'], [1226, 'contradiction'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'neutral'], [1230, 'contradiction'], [1231, 'contradiction'], [1232, 'entailment'], [1233, 'contradiction'], [1234, 'contradiction'], [1235, 'neutral'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'neutral'], [1240, 'neutral'], [1241, 'neutral'], [1242, 'neutral'], [1243, 'neutral'], [1244, 'entailment'], [1245, 'contradiction'], [1246, 'contradiction'], [1247, 'contradiction'], [1248, 'neutral'], [1249, 'entailment'], [1250, 'neutral'], [1251, 'entailment'], [1252, 'neutral'], [1253, 'contradiction'], [1254, 'neutral'], [1255, 'contradiction'], [1256, 'entailment'], [1257, 'neutral'], [1258, 'contradiction'], [1259, 'entailment'], [1260, 'neutral'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'neutral'], [1264, 'neutral'], [1265, 'neutral'], [1266, 'entailment'], [1267, 'entailment'], [1268, 'contradiction'], [1269, 'contradiction'], [1270, 'neutral'], [1271, 'entailment'], [1272, 'contradiction'], [1273, 'entailment'], [1274, 'contradiction'], [1275, 'neutral'], [1276, 'neutral'], [1277, 'entailment'], [1278, 'contradiction'], [1279, 'entailment'], [1280, 'contradiction'], [1281, 'entailment'], [1282, 'contradiction'], [1283, 'entailment'], [1284, 'neutral'], [1285, 'entailment'], [1286, 'contradiction'], [1287, 'neutral'], [1288, 'entailment'], [1289, 'neutral'], [1290, 'neutral'], [1291, 'neutral'], [1292, 'neutral'], [1293, 'neutral'], [1294, 'entailment'], [1295, 'contradiction'], [1296, 'contradiction'], [1297, 'neutral'], [1298, 'contradiction'], [1299, 'neutral'], [1300, 'contradiction'], [1301, 'neutral'], [1302, 'entailment'], [1303, 'neutral'], [1304, 'neutral'], [1305, 'neutral'], [1306, 'contradiction'], [1307, 'neutral'], [1308, 'contradiction'], [1309, 'contradiction'], [1310, 'neutral'], [1311, 'contradiction'], [1312, 'contradiction'], [1313, 'neutral'], [1314, 'entailment'], [1315, 'neutral'], [1316, 'neutral'], [1317, 'entailment'], [1318, 'neutral'], [1319, 'contradiction'], [1320, 'entailment'], [1321, 'entailment'], [1322, 'neutral'], [1323, 'contradiction'], [1324, 'entailment'], [1325, 'neutral'], [1326, 'entailment'], [1327, 'contradiction'], [1328, 'neutral'], [1329, 'contradiction'], [1330, 'neutral'], [1331, 'neutral'], [1332, 'contradiction'], [1333, 'neutral'], [1334, 'contradiction'], [1335, 'neutral'], [1336, 'contradiction'], [1337, 'entailment'], [1338, 'entailment'], [1339, 'neutral'], [1340, 'neutral'], [1341, 'contradiction'], [1342, 'entailment'], [1343, 'neutral'], [1344, 'entailment'], [1345, 'contradiction'], [1346, 'contradiction'], [1347, 'entailment'], [1348, 'contradiction'], [1349, 'neutral'], [1350, 'neutral'], [1351, 'neutral'], [1352, 'contradiction'], [1353, 'entailment'], [1354, 'neutral'], [1355, 'contradiction'], [1356, 'contradiction'], [1357, 'contradiction'], [1358, 'entailment'], [1359, 'contradiction'], [1360, 'neutral'], [1361, 'contradiction'], [1362, 'neutral'], [1363, 'neutral'], [1364, 'neutral'], [1365, 'neutral'], [1366, 'contradiction'], [1367, 'contradiction'], [1368, 'entailment'], [1369, 'entailment'], [1370, 'neutral'], [1371, 'contradiction'], [1372, 'neutral'], [1373, 'contradiction'], [1374, 'neutral'], [1375, 'neutral'], [1376, 'neutral'], [1377, 'contradiction'], [1378, 'entailment'], [1379, 'contradiction'], [1380, 'contradiction'], [1381, 'neutral'], [1382, 'neutral'], [1383, 'entailment'], [1384, 'contradiction'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'contradiction'], [1388, 'neutral'], [1389, 'contradiction'], [1390, 'entailment'], [1391, 'neutral'], [1392, 'neutral'], [1393, 'neutral'], [1394, 'entailment'], [1395, 'neutral'], [1396, 'entailment'], [1397, 'entailment'], [1398, 'entailment'], [1399, 'neutral'], [1400, 'neutral'], [1401, 'contradiction'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'contradiction'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'contradiction'], [1409, 'contradiction'], [1410, 'contradiction'], [1411, 'neutral'], [1412, 'neutral'], [1413, 'entailment'], [1414, 'contradiction'], [1415, 'neutral'], [1416, 'neutral'], [1417, 'contradiction'], [1418, 'entailment'], [1419, 'entailment'], [1420, 'neutral'], [1421, 'contradiction'], [1422, 'contradiction'], [1423, 'entailment'], [1424, 'neutral'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'contradiction'], [1428, 'neutral'], [1429, 'neutral'], [1430, 'contradiction'], [1431, 'neutral'], [1432, 'neutral'], [1433, 'entailment'], [1434, 'neutral'], [1435, 'neutral'], [1436, 'contradiction'], [1437, 'entailment'], [1438, 'neutral'], [1439, 'contradiction'], [1440, 'contradiction'], [1441, 'entailment'], [1442, 'contradiction'], [1443, 'entailment'], [1444, 'entailment'], [1445, 'contradiction'], [1446, 'contradiction'], [1447, 'neutral'], [1448, 'contradiction'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'neutral'], [1452, 'entailment'], [1453, 'neutral'], [1454, 'entailment'], [1455, 'contradiction'], [1456, 'contradiction'], [1457, 'neutral'], [1458, 'neutral'], [1459, 'neutral'], [1460, 'contradiction'], [1461, 'neutral'], [1462, 'contradiction'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'contradiction'], [1466, 'contradiction'], [1467, 'neutral'], [1468, 'neutral'], [1469, 'contradiction'], [1470, 'entailment'], [1471, 'contradiction'], [1472, 'neutral'], [1473, 'contradiction'], [1474, 'entailment'], [1475, 'neutral'], [1476, 'neutral'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'contradiction'], [1480, 'contradiction'], [1481, 'contradiction'], [1482, 'contradiction'], [1483, 'neutral'], [1484, 'entailment'], [1485, 'neutral'], [1486, 'neutral'], [1487, 'contradiction'], [1488, 'contradiction'], [1489, 'entailment'], [1490, 'neutral'], [1491, 'entailment'], [1492, 'neutral'], [1493, 'entailment'], [1494, 'neutral'], [1495, 'entailment'], [1496, 'contradiction'], [1497, 'contradiction'], [1498, 'entailment'], [1499, 'contradiction'], [1500, 'contradiction'], [1501, 'neutral'], [1502, 'contradiction'], [1503, 'entailment'], [1504, 'contradiction'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'entailment'], [1508, 'neutral'], [1509, 'entailment'], [1510, 'entailment'], [1511, 'contradiction'], [1512, 'contradiction'], [1513, 'neutral'], [1514, 'contradiction'], [1515, 'contradiction'], [1516, 'entailment'], [1517, 'neutral'], [1518, 'neutral'], [1519, 'contradiction'], [1520, 'neutral'], [1521, 'contradiction'], [1522, 'neutral'], [1523, 'entailment'], [1524, 'contradiction'], [1525, 'neutral'], [1526, 'neutral'], [1527, 'neutral'], [1528, 'neutral'], [1529, 'contradiction'], [1530, 'neutral'], [1531, 'entailment'], [1532, 'contradiction'], [1533, 'contradiction'], [1534, 'neutral'], [1535, 'contradiction'], [1536, 'neutral'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'neutral'], [1540, 'contradiction'], [1541, 'entailment'], [1542, 'neutral'], [1543, 'neutral'], [1544, 'entailment'], [1545, 'neutral'], [1546, 'neutral'], [1547, 'neutral'], [1548, 'neutral'], [1549, 'neutral'], [1550, 'contradiction'], [1551, 'entailment'], [1552, 'neutral'], [1553, 'entailment'], [1554, 'neutral'], [1555, 'neutral'], [1556, 'entailment'], [1557, 'entailment'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'neutral'], [1561, 'entailment'], [1562, 'neutral'], [1563, 'neutral'], [1564, 'contradiction'], [1565, 'entailment'], [1566, 'contradiction'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'contradiction'], [1570, 'entailment'], [1571, 'contradiction'], [1572, 'entailment'], [1573, 'contradiction'], [1574, 'contradiction'], [1575, 'contradiction'], [1576, 'neutral'], [1577, 'contradiction'], [1578, 'neutral'], [1579, 'neutral'], [1580, 'neutral'], [1581, 'contradiction'], [1582, 'contradiction'], [1583, 'entailment'], [1584, 'neutral'], [1585, 'neutral'], [1586, 'neutral'], [1587, 'neutral'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'contradiction'], [1591, 'entailment'], [1592, 'contradiction'], [1593, 'neutral'], [1594, 'neutral'], [1595, 'neutral'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'entailment'], [1599, 'neutral'], [1600, 'contradiction'], [1601, 'contradiction'], [1602, 'contradiction'], [1603, 'neutral'], [1604, 'entailment'], [1605, 'neutral'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'contradiction'], [1609, 'entailment'], [1610, 'neutral'], [1611, 'neutral'], [1612, 'entailment'], [1613, 'neutral'], [1614, 'entailment'], [1615, 'contradiction'], [1616, 'neutral'], [1617, 'contradiction'], [1618, 'contradiction'], [1619, 'contradiction'], [1620, 'neutral'], [1621, 'entailment'], [1622, 'contradiction'], [1623, 'neutral'], [1624, 'contradiction'], [1625, 'neutral'], [1626, 'neutral'], [1627, 'entailment'], [1628, 'contradiction'], [1629, 'entailment'], [1630, 'contradiction'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'entailment'], [1634, 'neutral'], [1635, 'neutral'], [1636, 'entailment'], [1637, 'contradiction'], [1638, 'contradiction'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'entailment'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'contradiction'], [1645, 'neutral'], [1646, 'contradiction'], [1647, 'neutral'], [1648, 'entailment'], [1649, 'contradiction'], [1650, 'contradiction'], [1651, 'entailment'], [1652, 'neutral'], [1653, 'contradiction'], [1654, 'contradiction'], [1655, 'entailment'], [1656, 'neutral'], [1657, 'contradiction'], [1658, 'neutral'], [1659, 'neutral'], [1660, 'entailment'], [1661, 'neutral'], [1662, 'entailment'], [1663, 'neutral'], [1664, 'neutral'], [1665, 'neutral']]\n"
     ]
    }
   ],
   "source": [
    "def num_to_label(label):\n",
    "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
    "    str_label = []\n",
    "\n",
    "    for i, v in enumerate(label):\n",
    "        str_label.append([i,label_dict[v]])\n",
    "    \n",
    "    return str_label\n",
    "\n",
    "answer = num_to_label(pred_answer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index          label\n",
      "0         0  contradiction\n",
      "1         1        neutral\n",
      "2         2     entailment\n",
      "3         3  contradiction\n",
      "4         4  contradiction\n",
      "...     ...            ...\n",
      "1661   1661        neutral\n",
      "1662   1662     entailment\n",
      "1663   1663        neutral\n",
      "1664   1664        neutral\n",
      "1665   1665        neutral\n",
      "\n",
      "[1666 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
    "\n",
    "df.to_csv('Large_data_roberta_hyperparameter_tune.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "094f33ed2071450d91c60f15b0331e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "095be4a6f89d4603b8a0b314727bd7a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1e6ccdaaa224d05be7928a5aafaab64",
      "max": 751504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5a393fdf1044e6298a258d4bb8fcd84",
      "value": 751504
     }
    },
    "0bbfd5f0ec2d4436a06bb502f8131f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cde98b9a09144b6b25b121ab70b4ff4",
      "placeholder": "​",
      "style": "IPY_MODEL_21f45f4a718446cea0a2ae70c743ba61",
      "value": "Downloading: 100%"
     }
    },
    "0cde98b9a09144b6b25b121ab70b4ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c3fbc303704c62957bd8c329b8024e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fe9d0f2a6924eba82b3502d43030b61",
       "IPY_MODEL_8902ff1c00df45c78d5b02464ee50756",
       "IPY_MODEL_8fdfe2b3e6e64012ac265a462fbcf328"
      ],
      "layout": "IPY_MODEL_ddd8542cdb7c4844b19cb62fa5e5e146"
     }
    },
    "16cd5a8125f64e618585d262ed0dcc39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1809bf6050194337a8a1efd347bf1f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a91d489ae164c8ca4243d06894962fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c5b91e6ae4d46d0b2f099cd1d4c15cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bbfd5f0ec2d4436a06bb502f8131f49",
       "IPY_MODEL_2613deb06698404396c37a2cc26f5dc4",
       "IPY_MODEL_daa90c709c4b46439770068ba936d25f"
      ],
      "layout": "IPY_MODEL_d66d726b5a104734a7bcfa4d5bfd53b2"
     }
    },
    "1ced7dcc914c47788ca51353a2245f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25ef02ee9d634d79b632eb0a5ad0f6fa",
       "IPY_MODEL_095be4a6f89d4603b8a0b314727bd7a4",
       "IPY_MODEL_c3e047157c734a5fbf6a6c8dc27c5913"
      ],
      "layout": "IPY_MODEL_16cd5a8125f64e618585d262ed0dcc39"
     }
    },
    "1d38cc6507084d34a2d41ada6a37b83e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f45f4a718446cea0a2ae70c743ba61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25ef02ee9d634d79b632eb0a5ad0f6fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3560910251ab4451ba5df9bf0953e999",
      "placeholder": "​",
      "style": "IPY_MODEL_c0ef75dc157d4b2a9c881661aa39347c",
      "value": "Downloading: 100%"
     }
    },
    "2613deb06698404396c37a2cc26f5dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3882a8be8ec44b9fb9595d4239c46930",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6e6cbbc9d0e443ca58cdcfe2c44f49e",
      "value": 375
     }
    },
    "27848cf6c21243f99f6421c294e2844f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c17f7168c24bcfbfb6cacf9d8a2b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd3c31a170a431ca04bbeeb641f6590": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341d1f2f2ec34446bcc1049dafda1c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3560910251ab4451ba5df9bf0953e999": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3882a8be8ec44b9fb9595d4239c46930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa68625b6364fdcb47c203b43277941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bebe6d4ba11479c8d6b952c786d5393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f4bd07499745d09d398568221a49aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a046ee54d1d485e84835c858f31be0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c07c3365e984f3596c00edb9cd2c184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cdf8336d32747629b01a6550240c6fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d26fc2e49c4bfaa89415d44a0606ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b541face9d74d2eae19066c55320567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afd8616825be40a8a52b1df11d73c64d",
      "placeholder": "​",
      "style": "IPY_MODEL_341d1f2f2ec34446bcc1049dafda1c82",
      "value": "Downloading: 100%"
     }
    },
    "5fe9d0f2a6924eba82b3502d43030b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3f1a17e1bd642e9b17fa94aff662eda",
      "placeholder": "​",
      "style": "IPY_MODEL_6c7eed7e50f34a1584a9639f26c277fe",
      "value": "Downloading: 100%"
     }
    },
    "683388a3551c4cfc922c56cba867d04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6860bf24436f4e098c668a285fd06f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b541face9d74d2eae19066c55320567",
       "IPY_MODEL_fbabe1a9a00a419b8c5f54375e80d952",
       "IPY_MODEL_f207ba49d03d4d11abd8a50c624eb7c8"
      ],
      "layout": "IPY_MODEL_3aa68625b6364fdcb47c203b43277941"
     }
    },
    "6be5e8971a294d58b173245f74bf1975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cd3c31a170a431ca04bbeeb641f6590",
      "placeholder": "​",
      "style": "IPY_MODEL_77abc577d69e4ca69ff1afe8c3a37d43",
      "value": "Downloading: 100%"
     }
    },
    "6c7eed7e50f34a1584a9639f26c277fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "704b74d3a9a040e9a11e57234af566ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73c789717a3745a9b431931ce845432b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77abc577d69e4ca69ff1afe8c3a37d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7af67cc2ae4b4c3abb9e7a208ecc9fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cb35513245c4927858d1ad05062340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8242b29066ed4717b957c897adba8533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8437c6dcd988498fb32f3d0557bb2385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_accc4b1e20d149aab8385df3109eb92f",
       "IPY_MODEL_9579ee57512f4bfbae9eeaac961ef7cb",
       "IPY_MODEL_a3591cd1d9f04511b42b45cde368fbc7"
      ],
      "layout": "IPY_MODEL_1d38cc6507084d34a2d41ada6a37b83e"
     }
    },
    "86daa3417a4147c4acc5b2cb0aff4935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6be5e8971a294d58b173245f74bf1975",
       "IPY_MODEL_ebdfb09f0319470db6ef22d68916b111",
       "IPY_MODEL_c0c048b2bc734c2a9a05a3195b29b136"
      ],
      "layout": "IPY_MODEL_f2b21dab53e944a58572bbdd6c9c94b0"
     }
    },
    "8902ff1c00df45c78d5b02464ee50756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c17f7168c24bcfbfb6cacf9d8a2b24",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1809bf6050194337a8a1efd347bf1f88",
      "value": 173
     }
    },
    "8fdfe2b3e6e64012ac265a462fbcf328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c40ba97a8a66488cb7b62cf85aead2b5",
      "placeholder": "​",
      "style": "IPY_MODEL_e8da32862f9049ceb6796662fcd4444f",
      "value": " 173/173 [00:00&lt;00:00, 3.16kB/s]"
     }
    },
    "9251c8da568641daacabf3e198c79290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9579ee57512f4bfbae9eeaac961ef7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_094f33ed2071450d91c60f15b0331e8c",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cb35513245c4927858d1ad05062340d",
      "value": 248477
     }
    },
    "a3591cd1d9f04511b42b45cde368fbc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f4bd07499745d09d398568221a49aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e03141fe0ca24aa888dc4ce1734ef897",
      "value": " 248k/248k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "accc4b1e20d149aab8385df3109eb92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c07c3365e984f3596c00edb9cd2c184",
      "placeholder": "​",
      "style": "IPY_MODEL_b18b9e54b8bb47a7ac0d5d4db9cc0946",
      "value": "Downloading: 100%"
     }
    },
    "afd8616825be40a8a52b1df11d73c64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18b9e54b8bb47a7ac0d5d4db9cc0946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1e6ccdaaa224d05be7928a5aafaab64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0c048b2bc734c2a9a05a3195b29b136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9251c8da568641daacabf3e198c79290",
      "placeholder": "​",
      "style": "IPY_MODEL_1a91d489ae164c8ca4243d06894962fa",
      "value": " 1.35G/1.35G [00:20&lt;00:00, 73.7MB/s]"
     }
    },
    "c0ef75dc157d4b2a9c881661aa39347c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3e047157c734a5fbf6a6c8dc27c5913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a046ee54d1d485e84835c858f31be0c",
      "placeholder": "​",
      "style": "IPY_MODEL_57d26fc2e49c4bfaa89415d44a0606ec",
      "value": " 752k/752k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "c40ba97a8a66488cb7b62cf85aead2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a393fdf1044e6298a258d4bb8fcd84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d66d726b5a104734a7bcfa4d5bfd53b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa90c709c4b46439770068ba936d25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cdf8336d32747629b01a6550240c6fe",
      "placeholder": "​",
      "style": "IPY_MODEL_8242b29066ed4717b957c897adba8533",
      "value": " 375/375 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "ddd8542cdb7c4844b19cb62fa5e5e146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e03141fe0ca24aa888dc4ce1734ef897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8da32862f9049ceb6796662fcd4444f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebdfb09f0319470db6ef22d68916b111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c789717a3745a9b431931ce845432b",
      "max": 1346930258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_704b74d3a9a040e9a11e57234af566ea",
      "value": 1346930258
     }
    },
    "f207ba49d03d4d11abd8a50c624eb7c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bebe6d4ba11479c8d6b952c786d5393",
      "placeholder": "​",
      "style": "IPY_MODEL_683388a3551c4cfc922c56cba867d04c",
      "value": " 547/547 [00:00&lt;00:00, 9.70kB/s]"
     }
    },
    "f2b21dab53e944a58572bbdd6c9c94b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f1a17e1bd642e9b17fa94aff662eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6e6cbbc9d0e443ca58cdcfe2c44f49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbabe1a9a00a419b8c5f54375e80d952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27848cf6c21243f99f6421c294e2844f",
      "max": 547,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7af67cc2ae4b4c3abb9e7a208ecc9fd5",
      "value": 547
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
