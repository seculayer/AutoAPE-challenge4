{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHIlMelgbWeC"
      },
      "outputs": [],
      "source": [
        "# https://dacon.io/competitions/official/235951/codeshare/6628?page=1&dtype=recent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c09TDARFf7t"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/이미지_3D.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "import h5py\n",
        "import os\n",
        "import csv"
      ],
      "metadata": {
        "id": "1RX1ilIrKi47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class H5DataLoader:\n",
        "    def __init__(self, data_path, mode='train', img_size=256):\n",
        "        self.it = 0\n",
        "        self.mode = mode\n",
        "        self.label = None\n",
        "        if mode == 'train':\n",
        "            self.off = 0\n",
        "            self.label = {r['ID']: r['label'] for r in csv.DictReader(open(os.path.join(data_path, 'train.csv')))}\n",
        "            self.data = h5py.File(os.path.join(data_path, \"train.h5\"), 'r')\n",
        "        elif mode == 'test':\n",
        "            self.off = 50000\n",
        "            self.data = h5py.File(os.path.join(data_path, \"test.h5\"), 'r')\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        index = self.it\n",
        "        if index >= len(self.data):\n",
        "            raise StopIteration\n",
        "        data = self.data[str(index + self.off)]\n",
        "        label = index + self.off\n",
        "        if self.mode == 'train':\n",
        "            label = self.label[str(index)]\n",
        "            label = np.array(label).astype(int)\n",
        "        self.it += 1\n",
        "        return str(index + self.off), data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "4QxltfUtLOoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def h5_to_np(data_path, save_path):\n",
        "    [os.makedirs(\"%s/train/%d\" % (save_path, i), exist_ok=True) for i in range(10)]\n",
        "    os.makedirs(\"%s/test\" % save_path, exist_ok=True)\n",
        "\n",
        "    train_dl = H5DataLoader(data_path, mode='train')\n",
        "    bar = tqdm(train_dl, total=len(train_dl))\n",
        "    for index, dd, gt in bar:\n",
        "        np.save(\"%s/train/%d/%05d\" % (save_path, gt, int(index)), dd)\n",
        "    print('train data save complete')\n",
        "    test_dl = H5DataLoader(data_path, mode='test')\n",
        "    bar = tqdm(test_dl, total=len(test_dl))\n",
        "    for index, dd, gt in bar:\n",
        "        np.save(\"%s/test/%05d\" % (save_path, int(index)), dd)"
      ],
      "metadata": {
        "id": "U2MvY_NCLPzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h5_to_np('/content', \"/content/np\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21zj4uOCLQw5",
        "outputId": "2e58ea1e-f4a0-4f5a-be9b-882452c092f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:56<00:00, 283.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data save complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [03:00<00:00, 221.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DeepHoughModel(nn.Module):\n",
        "    def __init__(self, input_size=10000):\n",
        "        super(DeepHoughModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Conv1d(3, 16, (100, ), (5, ))\n",
        "        self.l2 = nn.Conv1d(16, 64, (100, ), (5, ))\n",
        "        self.l3 = nn.Conv1d(64, 128, (10, ), (5, ))\n",
        "        self.l4 = nn.Conv1d(128, 256, (10, ), (5, ))\n",
        "        self.l5 = nn.Conv1d(256, 512, (10, ), (5, ))\n",
        "        self.fc1 = nn.Linear(512, 128)\n",
        "        self.fc2 = nn.Linear(128, 3)\n",
        "        self.active = nn.ReLU()\n",
        "        self.fc_active = nn.Tanh()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        c = x.permute(0, 2, 1)\n",
        "        c = self.l1(c)\n",
        "        c = self.active(c)\n",
        "        c = self.l2(c)\n",
        "        c = self.active(c)\n",
        "        c = self.l3(c)\n",
        "        c = self.active(c)\n",
        "        c = self.l4(c)\n",
        "        c = self.active(c)\n",
        "        c = self.l5(c)\n",
        "        c = self.active(c)\n",
        "        feature = torch.mean(c, dim=2)\n",
        "        c = self.fc1(feature)\n",
        "        c = self.fc_active(c)\n",
        "        pred = self.fc2(c)\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "qk_Rh5TELfw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def derotation(a, b, c, dots):\n",
        "    def _rotation(a, b, c, dots):\n",
        "        mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
        "        my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
        "        mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
        "        m = np.dot(np.dot(mx, my), mz)\n",
        "        dots = np.dot(dots, m.T)\n",
        "        return dots\n",
        "    dot = _rotation(0, 0, c, dots)\n",
        "    dot = _rotation(0, b, 0, dot)\n",
        "    dot = _rotation(a, 0, 0, dot)\n",
        "    return dot\n",
        "\n",
        "\n",
        "def viz_result(data, pred, gt):\n",
        "    b_size = data.shape[0]\n",
        "    in_list = []\n",
        "    pred_list = []\n",
        "    gt_list = []\n",
        "    for i in range(b_size):\n",
        "        dd = data[i].cpu().detach().numpy()\n",
        "        in_list.append(data2img(dd.copy()))\n",
        "        pp = pred[i].cpu().detach().numpy()\n",
        "        gg = gt[i]\n",
        "        x, y, z = pp\n",
        "        # x *= np.pi*2\n",
        "        # y *= np.pi*2\n",
        "        # z *= np.pi*2\n",
        "        result_data = derotation(-x, -y, -z, dd.copy())\n",
        "        result_img = data2img(result_data)\n",
        "        pred_list.append(result_img)\n",
        "        x, y, z = gg\n",
        "        # x *= np.pi*2\n",
        "        # y *= np.pi*2\n",
        "        # z *= np.pi*2\n",
        "        gt_data = derotation(-x, -y, -z, dd.copy())\n",
        "        gt_img = data2img(gt_data)\n",
        "        gt_list.append(gt_img)\n",
        "\n",
        "    in_list = np.concatenate(in_list, axis=1)\n",
        "    pred_list = np.concatenate(pred_list, axis=1)\n",
        "    gt_list = np.concatenate(gt_list, axis=1)\n",
        "    return np.concatenate([in_list, pred_list, gt_list])\n",
        "\n",
        "\n",
        "def data2img(data, img_size=224):\n",
        "    w = 1\n",
        "    index = np.array(data)\n",
        "    index = np.array((index + 1) * (img_size // 2), dtype=int)\n",
        "    img = np.zeros((img_size, img_size, img_size), dtype=float)\n",
        "    for i in index:\n",
        "        x, y, z = i\n",
        "        # img[x, y, z] += 1\n",
        "        img[x - w:x + w, y - w:y + w, z - w:z + w] += 1\n",
        "    # print(np.max(img))\n",
        "    img = img[img_size // 2, :, :]\n",
        "    # img = cv2.blur(img, (5, 5))\n",
        "    # img = cv2.blur(img, (11, 11))\n",
        "    img[img > 1] = 1\n",
        "    img *= 255\n",
        "    return img.astype(np.uint8)"
      ],
      "metadata": {
        "id": "mSJy9VmENFC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class RotationLoader(Dataset):\n",
        "    def __init__(self, data_path, mode='train', img_size=128):\n",
        "        # data_path=\"F:\\\\Data\\\\mnist_3d\", mode='train'\n",
        "        self.mode = mode\n",
        "        self.data, self.label = self.get_img_list(data_path)\n",
        "        self.img_size = img_size\n",
        "        self.off = None\n",
        "        self.transform_3d = transforms.Compose([transforms.ToTensor(),\n",
        "                                             transforms.Normalize(mean=[0.5]*img_size,\n",
        "                                                                  std=[0.225]*img_size)\n",
        "                                             ])\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def get_img_list(self, data_path):\n",
        "        if self.mode == 'test':\n",
        "            img_list = glob(os.path.join(data_path, 'test', '*.npy'))\n",
        "            label_list = [int(img_l.split(os.sep)[-1].split('.')[0]) for img_l in img_list]\n",
        "            return img_list, label_list\n",
        "        else:\n",
        "            img_list = []\n",
        "            label_list = []\n",
        "            for i in range(10):\n",
        "                sub_path = os.path.join(data_path, 'train', '%d' % i)\n",
        "                sub_img_list = [os.path.join(sub_path, s) for s in os.listdir(sub_path) if 'npy' in s]\n",
        "                sub_img_num = len(sub_img_list)\n",
        "                sub_img_list.sort()\n",
        "                if self.mode == 'train':\n",
        "                    sub_img_list = sub_img_list[:int(sub_img_num*0.9)]\n",
        "                elif self.mode == 'val':\n",
        "                    sub_img_list = sub_img_list[int(sub_img_num*0.9):]\n",
        "                else:\n",
        "                    raise AssertionError\n",
        "                sub_label = [i for _ in range(len(sub_img_list))]\n",
        "                img_list += sub_img_list\n",
        "                label_list += sub_label\n",
        "\n",
        "            return img_list, label_list\n",
        "\n",
        "    @staticmethod\n",
        "    def rotation(a, b, c, dots):\n",
        "        def _rotation(a, b, c, dots):\n",
        "            mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
        "            my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
        "            mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
        "            m = np.dot(np.dot(mx, my), mz)\n",
        "            dots = np.dot(dots, m.T)\n",
        "            return dots\n",
        "        dot = _rotation(a, 0, 0, dots)\n",
        "        dot = _rotation(0, b, 0, dot)\n",
        "        dot = _rotation(0, 0, c, dot)\n",
        "        return dot\n",
        "\n",
        "    @staticmethod\n",
        "    def derotation(a, b, c, dots):\n",
        "        def _derotation(a, b, c, dots):\n",
        "            mx = np.array([[1, 0, 0], [0, np.cos(a), -np.sin(a)], [0, np.sin(a), np.cos(a)]])\n",
        "            my = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
        "            mz = np.array([[np.cos(c), -np.sin(c), 0], [np.sin(c), np.cos(c), 0], [0, 0, 1]])\n",
        "            m = np.dot(np.dot(mx, my), mz)\n",
        "            dots = np.dot(dots, m.T)\n",
        "            return dots\n",
        "\n",
        "        dot = _derotation(0, 0, c, dots)\n",
        "        dot = _derotation(0, b, 0, dot)\n",
        "        dot = _derotation(a, 0, 0, dot)\n",
        "        return dot\n",
        "\n",
        "\n",
        "    def random_rotation(self, data):\n",
        "        # 45 -np.pi/4\n",
        "        # off = np.pi*2\n",
        "        if self.off is None:\n",
        "            off = 0.5*np.pi\n",
        "        else:\n",
        "            off = self.off\n",
        "        x, y, z = 2*np.random.rand(3) - 1\n",
        "        x *= off\n",
        "        y *= off\n",
        "        z *= off\n",
        "        return self.rotation(x, y, z, data), [x, y, z]\n",
        "\n",
        "    def cvt_data(self, data):\n",
        "        data_np = np.array(data[:, 14, :], dtype=np.float32)\n",
        "        data_np -= np.min(data_np)\n",
        "        data_np /= np.max(data_np)\n",
        "        img = np.array(data_np*255, dtype=np.uint8)\n",
        "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    def data2img(self, data):\n",
        "        w = 1\n",
        "        index = np.array(data)\n",
        "        index = np.array((index + 1) * (self.img_size//2), dtype=int)\n",
        "        img = np.zeros((self.img_size, self.img_size, self.img_size), dtype=float)\n",
        "        for i in index:\n",
        "            x, y, z = i\n",
        "            img[x-w:x+w, y-w:y+w, z-w:z+w] += 1\n",
        "        # print(np.max(img))\n",
        "        img /= np.max(img)\n",
        "        img *= 255\n",
        "        return img.astype(np.uint8)\n",
        "\n",
        "    def sampling(self, data):\n",
        "        data_len = data.shape[0]\n",
        "        try:\n",
        "            idx = np.random.choice(np.array(range(0, data_len)), 10000, False)\n",
        "        except:\n",
        "            idx = np.random.choice(np.array(range(0, data_len)), 10000)\n",
        "        idx.sort()\n",
        "        feature = data[idx]\n",
        "        # sample_idx = torch.tensor(sample(range(0, data.shape[0]), 10000))\n",
        "        # feature = torch.index_select(data, 1, sample_idx)\n",
        "        return feature\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # index = 0\n",
        "        data = self.data[index]\n",
        "        label = self.label[index]\n",
        "        try:\n",
        "            data = np.load(data)\n",
        "        except Exception as e:\n",
        "            print('='*100)\n",
        "            print(index, e)\n",
        "            print('='*100)\n",
        "            index = 0\n",
        "            data = self.data[index]\n",
        "            data = np.load(data)\n",
        "            label = self.label[index]\n",
        "\n",
        "        data, rota = self.random_rotation(data)\n",
        "        data = self.sampling(data.astype(np.float32))\n",
        "\n",
        "        # data = self.transform(data)[0]\n",
        "        # print(data.shape)\n",
        "        return data, label, np.array(rota, dtype=float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class TestRotationLoader(RotationLoader):\n",
        "    def __init__(self, data_path, mode='train', img_size=128):\n",
        "        # data_path=\"F:\\\\Data\\\\mnist_3d\", mode='train'\n",
        "        super().__init__(data_path, mode, img_size)\n",
        "        self.mode = mode\n",
        "        self.data, self.label = self.get_img_list(data_path)\n",
        "        self.img_size = img_size\n",
        "        self.transform_3d = transforms.Compose([transforms.ToTensor(),\n",
        "                                             transforms.Normalize(mean=[0.5]*img_size,\n",
        "                                                                  std=[0.225]*img_size)\n",
        "                                             ])\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def random_rotation(self, data, off=None):\n",
        "        # 45 -np.pi/4\n",
        "        # off = np.pi*2\n",
        "        if off is None:\n",
        "            off = np.pi * 0.5\n",
        "        x, y, z = np.random.rand(3)\n",
        "        # x, y, z = 1.0, 1.0, 1.0\n",
        "        x *= off\n",
        "        y *= off\n",
        "        z *= off\n",
        "        return self.rotation(x, y, z, data), [x, y, z]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # index = 0\n",
        "        data = self.data[index]\n",
        "        label = self.label[index]\n",
        "        try:\n",
        "            data = np.load(data)\n",
        "        except Exception as e:\n",
        "            print('='*100)\n",
        "            print(index, e)\n",
        "            print('='*100)\n",
        "            index = 0\n",
        "            data = self.data[index]\n",
        "            data = np.load(data)\n",
        "            label = self.label[index]\n",
        "\n",
        "        data, rota = self.random_rotation(data, np.pi*0.2)\n",
        "        data = self.sampling(data.astype(np.float32))\n",
        "\n",
        "        return data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class TrainDataLoader(RotationLoader):\n",
        "    def __init__(self, data_path):\n",
        "        super().__init__(data_path)\n",
        "        self.data, self.label = self.get_img_list(data_path)\n",
        "        self.idx = 0\n",
        "\n",
        "    def get_img_list(self, data_path):\n",
        "        img_list = []\n",
        "        label_list = []\n",
        "        for i in range(10):\n",
        "            sub_path = os.path.join(data_path, 'train', '%d' % i)\n",
        "            sub_img_list = [os.path.join(sub_path, s) for s in os.listdir(sub_path) if 'npy' in s]\n",
        "            sub_img_list.sort()\n",
        "            sub_label = [i for _ in range(len(sub_img_list))]\n",
        "            img_list += sub_img_list\n",
        "            label_list += sub_label\n",
        "\n",
        "        return img_list, label_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_name = self.data[index]\n",
        "        label = self.label[index]\n",
        "        data = np.load(data_name)\n",
        "        data = self.sampling(data.astype(np.float32))\n",
        "        name = os.path.split(data_name)[-1].split('.')[0]\n",
        "        return data, label, name"
      ],
      "metadata": {
        "id": "OGdJzOfuNGnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "8cC2c7lxNJvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rotation(data_path, save_path):\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    model = DeepHoughModel()\n",
        "    model = model.cuda()\n",
        "\n",
        "    train_dl = RotationLoader(data_path, mode='train', img_size=64)\n",
        "    train_loader = DataLoader(dataset=train_dl, batch_size=8, num_workers=4, shuffle=False)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, amsgrad=True, weight_decay=1e-4)  # default as 0.0001\n",
        "    val_dl = RotationLoader(data_path, mode='val', img_size=64)\n",
        "    val_loader = DataLoader(dataset=val_dl, batch_size=8, num_workers=4, shuffle=True)\n",
        "\n",
        "    for epoch in range(50):\n",
        "        print('train', epoch)\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, total=len(train_loader))\n",
        "        total_loss = 0\n",
        "        for i, (data, label, gt) in enumerate(pbar):\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data.cuda())\n",
        "            distance = gt.cuda() - pred\n",
        "            l2_loss = torch.sum(torch.multiply(distance, distance))\n",
        "            l1_loss = torch.sum(torch.abs(distance))\n",
        "            loss = l1_loss + l2_loss\n",
        "            total_loss += float(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pbar.set_postfix({'loss': '%.4f (%.4f, %.4f)' % (loss, l1_loss, l2_loss)})\n",
        "            if i % 3000 == 0:\n",
        "                result_img = viz_result(data, pred, gt)\n",
        "                cv2.imwrite(os.path.join(save_path, \"train_%d_%d.png\" % (epoch, i//3000)), result_img)\n",
        "        total_loss /= len(train_loader)\n",
        "\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for i, (data, label, gt) in enumerate(val_loader):\n",
        "                pred = model(data.cuda())\n",
        "                distance = gt.cuda() - pred\n",
        "                # distance = torch.cos(gt.cuda()) - torch.cos(pred)\n",
        "                val_loss += torch.sum(torch.multiply(distance, distance))\n",
        "                if i % 300 == 0:\n",
        "                    result_img = viz_result(data, pred, gt)\n",
        "                    cv2.imwrite(os.path.join(save_path, \"val_%d_%d.png\" % (epoch, i//300)), result_img)\n",
        "\n",
        "        model_save_path = os.path.join(save_path, \"%d_rotation1d_%.4f_%.4f.pth\" % (epoch, total_loss, val_loss/len(val_loader)))\n",
        "        torch.save({'weight': model.state_dict()}, model_save_path)\n",
        "        print(\"#\"*100)\n",
        "        print(\"[%d] validation loss : %.4f\" % (epoch, val_loss/len(val_loader)), end=' ')\n",
        "        print(\"#\"*100)"
      ],
      "metadata": {
        "id": "IKH7ewTBNK8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_data_path = \"/content/np\"\n",
        "save_model_path = \"/content/model/rotatio\"\n",
        "result_data_path = \"/content/img\""
      ],
      "metadata": {
        "id": "natR9MfWNMMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rotation(np_data_path, save_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-w3sQaHOGGp",
        "outputId": "32fa30e5-036e-4157-929d-40b91cafadb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:28<00:00, 26.93it/s, loss=0.8765 (0.7771, 0.0995)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[0] validation loss : 1.3769 ####################################################################################################\n",
            "train 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:41<00:00, 25.37it/s, loss=0.2672 (0.2555, 0.0117)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[1] validation loss : 0.6398 ####################################################################################################\n",
            "train 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:39<00:00, 25.61it/s, loss=0.3938 (0.3707, 0.0231)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[2] validation loss : 0.4525 ####################################################################################################\n",
            "train 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:38<00:00, 25.74it/s, loss=1.4239 (1.0476, 0.3764)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[3] validation loss : 0.3840 ####################################################################################################\n",
            "train 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:39<00:00, 25.60it/s, loss=0.5169 (0.4608, 0.0560)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[4] validation loss : 0.3307 ####################################################################################################\n",
            "train 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:39<00:00, 25.61it/s, loss=0.5497 (0.4754, 0.0743)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[5] validation loss : 0.3073 ####################################################################################################\n",
            "train 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:42<00:00, 25.25it/s, loss=0.3099 (0.2925, 0.0174)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[6] validation loss : 0.2489 ####################################################################################################\n",
            "train 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:02<00:00, 30.75it/s, loss=0.1157 (0.1131, 0.0026)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[7] validation loss : 0.2572 ####################################################################################################\n",
            "train 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:04<00:00, 30.50it/s, loss=0.2071 (0.2005, 0.0066)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[8] validation loss : 0.2030 ####################################################################################################\n",
            "train 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.49it/s, loss=0.1926 (0.1860, 0.0067)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[9] validation loss : 0.2300 ####################################################################################################\n",
            "train 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.43it/s, loss=0.4925 (0.4383, 0.0541)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[10] validation loss : 0.2341 ####################################################################################################\n",
            "train 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:55<00:00, 32.00it/s, loss=0.3524 (0.3351, 0.0173)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[11] validation loss : 0.1555 ####################################################################################################\n",
            "train 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:55<00:00, 32.11it/s, loss=0.2244 (0.2173, 0.0071)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[12] validation loss : 0.2529 ####################################################################################################\n",
            "train 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:56<00:00, 31.82it/s, loss=0.2887 (0.2791, 0.0097)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[13] validation loss : 0.1875 ####################################################################################################\n",
            "train 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.75it/s, loss=2.7126 (1.5958, 1.1168)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[14] validation loss : 0.1873 ####################################################################################################\n",
            "train 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:56<00:00, 31.92it/s, loss=0.2468 (0.2388, 0.0080)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[15] validation loss : 0.1614 ####################################################################################################\n",
            "train 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.75it/s, loss=0.2903 (0.2792, 0.0111)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[16] validation loss : 0.1713 ####################################################################################################\n",
            "train 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.72it/s, loss=0.2157 (0.2100, 0.0057)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[17] validation loss : 0.2150 ####################################################################################################\n",
            "train 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:01<00:00, 31.06it/s, loss=0.2126 (0.2057, 0.0070)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[18] validation loss : 0.1894 ####################################################################################################\n",
            "train 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:03<00:00, 30.66it/s, loss=0.2055 (0.1986, 0.0069)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[19] validation loss : 0.2038 ####################################################################################################\n",
            "train 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.45it/s, loss=0.2577 (0.2414, 0.0164)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[20] validation loss : 0.2047 ####################################################################################################\n",
            "train 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:55<00:00, 32.04it/s, loss=0.1949 (0.1887, 0.0062)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[21] validation loss : 0.1240 ####################################################################################################\n",
            "train 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.58it/s, loss=0.4515 (0.4197, 0.0318)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[22] validation loss : 0.1290 ####################################################################################################\n",
            "train 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.43it/s, loss=0.1784 (0.1723, 0.0060)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[23] validation loss : 0.1560 ####################################################################################################\n",
            "train 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.66it/s, loss=0.1998 (0.1928, 0.0070)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[24] validation loss : 0.1715 ####################################################################################################\n",
            "train 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.43it/s, loss=0.1989 (0.1931, 0.0058)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[25] validation loss : 0.1231 ####################################################################################################\n",
            "train 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:59<00:00, 31.36it/s, loss=0.2512 (0.2402, 0.0110)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[26] validation loss : 0.1500 ####################################################################################################\n",
            "train 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:56<00:00, 31.78it/s, loss=0.1674 (0.1625, 0.0049)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[27] validation loss : 0.1561 ####################################################################################################\n",
            "train 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.68it/s, loss=0.1294 (0.1257, 0.0038)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[28] validation loss : 0.1414 ####################################################################################################\n",
            "train 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:55<00:00, 32.03it/s, loss=0.2262 (0.2173, 0.0089)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[29] validation loss : 0.1989 ####################################################################################################\n",
            "train 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.46it/s, loss=0.1957 (0.1912, 0.0046)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[30] validation loss : 0.1463 ####################################################################################################\n",
            "train 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.60it/s, loss=0.2275 (0.2200, 0.0075)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[31] validation loss : 0.1659 ####################################################################################################\n",
            "train 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.63it/s, loss=0.1089 (0.1067, 0.0022)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[32] validation loss : 0.1344 ####################################################################################################\n",
            "train 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:59<00:00, 31.35it/s, loss=0.3165 (0.3020, 0.0144)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[33] validation loss : 0.2404 ####################################################################################################\n",
            "train 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.66it/s, loss=0.1356 (0.1326, 0.0030)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[34] validation loss : 0.1239 ####################################################################################################\n",
            "train 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:59<00:00, 31.37it/s, loss=0.2308 (0.2226, 0.0082)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[35] validation loss : 0.1377 ####################################################################################################\n",
            "train 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.47it/s, loss=0.2330 (0.2249, 0.0081)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[36] validation loss : 0.0866 ####################################################################################################\n",
            "train 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.64it/s, loss=0.1542 (0.1507, 0.0035)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[37] validation loss : 0.1184 ####################################################################################################\n",
            "train 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.54it/s, loss=0.1638 (0.1599, 0.0040)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[38] validation loss : 0.1367 ####################################################################################################\n",
            "train 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.54it/s, loss=0.2530 (0.2382, 0.0149)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[39] validation loss : 0.1615 ####################################################################################################\n",
            "train 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:59<00:00, 31.40it/s, loss=0.2003 (0.1941, 0.0062)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[40] validation loss : 0.1316 ####################################################################################################\n",
            "train 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:59<00:00, 31.37it/s, loss=0.4530 (0.4174, 0.0356)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[41] validation loss : 0.1498 ####################################################################################################\n",
            "train 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:56<00:00, 31.84it/s, loss=0.3045 (0.2888, 0.0157)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[42] validation loss : 0.1556 ####################################################################################################\n",
            "train 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.55it/s, loss=0.2484 (0.2408, 0.0075)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[43] validation loss : 0.1565 ####################################################################################################\n",
            "train 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.61it/s, loss=0.1641 (0.1599, 0.0043)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[44] validation loss : 0.1278 ####################################################################################################\n",
            "train 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.67it/s, loss=0.1634 (0.1596, 0.0038)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[45] validation loss : 0.1418 ####################################################################################################\n",
            "train 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.52it/s, loss=0.1964 (0.1917, 0.0047)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[46] validation loss : 0.1473 ####################################################################################################\n",
            "train 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:58<00:00, 31.45it/s, loss=0.3950 (0.3746, 0.0204)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[47] validation loss : 0.1625 ####################################################################################################\n",
            "train 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [02:57<00:00, 31.67it/s, loss=0.0783 (0.0773, 0.0010)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[48] validation loss : 0.1651 ####################################################################################################\n",
            "train 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5625/5625 [03:00<00:00, 31.22it/s, loss=0.1354 (0.1322, 0.0032)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################################################################################\n",
            "[49] validation loss : 0.1147 ####################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sTmV0k23Kzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cvt_train_data_2d(data_path, save_path):\n",
        "  os.makedirs(save_path, exist_ok=True)\n",
        "  [os.makedirs(\"%s/%d\" % (save_path, i), exist_ok=True) for i in range(10)]\n",
        "  train_dl = TrainDataLoader(data_path)\n",
        "  train_loader = DataLoader(dataset=train_dl, batch_size=1, num_workers=4, shuffle=False)\n",
        "  pbar = tqdm(train_loader, total=len(train_loader))\n",
        "  for i, (data, label, name) in enumerate(pbar):\n",
        "      # print(data.shape, label, name)\n",
        "      img = data2img(data[0], 64)\n",
        "      cv2.imwrite(os.path.join(save_path, '%d' % label[0], name[0] + '.png'), img)"
      ],
      "metadata": {
        "id": "Q18vNRkw3Kxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvt_train_data_2d(np_data_path, result_data_path + '/train')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN67WhPfOHhx",
        "outputId": "0f7aee0a-bbfc-4321-e417-2950c6f60ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [1:04:10<00:00, 12.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_cascade_result(weight_path, data_path, save_path):\n",
        "    pre_weight = torch.load(weight_path)\n",
        "\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    [os.remove(p) for p in glob(save_path + '/*.png')]\n",
        "\n",
        "    model = DeepHoughModel()\n",
        "    model = model.cuda()\n",
        "    init_weight = model.state_dict()\n",
        "    init_weight.update(pre_weight['weight'])\n",
        "    model.load_state_dict(init_weight)\n",
        "    model = model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    test_dl = TestRotationLoader(data_path, mode='test', img_size=64)\n",
        "    test_loader = DataLoader(dataset=test_dl, batch_size=1, num_workers=32, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(test_loader, total=len(test_loader))\n",
        "        for i, (data, label) in enumerate(pbar):\n",
        "            dd = data.cpu().detach().numpy()\n",
        "            for j in range(9):\n",
        "                pred = model(torch.from_numpy(dd.astype(np.float32)).cuda())\n",
        "                pp = pred[0].cpu().detach().numpy()\n",
        "                x, y, z = pp\n",
        "                dd = test_dl.derotation(-x, -y, -z, dd)\n",
        "            result_img = data2img(dd[0], 64)\n",
        "            cv2.imwrite(os.path.join(save_path, '%d.png' % label), result_img)"
      ],
      "metadata": {
        "id": "6AS31nG93IKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    ww = glob(\"%s/%d_*.pth\" % (save_model_path, 3*i + 22))[0]\n",
        "    ss = \"%s/test_%d\" % (result_data_path, i)\n",
        "    print(ww, ss)\n",
        "    inference_cascade_result(ww, np_data_path, ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPb_XmYLHKQg",
        "outputId": "b4b87750-fb4d-4d68-eefd-38d177e51c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/22_rotation1d_1.0856_0.1290.pth /content/img/test_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 40000/40000 [1:17:48<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/25_rotation1d_1.0701_0.1231.pth /content/img/test_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:17:57<00:00,  8.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/28_rotation1d_1.0161_0.1414.pth /content/img/test_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:17:15<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/31_rotation1d_0.9952_0.1659.pth /content/img/test_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:17:05<00:00,  8.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/34_rotation1d_0.9571_0.1239.pth /content/img/test_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:17:58<00:00,  8.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/37_rotation1d_0.9189_0.1184.pth /content/img/test_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:17:24<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/40_rotation1d_0.9027_0.1316.pth /content/img/test_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:17:29<00:00,  8.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/43_rotation1d_0.9055_0.1565.pth /content/img/test_7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:15:42<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/46_rotation1d_0.9080_0.1473.pth /content/img/test_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:15:36<00:00,  8.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model/rotatio/49_rotation1d_0.8979_0.1147.pth /content/img/test_9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [1:14:20<00:00,  8.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_path = \"/content/img\"\n",
        "save_model_path = \"/content/model/cnn\"\n",
        "save_result_path = \"/content/result\""
      ],
      "metadata": {
        "id": "7iLyz7sq3Jnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return vf.rotate(img, angle, False, False, None, None)"
      ],
      "metadata": {
        "id": "aI9qNuPx3aWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistRotaDatasetLabel(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_path, mode=None, transform=None):\n",
        "        self.mode = mode\n",
        "        name_list, img_list, label_list = [], [], []\n",
        "        if mode == 'test':\n",
        "            for n in range(50000, 90000):\n",
        "                name_list.append(n)\n",
        "                img_list.append(os.path.join(img_path, '%s.png' % n))\n",
        "                label_list.append(0)\n",
        "        else:\n",
        "            name_list, img_list, label_list = self.get_img_list(img_path)\n",
        "        self.name_data = name_list\n",
        "        self.x_data = img_list\n",
        "        self.y_data = label_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def get_img_list(self, data_path):\n",
        "        img_list = []\n",
        "        label_list = []\n",
        "        name_list = []\n",
        "        for i in range(10):\n",
        "            sub_path = os.path.join(data_path, 'train/%d' % i)\n",
        "            sub_img_list = [os.path.join(sub_path, s) for s in os.listdir(sub_path) if 'png' in s]\n",
        "            sub_img_num = len(sub_img_list)\n",
        "            sub_img_list.sort()\n",
        "            if self.mode == 'train':\n",
        "                sub_img_list = sub_img_list[:int(sub_img_num*0.9)]\n",
        "            elif self.mode == 'val':\n",
        "                sub_img_list = sub_img_list[int(sub_img_num*0.9):]\n",
        "            else:\n",
        "                raise AssertionError\n",
        "            sub_name = [p.split(os.sep)[-1] for p in sub_img_list]\n",
        "            name_list += sub_name\n",
        "            sub_label = [i for _ in range(len(sub_img_list))]\n",
        "            img_list += sub_img_list\n",
        "            label_list += sub_label\n",
        "\n",
        "        return name_list, img_list, label_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = cv2.imread(self.x_data[idx], 0)\n",
        "        x[x > 1] = 255\n",
        "        x = cv2.resize(x, (28, 28))\n",
        "        x = np.reshape(x, (28, 28, 1)).astype(np.float32)\n",
        "        y = self.y_data[idx]\n",
        "        n = self.name_data[idx]\n",
        "        x = transforms.ToPILImage()(x)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y, n"
      ],
      "metadata": {
        "id": "0jQozsZl3jN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "rD1z3lYf3oh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]\n"
      ],
      "metadata": {
        "id": "V8JM4G953ukg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "def train(data_path, save_path, p_seed=0, p_epochs=150):\n",
        "    # random number generator seed ------------------------------------------------#\n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # number of epochs ------------------------------------------------------------#\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # file names ------------------------------------------------------------------#\n",
        "    os.makedirs(\"%s\" % save_path, exist_ok=True)\n",
        "    MODEL_FILE = str(\"%s/model%03d.pth\" % (save_path, SEED))\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data augmentation methods ---------------------------------------------------#\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    train_dataset = MnistRotaDatasetLabel(data_path, mode='train', transform=transform)\n",
        "    val_dataset = MnistRotaDatasetLabel(data_path, mode='val', transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=4, batch_size=120, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, num_workers=4, batch_size=120, shuffle=True)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    model = ModelM3().to(device)\n",
        "\n",
        "    # hyperparameter selection ----------------------------------------------------#\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # global variables ------------------------------------------------------------#\n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "    min_loss = 10\n",
        "\n",
        "    # training and evaluation loop ------------------------------------------------#\n",
        "\n",
        "    for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # train process                                                            #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target, name) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device, dtype=torch.int64)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "#             if batch_idx % 100 == 0:\n",
        "#                 print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#                     epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "#                     100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        if (train_loss < min_loss):\n",
        "            torch.save(model.state_dict(), MODEL_FILE)\n",
        "            min_loss = train_loss\n",
        "#             print(\"Save Model Best train loss %.4f\" % train_loss)\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # test process                                                             #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_pred = np.zeros(0)\n",
        "        val_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target, name in val_loader:\n",
        "                data, target = data.to(device), target.to(device,  dtype=torch.int64)\n",
        "                output = model(data)\n",
        "                val_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                val_pred = np.append(val_pred, pred.cpu().numpy())\n",
        "                val_target = np.append(val_target, target.cpu().numpy())\n",
        "                val_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = 100 * val_correct / len(val_loader.dataset)\n",
        "#         print('Val set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "#             val_loss, val_correct, len(val_loader.dataset), val_accuracy))\n",
        "        ema.resume(model)\n",
        "\n",
        "        lr_scheduler.step()"
      ],
      "metadata": {
        "id": "YJ8o8uqfHQkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as vf"
      ],
      "metadata": {
        "id": "-ZdDkAIY33Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print('train', i)\n",
        "    train(img_data_path,\n",
        "          save_model_path,\n",
        "          p_seed=i,\n",
        "          p_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J_iuvvw3XHN",
        "outputId": "e66b5470-abf2-4482-cbee-18c5ce84a02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:04<00:00, 14.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:01<00:00, 14.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:03<00:00, 14.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:05<00:00, 14.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:13<00:00, 14.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:05<00:00, 14.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:08<00:00, 14.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:10<00:00, 14.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:14<00:00, 14.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [24:12<00:00, 14.52s/it]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}