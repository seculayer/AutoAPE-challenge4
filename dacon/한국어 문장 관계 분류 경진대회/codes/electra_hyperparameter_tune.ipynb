{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  9 13:36:43 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   38C    P0    66W / 300W |    954MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   49C    P0   106W / 300W |   1096MiB / 32510MiB |     81%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     74414      C   .../envs/test_env/bin/python      951MiB |\r\n",
      "|    1   N/A  N/A      7312      C   .../envs/test_env/bin/python     1093MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/centos/psw/KSRC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_bVw3BzS66Gp"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast, BartModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K7aUlj6L7eAH",
    "outputId": "575cdb6d-f613-45e8-82d4-146d2a0c2761"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            premise  \\\n",
       "0           0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...   \n",
       "1           1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...   \n",
       "2           2                    이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.   \n",
       "3           3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4           4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dpath = '/content/drive/My Drive/Seculayer/KSRC/'\n",
    "train = pd.read_csv('data/with_kakao_train.csv',encoding='utf-8')\n",
    "test = pd.read_csv('data/test_data.csv',encoding='utf-8')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "yv3YDRoOHPoX",
    "outputId": "0883bafc-6b61-4dd4-c270-51516ed832f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            premise  \\\n",
       "0           0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1           1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2           2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3           3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4           4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                                hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불 용어 처리 \n",
    "\n",
    "train['premise'] = train['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['premise'] = test['premise'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "hCfxgISsHvZl",
    "outputId": "43f42d44-7632-48bd-d175-3c42d7029276"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
       "      <td>씨름의 여자들의 놀이이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
       "      <td>자작극을 벌인 이는 3명이다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
       "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
       "      <td>원주민들은 종합대책에 만족했다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
       "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            premise  \\\n",
       "0           0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...   \n",
       "1           1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...   \n",
       "2           2                     이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다   \n",
       "3           3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
       "4           4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...   \n",
       "\n",
       "                               hypothesis          label  \n",
       "0                           씨름의 여자들의 놀이이다  contradiction  \n",
       "1                         자작극을 벌인 이는 3명이다  contradiction  \n",
       "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다     entailment  \n",
       "3                        원주민들은 종합대책에 만족했다        neutral  \n",
       "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다        neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hypothesis'] = train['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
    "test['hypothesis'] = test['hypothesis'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6FpW8SM7lwW",
    "outputId": "e779fb75-c660-4224-8296-fb17f2facfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159475 entries, 0 to 159474\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159475 non-null  int64 \n",
      " 1   premise     159475 non-null  object\n",
      " 2   hypothesis  159475 non-null  object\n",
      " 3   label       159475 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1666 entries, 0 to 1665\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   index       1666 non-null   int64 \n",
      " 1   premise     1666 non-null   object\n",
      " 2   hypothesis  1666 non-null   object\n",
      " 3   label       1666 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 52.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 결측치는 없음\n",
    "\n",
    "print(train.info(), end='\\n\\n')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4L1jeCl72DF",
    "outputId": "b5c8ce74-4bce-4603-a0f6-e8cbcd527b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label: \n",
      "entailment       53618\n",
      "contradiction    53468\n",
      "neutral          52389\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Label: ', train['label'].value_counts(), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9SAoqqNmAU3x",
    "outputId": "cbe32eff-2df0-4a4f-9d17-50537c24cd33"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data imbalance는 사실상 존재하지 않음 \n",
    "\n",
    "sns.countplot(data=train,x='label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T6hQolMqAkji"
   },
   "outputs": [],
   "source": [
    "max_premise = np.max(train['premise'].str.len())\n",
    "\n",
    "max_hypothesis = np.max(train['hypothesis'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AApuxsJBcYi",
    "outputId": "744f3bd4-e74b-40cf-defb-abfd64225d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max premise = 135 \n",
      "max hypothesis = 102\n"
     ]
    }
   ],
   "source": [
    "print('max premise =',max_premise,\"\\nmax hypothesis =\",max_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['premise'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "5xFFliUaCiwR",
    "outputId": "b7132a6d-24cb-4773-edaa-13d9d7e75af2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=train['hypothesis'].str.len());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 2023):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'tunib/electra-ko-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "config.num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "print(model)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 16626,  1992, 19479,  6148, 17858, 11306, 20947,  3554,  6031,\n",
      "         2188, 13089, 15275,  6148, 13736,  6011,  6692,  6011,     3, 14941,\n",
      "        16118, 11351, 12195,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "[CLS] 입에 막대기를 물고 있는 개가 얕은 물 속에서 바위를 뛰어다닌다 [SEP] 아무것도 작동하지 않는다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# train test split 및 tokenizing \n",
    "# token에 들어가는 문장은 premise와 hypothesis를 concat 한 문장\n",
    "\n",
    "train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['label'])\n",
    "\n",
    "tokenized_train = tokenizer(\n",
    "    list(train_dataset['premise']),\n",
    "    list(train_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=300, # Max_Length = 190\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "tokenized_eval = tokenizer(\n",
    "    list(eval_dataset['premise']),\n",
    "    list(eval_dataset['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=300,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(tokenized_train['input_ids'][0])\n",
    "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pair_dataset, label):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def label_to_num(label):\n",
    "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
    "    num_label = []\n",
    "\n",
    "    for v in label:\n",
    "        num_label.append(label_dict[v])\n",
    "\n",
    "    return num_label\n",
    "\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "eval_label = label_to_num(eval_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127580\n",
      "{'input_ids': tensor([    2, 13610, 13595, 15049, 12199, 23296, 13163,  3524,  6590,  6015,\n",
      "        12219, 11392,     3, 20714, 11331, 13610,  6063, 15049, 12199, 13163,\n",
      "         6007,  3931, 13776, 11884,     3,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(2)}\n",
      "[CLS] 인물간의 감정선을 이끄는 카메라 앵글도 좋았구요 [SEP] 극단적인 인물의 감정선을 카메라가 잘 이끌었어요 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BERTDataset(tokenized_train, train_label)\n",
    "eval_dataset = BERTDataset(tokenized_eval, eval_label)\n",
    "\n",
    "print(train_dataset.__len__())\n",
    "print(train_dataset.__getitem__(19997))\n",
    "print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  \"\"\" validation을 위한 metrics function \"\"\"\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  probs = pred.predictions\n",
    "\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
    "\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, \n",
    "                                                              config=config)\n",
    "\n",
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 3e-5, 1.5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 0.01),\n",
    "#         \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "#         \"seed\": trial.suggest_int(\"seed\", 20, 40),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
    "    }\n",
    "\n",
    "# def my_hp_space(trial):\n",
    "#     return {\n",
    "#         \"learning_rate\":  trial.suggest_categorical(\"learning_rate\", [0.00001,0.00002, 0.00003,0.00004,0.00005]),\n",
    "#         \"warmup_ratio\":  trial.suggest_categorical(\"warmup_ratio\", [0,0.1, 0.2,0.6]),\n",
    "#         \"weight_decay\":  trial.suggest_categorical(\"weight_decay\", [0, 0.01]),\n",
    "# #         \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "# #         \"seed\": trial.suggest_int(\"seed\", 20, 40),\n",
    "#         \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8,16, 32]),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_ars = TrainingArguments(\n",
    "    output_dir='result/electra_hyperparameter_tune/',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_total_limit=5,\n",
    "    save_steps=1200,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 1200,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_ars,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 13:37:31,707]\u001b[0m A new study created in memory with name: no-name-5a65569d-e038-4199-835f-2da6665e4bbd\u001b[0m\n",
      "Trial: {'learning_rate': 8.94813195527071e-05, 'weight_decay': 0.00011458736482220067, 'per_device_train_batch_size': 32}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13958\n",
      "  Number of trainable parameters = 110619651\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msangmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_133736-2vnwed6q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/2vnwed6q\" target=\"_blank\">mild-water-51</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13958' max='13958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13958/13958 1:22:28, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.492410</td>\n",
       "      <td>0.817432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.437094</td>\n",
       "      <td>0.846183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.389993</td>\n",
       "      <td>0.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>0.447521</td>\n",
       "      <td>0.861859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.510299</td>\n",
       "      <td>0.865841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.149700</td>\n",
       "      <td>0.455618</td>\n",
       "      <td>0.866907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.545611</td>\n",
       "      <td>0.866437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.504960</td>\n",
       "      <td>0.868036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.697760</td>\n",
       "      <td>0.871892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.872770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.784617</td>\n",
       "      <td>0.871829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-1200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-1200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-1200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-2400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-2400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-3600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-3600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-3600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-4800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-4800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-4800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-6000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-6000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-6000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-7200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-7200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-7200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-7200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-0/checkpoint-1200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-8400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-8400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-8400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-8400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-8400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-0/checkpoint-2400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-9600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-9600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-9600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-0/checkpoint-4800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-10800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-10800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-10800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-10800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-10800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-0/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-12000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-12000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-0/checkpoint-7200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-0/checkpoint-13200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-0/checkpoint-13200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-0/checkpoint-13200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-0/checkpoint-13200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-0/checkpoint-13200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-0/checkpoint-8400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/electra_hyperparameter_tune/run-0/checkpoint-3600 (score: 0.3899931013584137).\n",
      "\u001b[32m[I 2023-01-09 15:00:10,362]\u001b[0m Trial 0 finished with value: 0.8718294403511522 and parameters: {'learning_rate': 8.94813195527071e-05, 'weight_decay': 0.00011458736482220067, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8718294403511522.\u001b[0m\n",
      "Trial: {'learning_rate': 0.0001377375512723889, 'weight_decay': 0.002396503686062288, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27909\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>▃▂▁▂▃▂▄▃▆▇█</td></tr><tr><td>eval/runtime</td><td>▂▂▁▁▁▁█▁▂▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▆▇████▁▇▆▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▆▇████▁▇▆▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.87183</td></tr><tr><td>eval/loss</td><td>0.78462</td></tr><tr><td>eval/runtime</td><td>99.6939</td></tr><tr><td>eval/samples_per_second</td><td>319.929</td></tr><tr><td>eval/steps_per_second</td><td>20.001</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>13958</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0407</td></tr><tr><td>train/total_flos</td><td>4.314013763789016e+16</td></tr><tr><td>train/train_loss</td><td>0.21054</td></tr><tr><td>train/train_runtime</td><td>4956.5735</td></tr><tr><td>train/train_samples_per_second</td><td>180.177</td></tr><tr><td>train/train_steps_per_second</td><td>2.816</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mild-water-51</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/2vnwed6q\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/2vnwed6q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_133736-2vnwed6q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e80aca102e440039a28d66b9a48dbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669471065203348, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_150022-3nlaard0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/3nlaard0\" target=\"_blank\">fanciful-river-52</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27909' max='27909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27909/27909 2:04:31, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.100148</td>\n",
       "      <td>0.328515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.099100</td>\n",
       "      <td>1.099792</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.099300</td>\n",
       "      <td>1.098713</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.099000</td>\n",
       "      <td>1.099270</td>\n",
       "      <td>0.328515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.098800</td>\n",
       "      <td>1.098690</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.098400</td>\n",
       "      <td>1.098572</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098587</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098673</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098589</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098724</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098665</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098577</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.098563</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098581</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098818</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098560</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098582</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098581</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098563</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098576</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098590</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.098562</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098560</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-1200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-1200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-1200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-2400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-2400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-3600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-3600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-3600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-4800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-4800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-4800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-6000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-6000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-6000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-7200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-7200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-7200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-7200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-1200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-8400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-8400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-8400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-8400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-8400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-2400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-9600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-9600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-9600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-3600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-10800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-10800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-10800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-10800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-10800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-4800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-12000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-12000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-13200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-13200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-13200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-13200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-13200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-8400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-14400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-14400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-14400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-14400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-14400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-9600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-15600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-15600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-15600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-15600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-15600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-7200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-16800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-16800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-16800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-16800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-16800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-10800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-18000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-18000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-12000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-19200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-19200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-19200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-19200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-19200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-13200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-20400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-20400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-20400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-20400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-20400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-14400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-21600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-21600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-21600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-21600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-21600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-15600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-22800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-22800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-22800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-22800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-22800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-16800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-24000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-24000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-18000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-25200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-25200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-25200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-25200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-25200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-20400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-26400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-26400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-26400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-26400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-26400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-21600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-1/checkpoint-27600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-1/checkpoint-27600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-1/checkpoint-27600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-1/checkpoint-27600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-1/checkpoint-27600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-1/checkpoint-22800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/electra_hyperparameter_tune/run-1/checkpoint-19200 (score: 1.0985597372055054).\n",
      "\u001b[32m[I 2023-01-09 17:04:56,215]\u001b[0m Trial 1 finished with value: 0.3362282489418404 and parameters: {'learning_rate': 0.0001377375512723889, 'weight_decay': 0.002396503686062288, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8718294403511522.\u001b[0m\n",
      "Trial: {'learning_rate': 3.213114421183878e-05, 'weight_decay': 0.009872847838692694, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27909\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20505cbc6fa44edcb60a42e57cdaf4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▇▁▇█▇█▇████▇████▇▇███</td></tr><tr><td>eval/loss</td><td>█▆▂▄▂▁▁▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▃▂▃▃▃▃▃▅▄▄█▇▄▄▃▄▂▁▃▂▂▇</td></tr><tr><td>eval/samples_per_second</td><td>▄▆▇▆▆▆▆▆▄▄▄▁▂▅▅▅▅▇█▆▇▇▂</td></tr><tr><td>eval/steps_per_second</td><td>▄▆▇▆▆▆▆▆▄▄▄▁▂▅▅▅▅▇█▆▇▇▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.33623</td></tr><tr><td>eval/loss</td><td>1.09856</td></tr><tr><td>eval/runtime</td><td>104.2321</td></tr><tr><td>eval/samples_per_second</td><td>306.0</td></tr><tr><td>eval/steps_per_second</td><td>19.13</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>27909</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0986</td></tr><tr><td>train/total_flos</td><td>4.314013763789016e+16</td></tr><tr><td>train/train_loss</td><td>1.09882</td></tr><tr><td>train/train_runtime</td><td>7483.7254</td></tr><tr><td>train/train_samples_per_second</td><td>119.334</td></tr><tr><td>train/train_steps_per_second</td><td>3.729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-river-52</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/3nlaard0\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/3nlaard0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_150022-3nlaard0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7399375ce52e441da46da00f6d26bd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666913479566574, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_170503-110ic1rg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/110ic1rg\" target=\"_blank\">fallen-valley-53</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27909' max='27909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27909/27909 3:02:53, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.471414</td>\n",
       "      <td>0.816366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.845869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.395608</td>\n",
       "      <td>0.853613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.388986</td>\n",
       "      <td>0.859570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.374445</td>\n",
       "      <td>0.867127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.374441</td>\n",
       "      <td>0.866155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.459371</td>\n",
       "      <td>0.871955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.413407</td>\n",
       "      <td>0.869854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.387477</td>\n",
       "      <td>0.875216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.531806</td>\n",
       "      <td>0.874463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.523761</td>\n",
       "      <td>0.871923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.483733</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.516792</td>\n",
       "      <td>0.872174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.587014</td>\n",
       "      <td>0.874463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.541445</td>\n",
       "      <td>0.877348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.570299</td>\n",
       "      <td>0.872613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.692285</td>\n",
       "      <td>0.874996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.690283</td>\n",
       "      <td>0.875372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.654560</td>\n",
       "      <td>0.875874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.726110</td>\n",
       "      <td>0.874902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.776957</td>\n",
       "      <td>0.875372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.771904</td>\n",
       "      <td>0.875153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.788615</td>\n",
       "      <td>0.875059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-1200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-1200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-1200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-2400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-2400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-3600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-3600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-3600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-4800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-4800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-4800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-6000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-6000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-6000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-7200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-7200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-7200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-7200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-1200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-8400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-8400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-8400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-8400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-8400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-2400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-9600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-9600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-9600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-3600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-10800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-10800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-10800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-10800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-10800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-4800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-12000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-12000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-13200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-13200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-13200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-13200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-13200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-8400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-14400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-14400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-14400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-14400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-14400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-9600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-15600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-15600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-15600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-15600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-15600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-10800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-16800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-16800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-16800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-16800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-16800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-12000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-18000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-18000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-13200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-19200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-19200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-19200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-19200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-19200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-14400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-20400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-20400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-20400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-20400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-20400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-15600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-21600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-21600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-21600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-21600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-21600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-16800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-22800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-22800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-22800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-22800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-22800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-18000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-24000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-24000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-19200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-25200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-25200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-25200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-25200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-25200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-20400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-26400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-26400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-26400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-26400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-26400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-21600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-2/checkpoint-27600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-2/checkpoint-27600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-2/checkpoint-27600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-2/checkpoint-27600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-2/checkpoint-27600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-2/checkpoint-22800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/electra_hyperparameter_tune/run-2/checkpoint-7200 (score: 0.3744414746761322).\n",
      "\u001b[32m[I 2023-01-09 20:07:58,869]\u001b[0m Trial 2 finished with value: 0.8750587866436745 and parameters: {'learning_rate': 3.213114421183878e-05, 'weight_decay': 0.009872847838692694, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 0.8750587866436745.\u001b[0m\n",
      "Trial: {'learning_rate': 6.131552966000004e-05, 'weight_decay': 0.005632471255343468, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27909\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2707a3a5231e4e808aec817a769f346f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▅▆▇▇▇▇██▇█▇██▇███████</td></tr><tr><td>eval/loss</td><td>▃▂▁▁▁▁▂▂▁▄▄▃▃▅▄▄▆▆▆▇███</td></tr><tr><td>eval/runtime</td><td>▁▂▁▃█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▅▁▃▂▃▂▂▂▂▃▂▂▂▃▂▂▃▃▃▂</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▅▁▃▂▃▂▂▂▂▃▂▂▂▃▂▂▃▃▃▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.87506</td></tr><tr><td>eval/loss</td><td>0.78861</td></tr><tr><td>eval/runtime</td><td>169.9792</td></tr><tr><td>eval/samples_per_second</td><td>187.641</td></tr><tr><td>eval/steps_per_second</td><td>11.731</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>27909</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0567</td></tr><tr><td>train/total_flos</td><td>4.314013763789016e+16</td></tr><tr><td>train/train_loss</td><td>0.19889</td></tr><tr><td>train/train_runtime</td><td>10980.8442</td></tr><tr><td>train/train_samples_per_second</td><td>81.329</td></tr><tr><td>train/train_steps_per_second</td><td>2.542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fallen-valley-53</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/110ic1rg\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/110ic1rg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_170503-110ic1rg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32113245970f4cb18846ff6ffacc599d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016707988207538924, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_200808-3j2s0u0a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/3j2s0u0a\" target=\"_blank\">faithful-mountain-54</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27909' max='27909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27909/27909 2:13:09, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>0.512239</td>\n",
       "      <td>0.806365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.831823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.449455</td>\n",
       "      <td>0.835962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.441452</td>\n",
       "      <td>0.841637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.331800</td>\n",
       "      <td>0.436949</td>\n",
       "      <td>0.856623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.403872</td>\n",
       "      <td>0.858630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.312600</td>\n",
       "      <td>0.485469</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.448747</td>\n",
       "      <td>0.863051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.454360</td>\n",
       "      <td>0.864305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.516856</td>\n",
       "      <td>0.867848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.152400</td>\n",
       "      <td>0.566647</td>\n",
       "      <td>0.863364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.518399</td>\n",
       "      <td>0.865935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.466843</td>\n",
       "      <td>0.867942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.591495</td>\n",
       "      <td>0.868726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.604740</td>\n",
       "      <td>0.869321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.578243</td>\n",
       "      <td>0.867816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.702491</td>\n",
       "      <td>0.869509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.743907</td>\n",
       "      <td>0.870858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.681260</td>\n",
       "      <td>0.870952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.795260</td>\n",
       "      <td>0.872676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.816172</td>\n",
       "      <td>0.871829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.835169</td>\n",
       "      <td>0.872551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.821953</td>\n",
       "      <td>0.871579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-1200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-1200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-1200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-2400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-2400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-3600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-3600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-3600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-4800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-4800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-4800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-6000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-6000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-6000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-7200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-7200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-7200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-7200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-1200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-8400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-8400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-8400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-8400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-8400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-2400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-9600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-9600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-9600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-3600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-10800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-10800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-10800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-10800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-10800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-4800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-12000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-12000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-13200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-13200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-13200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-13200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-13200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-8400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-14400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-14400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-14400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-14400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-14400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-9600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-15600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-15600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-15600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-15600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-15600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-10800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-16800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-16800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-16800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-16800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-16800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-12000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-18000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-18000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-13200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-19200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-19200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-19200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-19200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-19200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-14400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-20400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-20400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-20400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-20400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-20400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-15600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-21600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-21600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-21600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-21600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-21600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-16800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-22800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-22800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-22800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-22800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-22800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-18000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-24000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-24000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-19200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-25200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-25200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-25200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-25200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-25200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-20400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-26400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-26400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-26400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-26400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-26400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-21600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-3/checkpoint-27600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-3/checkpoint-27600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-3/checkpoint-27600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-3/checkpoint-27600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-3/checkpoint-27600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-3/checkpoint-22800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/electra_hyperparameter_tune/run-3/checkpoint-7200 (score: 0.40387171506881714).\n",
      "\u001b[32m[I 2023-01-09 22:21:19,850]\u001b[0m Trial 3 finished with value: 0.8715786173381408 and parameters: {'learning_rate': 6.131552966000004e-05, 'weight_decay': 0.005632471255343468, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 0.8750587866436745.\u001b[0m\n",
      "Trial: {'learning_rate': 0.0001431225128275434, 'weight_decay': 0.006463213055981998, 'per_device_train_batch_size': 32}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13958\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ff9c3b4ba48839f5aec4e4da7314a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▄▅▆▇▇▇▇▇▇▇███▇███████</td></tr><tr><td>eval/loss</td><td>▃▂▂▂▂▁▂▂▂▃▄▃▂▄▄▄▆▇▆▇███</td></tr><tr><td>eval/runtime</td><td>█▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▂▂███████████████████</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▂▂███████████████████</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.87158</td></tr><tr><td>eval/loss</td><td>0.82195</td></tr><tr><td>eval/runtime</td><td>102.4359</td></tr><tr><td>eval/samples_per_second</td><td>311.365</td></tr><tr><td>eval/steps_per_second</td><td>19.466</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>27909</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0463</td></tr><tr><td>train/total_flos</td><td>4.314013763789016e+16</td></tr><tr><td>train/train_loss</td><td>0.21246</td></tr><tr><td>train/train_runtime</td><td>7998.8834</td></tr><tr><td>train/train_samples_per_second</td><td>111.648</td></tr><tr><td>train/train_steps_per_second</td><td>3.489</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">faithful-mountain-54</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/3j2s0u0a\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/3j2s0u0a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_200808-3j2s0u0a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4742f87263d747afa08e0e82ed56d7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016722162440419196, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_222128-1ju2vs0k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/1ju2vs0k\" target=\"_blank\">trim-serenity-55</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13958' max='13958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13958/13958 1:16:14, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.099600</td>\n",
       "      <td>1.100513</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>1.099706</td>\n",
       "      <td>0.328515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.098591</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.098900</td>\n",
       "      <td>1.098763</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.098800</td>\n",
       "      <td>1.098714</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098586</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098644</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098560</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.098588</td>\n",
       "      <td>0.336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098587</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.098583</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-1200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-1200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-1200/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-2400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-2400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-2400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-2400/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-3600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-3600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-3600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-3600/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-4800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-4800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-4800/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-6000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-6000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-6000/special_tokens_map.json\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-7200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-7200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-7200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-7200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-7200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-4/checkpoint-1200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-8400\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-8400/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-8400/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-8400/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-8400/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-4/checkpoint-2400] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-9600\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-9600/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-9600/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-4/checkpoint-3600] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-10800\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-10800/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-10800/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-10800/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-10800/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-4/checkpoint-4800] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-12000\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-12000/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-4/checkpoint-6000] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to result/electra_hyperparameter_tune/run-4/checkpoint-13200\n",
      "Configuration saved in result/electra_hyperparameter_tune/run-4/checkpoint-13200/config.json\n",
      "Model weights saved in result/electra_hyperparameter_tune/run-4/checkpoint-13200/pytorch_model.bin\n",
      "tokenizer config file saved in result/electra_hyperparameter_tune/run-4/checkpoint-13200/tokenizer_config.json\n",
      "Special tokens file saved in result/electra_hyperparameter_tune/run-4/checkpoint-13200/special_tokens_map.json\n",
      "Deleting older checkpoint [result/electra_hyperparameter_tune/run-4/checkpoint-7200] due to args.save_total_limit\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from result/electra_hyperparameter_tune/run-4/checkpoint-9600 (score: 1.0985599756240845).\n",
      "\u001b[32m[I 2023-01-09 23:37:45,542]\u001b[0m Trial 4 finished with value: 0.33525630976642107 and parameters: {'learning_rate': 0.0001431225128275434, 'weight_decay': 0.006463213055981998, 'per_device_train_batch_size': 32}. Best is trial 2 with value: 0.8750587866436745.\u001b[0m\n",
      "Trial: {'learning_rate': 8.694525524225553e-05, 'weight_decay': 0.0017718691197736148, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27909\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▁████▇██▇▇</td></tr><tr><td>eval/loss</td><td>█▅▁▂▂▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▁▇▄▅▆▇█▆▃▅</td></tr><tr><td>eval/samples_per_second</td><td>▅█▂▅▄▃▂▁▃▆▃</td></tr><tr><td>eval/steps_per_second</td><td>▅█▂▅▄▃▂▁▃▆▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▃▃▂▁▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▁▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.33526</td></tr><tr><td>eval/loss</td><td>1.09858</td></tr><tr><td>eval/runtime</td><td>101.8355</td></tr><tr><td>eval/samples_per_second</td><td>313.201</td></tr><tr><td>eval/steps_per_second</td><td>19.581</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>13958</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0986</td></tr><tr><td>train/total_flos</td><td>4.314013763789016e+16</td></tr><tr><td>train/train_loss</td><td>1.09887</td></tr><tr><td>train/train_runtime</td><td>4584.134</td></tr><tr><td>train/train_samples_per_second</td><td>194.815</td></tr><tr><td>train/train_steps_per_second</td><td>3.045</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">trim-serenity-55</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/1ju2vs0k\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/1ju2vs0k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_222128-1ju2vs0k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73a850d9b2a48b8a35ea12bc85a6c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016715274937450886, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_233754-2nmml8sk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/2nmml8sk\" target=\"_blank\">vague-jazz-56</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='27909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1200/27909 05:15 < 1:57:15, 3.80 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.099900</td>\n",
       "      <td>1.100556</td>\n",
       "      <td>0.328515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-09 23:43:12,187]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 7.346951137691866e-05, 'weight_decay': 0.00577990236203565, 'per_device_train_batch_size': 16}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27909\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆█</td></tr><tr><td>train/global_step</td><td>▁▆█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.32852</td></tr><tr><td>eval/loss</td><td>1.10056</td></tr><tr><td>eval/runtime</td><td>101.8262</td></tr><tr><td>eval/samples_per_second</td><td>313.23</td></tr><tr><td>eval/steps_per_second</td><td>19.582</td></tr><tr><td>train/epoch</td><td>0.3</td></tr><tr><td>train/global_step</td><td>1200</td></tr><tr><td>train/learning_rate</td><td>8e-05</td></tr><tr><td>train/loss</td><td>1.0999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vague-jazz-56</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/2nmml8sk\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/2nmml8sk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_233754-2nmml8sk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c231a2091b41758482a7a25bd2a9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016675184915463128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_234320-rz66728y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/rz66728y\" target=\"_blank\">wobbly-jazz-57</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='27909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1200/27909 05:18 < 1:58:22, 3.76 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.504765</td>\n",
       "      <td>0.805142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-09 23:48:41,389]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 0.00012651051165973913, 'weight_decay': 0.008071571145432364, 'per_device_train_batch_size': 32}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13958\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca44a566972453cae480956d7745102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆█</td></tr><tr><td>train/global_step</td><td>▁▆█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.80514</td></tr><tr><td>eval/loss</td><td>0.50477</td></tr><tr><td>eval/runtime</td><td>102.0223</td></tr><tr><td>eval/samples_per_second</td><td>312.628</td></tr><tr><td>eval/steps_per_second</td><td>19.545</td></tr><tr><td>train/epoch</td><td>0.3</td></tr><tr><td>train/global_step</td><td>1200</td></tr><tr><td>train/learning_rate</td><td>7e-05</td></tr><tr><td>train/loss</td><td>0.5826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wobbly-jazz-57</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/rz66728y\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/rz66728y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_234320-rz66728y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c9d5ed1c2149d1bd16b2a27ba5e51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016772219662865004, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_234849-40uiukjq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/40uiukjq\" target=\"_blank\">neat-pyramid-58</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='13958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1200/13958 06:31 < 1:09:32, 3.06 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.100233</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-09 23:55:23,632]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 0.0001430781750558233, 'weight_decay': 0.009059199019340488, 'per_device_train_batch_size': 32}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13958\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becea2d8323941ffa58c6a899473580a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆█</td></tr><tr><td>train/global_step</td><td>▁▆█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.33526</td></tr><tr><td>eval/loss</td><td>1.10023</td></tr><tr><td>eval/runtime</td><td>99.562</td></tr><tr><td>eval/samples_per_second</td><td>320.353</td></tr><tr><td>eval/steps_per_second</td><td>20.028</td></tr><tr><td>train/epoch</td><td>0.6</td></tr><tr><td>train/global_step</td><td>1200</td></tr><tr><td>train/learning_rate</td><td>0.00012</td></tr><tr><td>train/loss</td><td>1.0995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">neat-pyramid-58</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/40uiukjq\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/40uiukjq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_234849-40uiukjq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd63bee8ebbe4883a369917910f8c13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01668565645813942, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230109_235530-3ojwyd7e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/3ojwyd7e\" target=\"_blank\">fresh-snowball-59</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='13958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1200/13958 06:35 < 1:10:09, 3.03 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.100165</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-10 00:02:08,157]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "Trial: {'learning_rate': 6.394475774825806e-05, 'weight_decay': 0.0009238250281285176, 'per_device_train_batch_size': 32}\n",
      "loading weights file pytorch_model.bin from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/pytorch_model.bin\n",
      "Some weights of the model checkpoint at tunib/electra-ko-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at tunib/electra-ko-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 127580\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13958\n",
      "  Number of trainable parameters = 110619651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9470b663f7be4d2583c87d16f4476b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆█</td></tr><tr><td>train/global_step</td><td>▁▆█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.33526</td></tr><tr><td>eval/loss</td><td>1.10016</td></tr><tr><td>eval/runtime</td><td>102.0278</td></tr><tr><td>eval/samples_per_second</td><td>312.611</td></tr><tr><td>eval/steps_per_second</td><td>19.544</td></tr><tr><td>train/epoch</td><td>0.6</td></tr><tr><td>train/global_step</td><td>1200</td></tr><tr><td>train/learning_rate</td><td>0.00013</td></tr><tr><td>train/loss</td><td>1.0995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-snowball-59</strong>: <a href=\"https://wandb.ai/sangmi/huggingface/runs/3ojwyd7e\" target=\"_blank\">https://wandb.ai/sangmi/huggingface/runs/3ojwyd7e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_235530-3ojwyd7e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfa9a5004344f1c8f89d3bcfa771a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01676199765255054, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/centos/psw/KSRC/wandb/run-20230110_000216-1zfeass7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sangmi/huggingface/runs/1zfeass7\" target=\"_blank\">fast-water-60</a></strong> to <a href=\"https://wandb.ai/sangmi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='13958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1200/13958 06:33 < 1:09:54, 3.04 it/s, Epoch 0/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.100384</td>\n",
       "      <td>0.335256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 31895\n",
      "  Batch size = 16\n",
      "\u001b[32m[I 2023-01-10 00:08:52,139]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='2', objective=0.8750587866436745, hyperparameters={'learning_rate': 3.213114421183878e-05, 'weight_decay': 0.009872847838692694, 'per_device_train_batch_size': 16})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "trainer.hyperparameter_search(direction='maximize',\n",
    "                             backend='optuna',\n",
    "                             n_trials=10,\n",
    "                             hp_space=my_hp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/centos/.cache/huggingface/hub/models--tunib--electra-ko-base/snapshots/edfb795c9f667b3c5cb7085ca9112997823ce4e8/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"tunib/electra-ko-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file result/electra_hyperparameter_tune/run-2/checkpoint-7200/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"result/electra_hyperparameter_tune/run-2/checkpoint-7200\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file result/electra_hyperparameter_tune/run-2/checkpoint-7200/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at result/electra_hyperparameter_tune/run-2/checkpoint-7200.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='tunib/electra-ko-base', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Tokenizer_NAME = \"tunib/electra-ko-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
    "\n",
    "MODEL_NAME = 'result/electra_hyperparameter_tune/run-2/checkpoint-7200'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(tokenizer.vocab_size)\n",
    "model.to(device)\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n",
      "{'input_ids': tensor([    2,   791, 14921, 23745,  6237,   485, 15213,  2137,   204,  8377,\n",
      "        11304,     3,   791, 14921,  1485,  6020, 11461,  6015, 14521, 13377,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'label': tensor(3)}\n",
      "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다 [SEP] 18일 배를 타고 여행을 떠났습니다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "test_label = label_to_num(test['label'].values)\n",
    "\n",
    "tokenized_test = tokenizer(\n",
    "    list(test['premise']),\n",
    "    list(test['hypothesis']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "test_dataset = BERTDataset(tokenized_test, test_label)\n",
    "\n",
    "print(test_dataset.__len__())\n",
    "print(test_dataset.__getitem__(1665))\n",
    "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 1, 2, 0, 0, 1, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 0, 0, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 2, 1, 0, 2, 0, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 1, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 2, 0, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 2, 0, 1, 0, 2, 0, 2, 1, 1, 0, 2, 1, 1, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 1, 2, 2, 2, 2, 1, 0, 1, 2, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 0, 0, 2, 0, 0, 1, 1, 2, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 2, 1, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 2, 0, 2, 2, 1, 0, 2, 2, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 2, 1, 2, 1, 2, 1, 2, 2, 0, 0, 2, 1, 2, 1, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 0, 0, 1, 1, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 1, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 2, 0, 2, 2, 2, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 2, 2, 2, 1, 1, 1, 0, 1, 0, 1, 2, 0, 2, 2, 0, 2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 2, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 1, 0, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 2, 0, 2, 1, 2, 0, 1, 2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 0, 1, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 2, 1, 2, 1, 0, 2, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 1, 2, 2, 2, 2, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 0, 0, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 0, 1, 0, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 1, 1, 2, 2, 2, 0, 1, 2, 1, 1, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 0, 1, 2, 0, 1, 2, 2, 2, 2, 0, 2, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_pred = []\n",
    "output_prob = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=data['input_ids'].to(device),\n",
    "            attention_mask=data['attention_mask'].to(device),\n",
    "            token_type_ids=data['token_type_ids'].to(device)\n",
    "        )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000503677292726934, 0.9964536428451538, 0.0030427409801632166]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.000503677292726934, 0.9964536428451538, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.053734514862298965, 0.002680903533473611, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.011614812538027763, 0.003720239968970418, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0011501049157232046, 0.9467388391494751, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.012297039851546288, 0.9785420894622803, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               prob\n",
       "0      0  [0.000503677292726934, 0.9964536428451538, 0.0...\n",
       "1      1  [0.053734514862298965, 0.002680903533473611, 0...\n",
       "2      2  [0.011614812538027763, 0.003720239968970418, 0...\n",
       "3      3  [0.0011501049157232046, 0.9467388391494751, 0....\n",
       "4      4  [0.012297039851546288, 0.9785420894622803, 0.0..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(prob_of_output, columns=['index', 'prob'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_of_output = []\n",
    "for i, v in enumerate(output_prob):\n",
    "    prob_of_output.append([i,v])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [0.000503677292726934, 0.9964536428451538, 0.0030427409801632166]],\n",
       " [1, [0.053734514862298965, 0.002680903533473611, 0.9435845017433167]],\n",
       " [2, [0.011614812538027763, 0.003720239968970418, 0.9846648573875427]],\n",
       " [3, [0.0011501049157232046, 0.9467388391494751, 0.052111007273197174]],\n",
       " [4, [0.012297039851546288, 0.9785420894622803, 0.009160801768302917]],\n",
       " [5, [0.002121122321113944, 0.7874798774719238, 0.21039903163909912]],\n",
       " [6, [0.007405277341604233, 0.007436033338308334, 0.9851586222648621]],\n",
       " [7, [0.3682658076286316, 0.4189690351486206, 0.212765172123909]],\n",
       " [8, [0.9745813012123108, 0.002231544116511941, 0.023187166079878807]],\n",
       " [9, [0.07236459851264954, 0.7306638360023499, 0.19697163999080658]],\n",
       " [10, [0.00907385628670454, 0.9000028371810913, 0.0909232422709465]],\n",
       " [11, [0.9796241521835327, 0.0037880379240959883, 0.01658778265118599]],\n",
       " [12, [0.00038295050035230815, 0.9957523345947266, 0.0038646692410111427]],\n",
       " [13, [0.9867089986801147, 0.00841760728508234, 0.004873491823673248]],\n",
       " [14, [0.0021429387852549553, 0.003980581648647785, 0.9938765168190002]],\n",
       " [15, [0.0037626619450747967, 0.000912079936824739, 0.9953252077102661]],\n",
       " [16, [0.9490405321121216, 0.002949586370959878, 0.04800979420542717]],\n",
       " [17, [0.0011518232058733702, 0.001701605855487287, 0.9971465468406677]],\n",
       " [18, [0.0008374006138183177, 0.9907324314117432, 0.008430112153291702]],\n",
       " [19, [0.0013309952337294817, 0.0015570656396448612, 0.9971119165420532]],\n",
       " [20, [0.0007060300558805466, 0.9826953411102295, 0.016598623245954514]],\n",
       " [21, [0.010259237140417099, 0.010854349471628666, 0.9788863658905029]],\n",
       " [22, [0.723028302192688, 0.18745432794094086, 0.08951740711927414]],\n",
       " [23, [0.9941421151161194, 0.001854465575888753, 0.004003394395112991]],\n",
       " [24, [0.0003094435087405145, 0.9946264624595642, 0.005064067896455526]],\n",
       " [25, [0.0023276028223335743, 0.0189397893846035, 0.9787325263023376]],\n",
       " [26, [0.13948412239551544, 0.003085492178797722, 0.8574303388595581]],\n",
       " [27, [0.8455102443695068, 0.002356736920773983, 0.152133047580719]],\n",
       " [28, [0.9739716053009033, 0.0023103237617760897, 0.0237180944532156]],\n",
       " [29, [0.5892155170440674, 0.009167459793388844, 0.40161705017089844]],\n",
       " [30, [0.0007841497426852584, 0.9836137294769287, 0.015602142550051212]],\n",
       " [31, [0.9305335283279419, 0.0528266504406929, 0.016639739274978638]],\n",
       " [32, [0.00045006044092588127, 0.9899131059646606, 0.00963680911809206]],\n",
       " [33, [0.0010090639116242528, 0.01182253286242485, 0.9871683120727539]],\n",
       " [34, [0.017384514212608337, 0.0018127132207155228, 0.9808027744293213]],\n",
       " [35, [0.040562525391578674, 0.27977147698402405, 0.6796659827232361]],\n",
       " [36, [0.2276102900505066, 0.019539879634976387, 0.7528497576713562]],\n",
       " [37, [0.0005972830695100129, 0.998082160949707, 0.0013206250732764602]],\n",
       " [38, [0.9710388779640198, 0.0019695572555065155, 0.02699146792292595]],\n",
       " [39, [0.0004367437504697591, 0.9677574634552002, 0.031805723905563354]],\n",
       " [40, [0.0010890676639974117, 0.026255179196596146, 0.972655713558197]],\n",
       " [41, [0.21894605457782745, 0.039632461965084076, 0.7414215207099915]],\n",
       " [42, [0.002389011438935995, 0.004523868672549725, 0.993087112903595]],\n",
       " [43, [0.009314727038145065, 0.00206478638574481, 0.9886205196380615]],\n",
       " [44, [0.002398495562374592, 0.011917522177100182, 0.9856840372085571]],\n",
       " [45, [0.0005014208145439625, 0.9940151572227478, 0.005483497399836779]],\n",
       " [46, [0.0014074029168114066, 0.0012170918053016067, 0.99737548828125]],\n",
       " [47, [0.9743812680244446, 0.0008049691095948219, 0.02481376752257347]],\n",
       " [48, [0.0029948255978524685, 0.9864107966423035, 0.010594366118311882]],\n",
       " [49, [0.9882453680038452, 0.006478500086814165, 0.0052761356346309185]],\n",
       " [50, [0.0034726005978882313, 0.001349249156191945, 0.99517822265625]],\n",
       " [51, [0.0006149269174784422, 0.9961512684822083, 0.0032337179873138666]],\n",
       " [52, [0.324916273355484, 0.5222955942153931, 0.15278814733028412]],\n",
       " [53, [0.0009800288826227188, 0.0024192878045141697, 0.9966006875038147]],\n",
       " [54, [0.011847189627587795, 0.005571753717958927, 0.9825810790061951]],\n",
       " [55, [0.9282179474830627, 0.026438431814312935, 0.04534362256526947]],\n",
       " [56, [0.0010690104681998491, 0.0036521267611533403, 0.9952788352966309]],\n",
       " [57, [0.0010281368158757687, 0.005727077834308147, 0.9932448267936707]],\n",
       " [58, [0.0517323762178421, 0.06352666765451431, 0.8847408890724182]],\n",
       " [59, [0.010034413076937199, 0.0011474767234176397, 0.9888179898262024]],\n",
       " [60, [0.9829346537590027, 0.004903058055788279, 0.012162232771515846]],\n",
       " [61, [0.0013631954789161682, 0.008356642909348011, 0.9902800917625427]],\n",
       " [62, [0.0012715670745819807, 0.0014244706835597754, 0.99730384349823]],\n",
       " [63, [0.006324705667793751, 0.0031026769429445267, 0.9905726313591003]],\n",
       " [64, [0.008199968375265598, 0.0031443031039088964, 0.988655686378479]],\n",
       " [65, [0.00037944011273793876, 0.9981973767280579, 0.0014232267858460546]],\n",
       " [66, [0.0026999737601727247, 0.0008239050512202084, 0.9964761137962341]],\n",
       " [67, [0.001573039568029344, 0.0016880517359822989, 0.996738851070404]],\n",
       " [68, [0.01139394473284483, 0.0015039605787023902, 0.9871020913124084]],\n",
       " [69, [0.0017572324723005295, 0.9890605211257935, 0.00918219517916441]],\n",
       " [70, [0.9562107920646667, 0.0012960591120645404, 0.04249317944049835]],\n",
       " [71, [0.0011217164574190974, 0.0035231350921094418, 0.9953551292419434]],\n",
       " [72, [0.994309663772583, 0.0024408467579632998, 0.0032495190389454365]],\n",
       " [73, [0.0020183343440294266, 0.9895500540733337, 0.008431565947830677]],\n",
       " [74, [0.001161132357083261, 0.002026352798566222, 0.9968125224113464]],\n",
       " [75, [0.004076729994267225, 0.0014759424375370145, 0.9944473505020142]],\n",
       " [76, [0.9462699294090271, 0.003803228959441185, 0.049926891922950745]],\n",
       " [77, [0.0033210190013051033, 0.0012279835063964128, 0.995451033115387]],\n",
       " [78, [0.001113679027184844, 0.0016931422287598252, 0.9971931576728821]],\n",
       " [79, [0.0015751478495076299, 0.9801666140556335, 0.01825825683772564]],\n",
       " [80, [0.0018450821517035365, 0.0017340036574751139, 0.9964209794998169]],\n",
       " [81, [0.007246129214763641, 0.005042867735028267, 0.9877110123634338]],\n",
       " [82, [0.0004464861995074898, 0.9968913197517395, 0.002662188373506069]],\n",
       " [83, [0.12343067675828934, 0.7003665566444397, 0.17620278894901276]],\n",
       " [84, [0.9121029376983643, 0.003523294348269701, 0.08437377214431763]],\n",
       " [85, [0.0027222291100770235, 0.9894060492515564, 0.007871740497648716]],\n",
       " [86, [0.0021167497616261244, 0.003896911395713687, 0.9939863681793213]],\n",
       " [87, [0.0006443304009735584, 0.9965866804122925, 0.0027690210845321417]],\n",
       " [88, [0.9846531748771667, 0.0015339809469878674, 0.013812810182571411]],\n",
       " [89, [0.000849657051730901, 0.00977459829300642, 0.9893757104873657]],\n",
       " [90, [0.0011075532529503107, 0.9968417882919312, 0.0020506519358605146]],\n",
       " [91, [0.00754521694034338, 0.0010583943221718073, 0.9913963675498962]],\n",
       " [92, [0.991166889667511, 0.0037525834050029516, 0.0050806039944291115]],\n",
       " [93, [0.00030750175938010216, 0.9825630187988281, 0.017129534855484962]],\n",
       " [94, [0.9767627120018005, 0.002000828506425023, 0.02123655192553997]],\n",
       " [95, [0.6201614737510681, 0.0044378372840583324, 0.37540072202682495]],\n",
       " [96, [0.00045235242578200996, 0.9966391324996948, 0.002908466150984168]],\n",
       " [97, [0.004045412410050631, 0.2708950936794281, 0.725059449672699]],\n",
       " [98, [0.9757964611053467, 0.0023211392108350992, 0.02188246138393879]],\n",
       " [99, [0.002507786499336362, 0.001390955876559019, 0.9961012601852417]],\n",
       " [100, [0.0015433451626449823, 0.0012017687549814582, 0.9972549080848694]],\n",
       " [101, [0.9739100933074951, 0.0017906720750033855, 0.02429921180009842]],\n",
       " [102, [0.0034045111387968063, 0.004524776246398687, 0.992070734500885]],\n",
       " [103, [0.994838535785675, 0.0009447882766835392, 0.004216611385345459]],\n",
       " [104, [0.0017552644712850451, 0.001877402770332992, 0.996367335319519]],\n",
       " [105, [0.9615573287010193, 0.022676894441246986, 0.0157657191157341]],\n",
       " [106, [0.002840193919837475, 0.002790021011605859, 0.9943698048591614]],\n",
       " [107, [0.00547404307872057, 0.0015756089705973864, 0.9929503202438354]],\n",
       " [108, [0.024332880973815918, 0.5565023422241211, 0.4191648066043854]],\n",
       " [109, [0.8541656732559204, 0.11247549951076508, 0.033358775079250336]],\n",
       " [110, [0.0007159892120398581, 0.9958873391151428, 0.0033966894261538982]],\n",
       " [111, [0.0013534682802855968, 0.001769605209119618, 0.9968769550323486]],\n",
       " [112, [0.0006795802037231624, 0.9957078695297241, 0.003612472442910075]],\n",
       " [113, [0.9906660914421082, 0.0017623776802793145, 0.007571511436253786]],\n",
       " [114, [0.00173332286067307, 0.0027164160273969173, 0.995550274848938]],\n",
       " [115, [0.5702488422393799, 0.040715523064136505, 0.3890356421470642]],\n",
       " [116, [0.7803575396537781, 0.12801721692085266, 0.09162525832653046]],\n",
       " [117, [0.0005661696777679026, 0.9857150912284851, 0.013718763366341591]],\n",
       " [118, [0.0020316042937338352, 0.949343204498291, 0.04862517863512039]],\n",
       " [119, [0.00047576724318787456, 0.9849551320075989, 0.014569094404578209]],\n",
       " [120, [0.0006838170229457319, 0.9963961243629456, 0.002920116065070033]],\n",
       " [121, [0.006160303950309753, 0.05293243005871773, 0.9409072995185852]],\n",
       " [122, [0.0009254731703549623, 0.9966513514518738, 0.002423156052827835]],\n",
       " [123, [0.0012304327683523297, 0.0016363809118047357, 0.9971332550048828]],\n",
       " [124, [0.045565176755189896, 0.008289842866361141, 0.9461449384689331]],\n",
       " [125, [0.40001434087753296, 0.07403957843780518, 0.5259460806846619]],\n",
       " [126, [0.9901711344718933, 0.0027505524922162294, 0.007078404538333416]],\n",
       " [127, [0.018853407353162766, 0.9734105467796326, 0.0077360570430755615]],\n",
       " [128, [0.0013849695678800344, 0.993034839630127, 0.005580219905823469]],\n",
       " [129, [0.0034937108866870403, 0.0014479276724159718, 0.9950584173202515]],\n",
       " [130, [0.015417276881635189, 0.9451854825019836, 0.03939728066325188]],\n",
       " [131, [0.009430951438844204, 0.0009470919612795115, 0.9896219968795776]],\n",
       " [132, [0.006598257459700108, 0.9672789573669434, 0.026122773066163063]],\n",
       " [133, [0.5560767650604248, 0.01980115845799446, 0.4241220951080322]],\n",
       " [134, [0.005765797104686499, 0.002057556062936783, 0.9921767115592957]],\n",
       " [135, [0.9828169345855713, 0.00446558790281415, 0.012717418372631073]],\n",
       " [136, [0.7586397528648376, 0.12937325239181519, 0.11198700964450836]],\n",
       " [137, [0.0012666808906942606, 0.0012573215644806623, 0.9974759221076965]],\n",
       " [138, [0.0006150664994493127, 0.9644511342048645, 0.034933801740407944]],\n",
       " [139, [0.00040312434430234134, 0.9951647520065308, 0.004432086832821369]],\n",
       " [140, [0.0032449173741042614, 0.0030070138163864613, 0.9937480688095093]],\n",
       " [141, [0.0015656910836696625, 0.0077548255212605, 0.9906794428825378]],\n",
       " [142, [0.0014293320709839463, 0.005193738732486963, 0.9933769106864929]],\n",
       " [143, [0.9112680554389954, 0.03309432044625282, 0.05563763901591301]],\n",
       " [144, [0.01279221847653389, 0.006986179389059544, 0.9802215695381165]],\n",
       " [145, [0.011229750700294971, 0.0033885177690535784, 0.9853817224502563]],\n",
       " [146, [0.987733006477356, 0.00402795197442174, 0.008239012211561203]],\n",
       " [147, [0.0006174417212605476, 0.9943845272064209, 0.00499807670712471]],\n",
       " [148, [0.0013003540225327015, 0.0020005826372653246, 0.9966990351676941]],\n",
       " [149, [0.0014248723164200783, 0.0015227129915729165, 0.9970524311065674]],\n",
       " [150, [0.0007271302165463567, 0.9953789710998535, 0.003893939545378089]],\n",
       " [151, [0.9782112836837769, 0.005411518272012472, 0.01637726090848446]],\n",
       " [152, [0.0038875392638146877, 0.7835559844970703, 0.21255651116371155]],\n",
       " [153, [0.008979898877441883, 0.2815956771373749, 0.7094243764877319]],\n",
       " [154, [0.9860538840293884, 0.008491123095154762, 0.005454989615827799]],\n",
       " [155, [0.9944128394126892, 0.0020945039577782154, 0.0034926552325487137]],\n",
       " [156, [0.9948256015777588, 0.0012220731005072594, 0.003952337428927422]],\n",
       " [157, [0.061181940138339996, 0.5918264985084534, 0.3469915986061096]],\n",
       " [158, [0.022239554673433304, 0.008155683986842632, 0.9696047306060791]],\n",
       " [159, [0.0017252331599593163, 0.8640493154525757, 0.1342255026102066]],\n",
       " [160, [0.04489021748304367, 0.004515967797487974, 0.9505937695503235]],\n",
       " [161, [0.9858860969543457, 0.0025726640596985817, 0.011541304178535938]],\n",
       " [162, [0.0009133580606430769, 0.002133284928277135, 0.9969533681869507]],\n",
       " [163, [0.9510936737060547, 0.017140505835413933, 0.03176578879356384]],\n",
       " [164, [0.003750365460291505, 0.011482500471174717, 0.9847671389579773]],\n",
       " [165, [0.004729514475911856, 0.32041096687316895, 0.6748594641685486]],\n",
       " [166, [0.012173990719020367, 0.0011611004592850804, 0.986664891242981]],\n",
       " [167, [0.9928677082061768, 0.001649370533414185, 0.005482978653162718]],\n",
       " [168, [0.001548544387333095, 0.0014813435263931751, 0.9969700574874878]],\n",
       " [169, [0.9953113198280334, 0.0017402236117050052, 0.002948485082015395]],\n",
       " [170, [0.009595395997166634, 0.09471427649259567, 0.8956902623176575]],\n",
       " [171, [0.0015628847759217024, 0.0021155301947146654, 0.9963215589523315]],\n",
       " [172, [0.2830813527107239, 0.23643015325069427, 0.4804885685443878]],\n",
       " [173, [0.0018612504936754704, 0.002510883379727602, 0.9956278800964355]],\n",
       " [174, [0.003113378770649433, 0.3987427055835724, 0.598143994808197]],\n",
       " [175, [0.008650921285152435, 0.4686129689216614, 0.5227360725402832]],\n",
       " [176, [0.006263766437768936, 0.008596373721957207, 0.9851399064064026]],\n",
       " [177, [0.0015830716583877802, 0.0028156396001577377, 0.9956012964248657]],\n",
       " [178, [0.0004219428519718349, 0.998002827167511, 0.0015752814942970872]],\n",
       " [179, [0.003147311042994261, 0.04136315733194351, 0.9554895758628845]],\n",
       " [180, [0.0005626166239380836, 0.9957156777381897, 0.0037217375356703997]],\n",
       " [181, [0.0011943662539124489, 0.0013342555612325668, 0.9974714517593384]],\n",
       " [182, [0.004021938890218735, 0.04365244507789612, 0.9523256421089172]],\n",
       " [183, [0.0068952892906963825, 0.008875846862792969, 0.9842288494110107]],\n",
       " [184, [0.00243365322239697, 0.001415325328707695, 0.9961510896682739]],\n",
       " [185, [0.0018420537235215306, 0.0038608675822615623, 0.9942970871925354]],\n",
       " [186, [0.0005023559788241982, 0.991267740726471, 0.008229873143136501]],\n",
       " [187, [0.0019278023391962051, 0.0019529856508597732, 0.9961191415786743]],\n",
       " [188, [0.9819080233573914, 0.0020649482030421495, 0.01602712832391262]],\n",
       " [189, [0.0019338486017659307, 0.9167909622192383, 0.08127520978450775]],\n",
       " [190, [0.3271859288215637, 0.0521584078669548, 0.6206556558609009]],\n",
       " [191, [0.9554645419120789, 0.0014929311582818627, 0.043042611330747604]],\n",
       " [192, [0.0004396311705932021, 0.9935756325721741, 0.005984796676784754]],\n",
       " [193, [0.005179861560463905, 0.0010199898388236761, 0.9938001036643982]],\n",
       " [194, [0.001367264660075307, 0.0019023512722924352, 0.9967304468154907]],\n",
       " [195, [0.9728748798370361, 0.005555292125791311, 0.021569818258285522]],\n",
       " [196, [0.4685260057449341, 0.008108771406114101, 0.5233652591705322]],\n",
       " [197, [0.008022958412766457, 0.017676297575235367, 0.9743006825447083]],\n",
       " [198, [0.9645541906356812, 0.005939725786447525, 0.029506081715226173]],\n",
       " [199, [0.00539913447573781, 0.0022958340123295784, 0.9923050999641418]],\n",
       " [200, [0.004598827566951513, 0.0035736579447984695, 0.9918274879455566]],\n",
       " [201, [0.002723532263189554, 0.0014462950639426708, 0.995830237865448]],\n",
       " [202, [0.9677138328552246, 0.0024176491424441338, 0.029868578538298607]],\n",
       " [203, [0.0003360939444974065, 0.9965921640396118, 0.00307180592790246]],\n",
       " [204, [0.0003240477526560426, 0.997713565826416, 0.0019623618572950363]],\n",
       " [205, [0.9936050772666931, 0.00169095688033849, 0.004704010672867298]],\n",
       " [206, [0.9742386937141418, 0.003290745196864009, 0.022470535710453987]],\n",
       " [207, [0.0013002913910895586, 0.003575806738808751, 0.9951239228248596]],\n",
       " [208, [0.9848633408546448, 0.00782174151390791, 0.00731487013399601]],\n",
       " [209, [0.0009781840490177274, 0.0041957758367061615, 0.9948260188102722]],\n",
       " [210, [0.006503613665699959, 0.9869802594184875, 0.006516091525554657]],\n",
       " [211, [0.0007777411956340075, 0.9958003163337708, 0.0034218821674585342]],\n",
       " [212, [0.00034191671875305474, 0.9956315755844116, 0.004026493523269892]],\n",
       " [213, [0.0025503928773105145, 0.0009822673164308071, 0.9964673519134521]],\n",
       " [214, [0.0005677790031768382, 0.8930966854095459, 0.10633549839258194]],\n",
       " [215, [0.0005438402877189219, 0.9820886254310608, 0.017367573454976082]],\n",
       " [216, [0.001683119684457779, 0.7211160063743591, 0.277200847864151]],\n",
       " [217, [0.9835952520370483, 0.0046470919623970985, 0.0117576252669096]],\n",
       " [218, [0.001040646806359291, 0.992865800857544, 0.006093592848628759]],\n",
       " [219, [0.0030649856198579073, 0.990536630153656, 0.00639843475073576]],\n",
       " [220, [0.004628095775842667, 0.00336633063852787, 0.9920056462287903]],\n",
       " [221, [0.01317836344242096, 0.009142419323325157, 0.9776792526245117]],\n",
       " [222, [0.9847679734230042, 0.0017062954138964415, 0.013525781221687794]],\n",
       " [223, [0.0003342103445902467, 0.9970255494117737, 0.002640258753672242]],\n",
       " [224, [0.0018476250115782022, 0.0022327895276248455, 0.9959194660186768]],\n",
       " [225, [0.006315014790743589, 0.7461691498756409, 0.24751588702201843]],\n",
       " [226, [0.0005553180817514658, 0.9933998584747314, 0.006044883280992508]],\n",
       " [227, [0.0015145068755373359, 0.001234153751283884, 0.9972513318061829]],\n",
       " [228, [0.004161756485700607, 0.8959208130836487, 0.09991737455129623]],\n",
       " [229, [0.006969602312892675, 0.41556912660598755, 0.577461302280426]],\n",
       " [230, [0.9835472702980042, 0.002862080931663513, 0.013590657152235508]],\n",
       " [231, [0.0012330770259723067, 0.0014302852796390653, 0.9973366856575012]],\n",
       " [232, [0.7052870988845825, 0.05725686624646187, 0.23745602369308472]],\n",
       " [233, [0.954289436340332, 0.00690153893083334, 0.038808997720479965]],\n",
       " [234, [0.9855011105537415, 0.0010409853421151638, 0.013457952067255974]],\n",
       " [235, [0.0017306898953393102, 0.0024265970569103956, 0.9958426356315613]],\n",
       " [236, [0.0027921011205762625, 0.0010994801996275783, 0.9961084723472595]],\n",
       " [237, [0.0025706072337925434, 0.060857851058244705, 0.9365715384483337]],\n",
       " [238, [0.9942545294761658, 0.0015249712159857154, 0.004220579285174608]],\n",
       " [239, [0.9896398782730103, 0.0019306022441014647, 0.008429552428424358]],\n",
       " [240, [0.9944539666175842, 0.0013975444016978145, 0.00414845859631896]],\n",
       " [241, [0.0005945232696831226, 0.9964404702186584, 0.0029650088399648666]],\n",
       " [242, [0.0009596996242180467, 0.005755891557782888, 0.9932844638824463]],\n",
       " [243, [0.0018311013700440526, 0.008611448109149933, 0.9895575642585754]],\n",
       " [244, [0.001598954200744629, 0.001207021763548255, 0.9971939325332642]],\n",
       " [245, [0.775421679019928, 0.02557692490518093, 0.1990014612674713]],\n",
       " [246, [0.002198438160121441, 0.0010004538344219327, 0.9968011379241943]],\n",
       " [247, [0.0015027370536699891, 0.0028562312945723534, 0.9956409931182861]],\n",
       " [248, [0.0025739483535289764, 0.29820987582206726, 0.6992161870002747]],\n",
       " [249, [0.008659224957227707, 0.9756286144256592, 0.015712132677435875]],\n",
       " [250, [0.9061163663864136, 0.0011209758231416345, 0.09276257455348969]],\n",
       " [251, [0.0025337946135550737, 0.835837721824646, 0.16162842512130737]],\n",
       " [252, [0.051655370742082596, 0.0007898123003542423, 0.9475548267364502]],\n",
       " [253, [0.964656412601471, 0.0012858527479693294, 0.03405769541859627]],\n",
       " [254, [0.0028971366118639708, 0.37421706318855286, 0.6228857636451721]],\n",
       " [255, [0.0034441929310560226, 0.00238371011801064, 0.9941721558570862]],\n",
       " [256, [0.0038217806722968817, 0.004190470091998577, 0.9919878244400024]],\n",
       " [257, [0.016652008518576622, 0.8137941360473633, 0.16955387592315674]],\n",
       " [258, [0.99134361743927, 0.0055994195863604546, 0.0030570654198527336]],\n",
       " [259, [0.9912126660346985, 0.0008762210491113365, 0.007911130785942078]],\n",
       " [260, [0.49779385328292847, 0.26053327322006226, 0.24167294800281525]],\n",
       " [261, [0.9881008863449097, 0.002432030625641346, 0.009467105381190777]],\n",
       " [262, [0.0011237255530431867, 0.012839267961680889, 0.9860369563102722]],\n",
       " [263, [0.00137371348682791, 0.002550887642428279, 0.9960753321647644]],\n",
       " [264, [0.0025395131669938564, 0.0027217704337090254, 0.9947386384010315]],\n",
       " [265, [0.0021452833898365498, 0.0021950516384094954, 0.9956596493721008]],\n",
       " [266, [0.4653310179710388, 0.45981889963150024, 0.07485005259513855]],\n",
       " [267, [0.9898279905319214, 0.002518421271815896, 0.007653568871319294]],\n",
       " [268, [0.005173958837985992, 0.05591990053653717, 0.9389062523841858]],\n",
       " [269, [0.9952497482299805, 0.0013585188426077366, 0.0033917739056050777]],\n",
       " [270, [0.011767378076910973, 0.29285338521003723, 0.6953792572021484]],\n",
       " [271, [0.0037335497327148914, 0.0022347194608300924, 0.9940317273139954]],\n",
       " [272, [0.9154284000396729, 0.031012743711471558, 0.053558822721242905]],\n",
       " [273, [0.9413726329803467, 0.004502966068685055, 0.05412445589900017]],\n",
       " [274, [0.021402660757303238, 0.00530090881511569, 0.9732965230941772]],\n",
       " [275, [0.0005593777750618756, 0.9938676953315735, 0.005572950001806021]],\n",
       " [276, [0.0070757027715444565, 0.9839586019515991, 0.008965669199824333]],\n",
       " [277, [0.001233976799994707, 0.9888073205947876, 0.009958671405911446]],\n",
       " [278, [0.0028898639138787985, 0.0022488601971417665, 0.9948613047599792]],\n",
       " [279, [0.0010639699175953865, 0.011320555582642555, 0.9876154661178589]],\n",
       " [280, [0.00242670439183712, 0.013963615521788597, 0.983609676361084]],\n",
       " [281, [0.8732977509498596, 0.007412577513605356, 0.11928968876600266]],\n",
       " [282, [0.0426795557141304, 0.07528389990329742, 0.8820365071296692]],\n",
       " [283, [0.9935963153839111, 0.0027485541068017483, 0.0036551039665937424]],\n",
       " [284, [0.0024252922739833593, 0.8923341035842896, 0.10524065792560577]],\n",
       " [285, [0.9910679459571838, 0.0025299862027168274, 0.006402129773050547]],\n",
       " [286, [0.005544173531234264, 0.05677777901291847, 0.9376780986785889]],\n",
       " [287, [0.009652728214859962, 0.942059338092804, 0.04828791320323944]],\n",
       " [288, [0.9931668639183044, 0.0024186265654861927, 0.00441450159996748]],\n",
       " [289, [0.00526037672534585, 0.02856641449034214, 0.9661732316017151]],\n",
       " [290, [0.983460009098053, 0.003244285238906741, 0.013295697048306465]],\n",
       " [291, [0.00041754526318982244, 0.9971182346343994, 0.002464239951223135]],\n",
       " [292, [0.9914274215698242, 0.004502539988607168, 0.004070055205374956]],\n",
       " [293, [0.0033612900879234076, 0.0040323189459741116, 0.9926062822341919]],\n",
       " [294, [0.9778456091880798, 0.003195095108821988, 0.018959226086735725]],\n",
       " [295, [0.000387349515222013, 0.9974982142448425, 0.0021144018974155188]],\n",
       " [296, [0.0005867868894711137, 0.996960461139679, 0.002452721120789647]],\n",
       " [297, [0.018737463280558586, 0.9746994972229004, 0.0065630157478153706]],\n",
       " [298, [0.0010148874716833234, 0.0018229199340566993, 0.9971621632575989]],\n",
       " [299, [0.2365124225616455, 0.009736290201544762, 0.7537512183189392]],\n",
       " [300, [0.1822827011346817, 0.0016255100490525365, 0.816091775894165]],\n",
       " [301, [0.993055522441864, 0.0016964890528470278, 0.005247972439974546]],\n",
       " [302, [0.0007185094873420894, 0.006181090138852596, 0.9931004047393799]],\n",
       " [303, [0.8643292188644409, 0.11696868389844894, 0.018702086061239243]],\n",
       " [304, [0.5076087117195129, 0.4201453924179077, 0.07224585860967636]],\n",
       " [305, [0.9851623177528381, 0.0012540003517642617, 0.013583659194409847]],\n",
       " [306, [0.9112208485603333, 0.06786152720451355, 0.020917721092700958]],\n",
       " [307, [0.0005131775978952646, 0.9966270923614502, 0.0028598180506378412]],\n",
       " [308, [0.8738153576850891, 0.01080718170851469, 0.11537744849920273]],\n",
       " [309, [0.9894599914550781, 0.0016191847389563918, 0.008920860476791859]],\n",
       " [310, [0.015990590676665306, 0.0008212247048504651, 0.9831882119178772]],\n",
       " [311, [0.00023531333135906607, 0.9974576830863953, 0.002307033399119973]],\n",
       " [312, [0.059016454964876175, 0.006801865994930267, 0.9341816902160645]],\n",
       " [313, [0.0022440829779952765, 0.002056882018223405, 0.9956990480422974]],\n",
       " [314, [0.0017834585160017014, 0.0019427217775955796, 0.9962737560272217]],\n",
       " [315, [0.0019242579583078623, 0.00204133871011436, 0.9960344433784485]],\n",
       " [316, [0.09325999021530151, 0.01303365733474493, 0.8937063813209534]],\n",
       " [317, [0.0011794035090133548, 0.002097525168210268, 0.9967231154441833]],\n",
       " [318, [0.9926544427871704, 0.0019339454593136907, 0.005411659367382526]],\n",
       " [319, [0.9439922571182251, 0.010589799843728542, 0.04541797563433647]],\n",
       " [320, [0.9162390232086182, 0.0012920700246468186, 0.08246885985136032]],\n",
       " [321, [0.0013439639005810022, 0.0014841904630884528, 0.9971718192100525]],\n",
       " [322, [0.0017253465484827757, 0.0013747414341196418, 0.9968999624252319]],\n",
       " [323, [0.09170552343130112, 0.007773885037750006, 0.9005206227302551]],\n",
       " [324, [0.021718325093388557, 0.5926397442817688, 0.3856419622898102]],\n",
       " [325, [0.5469985008239746, 0.016176272183656693, 0.4368251860141754]],\n",
       " [326, [0.0006379809346981347, 0.9968444108963013, 0.0025176904164254665]],\n",
       " [327, [0.08137734234333038, 0.011081160977482796, 0.9075414538383484]],\n",
       " [328, [0.0024134921841323376, 0.9667734503746033, 0.0308130644261837]],\n",
       " [329, [0.0003976425505243242, 0.9962181448936462, 0.0033841754775494337]],\n",
       " [330, [0.0015443186275660992, 0.0013166883727535605, 0.9971389770507812]],\n",
       " [331, [0.9830151796340942, 0.008170461282134056, 0.008814376778900623]],\n",
       " [332, [0.9705604314804077, 0.001626855111680925, 0.027812736108899117]],\n",
       " [333, [0.021956635639071465, 0.962125837802887, 0.015917440876364708]],\n",
       " [334, [0.0006182243814691901, 0.9919988512992859, 0.007382916286587715]],\n",
       " [335, [0.0009788498282432556, 0.995735764503479, 0.003285359125584364]],\n",
       " [336, [0.7601510286331177, 0.0019758676644414663, 0.23787307739257812]],\n",
       " [337, [0.00036241530324332416, 0.9972018003463745, 0.0024357496295124292]],\n",
       " [338, [0.002685540821403265, 0.9832627773284912, 0.014051724225282669]],\n",
       " [339, [0.06845388561487198, 0.006122262217104435, 0.9254238605499268]],\n",
       " [340, [0.0011374655878171325, 0.9835345149040222, 0.01532800868153572]],\n",
       " [341, [0.001372958766296506, 0.002387038432061672, 0.9962399005889893]],\n",
       " [342, [0.0024973612744361162, 0.6466533541679382, 0.3508492708206177]],\n",
       " [343, [0.0006561845075339079, 0.9976193308830261, 0.0017244260525330901]],\n",
       " [344, [0.0009675773326307535, 0.006628852803260088, 0.992403507232666]],\n",
       " [345, [0.9923586249351501, 0.0014501899713650346, 0.006191101390868425]],\n",
       " [346, [0.0009807118913158774, 0.997112512588501, 0.001906752004288137]],\n",
       " [347, [0.0007427725940942764, 0.9899915456771851, 0.009265737608075142]],\n",
       " [348, [0.0012636409373953938, 0.9902993440628052, 0.008436952717602253]],\n",
       " [349, [0.0015521395253017545, 0.0017899840604513884, 0.9966578483581543]],\n",
       " [350, [0.013742693699896336, 0.9646811485290527, 0.02157612144947052]],\n",
       " [351, [0.0402214452624321, 0.0013212355552241206, 0.9584572911262512]],\n",
       " [352, [0.0688975602388382, 0.9252980947494507, 0.005804393440485001]],\n",
       " [353, [0.01046267244964838, 0.2737140953540802, 0.715823233127594]],\n",
       " [354, [0.0009782328270375729, 0.007583316881209612, 0.9914383888244629]],\n",
       " [355, [0.15316133201122284, 0.19673508405685425, 0.6501036286354065]],\n",
       " [356, [0.0010688420152291656, 0.012026932090520859, 0.9869042038917542]],\n",
       " [357, [0.9803667664527893, 0.0051357257179915905, 0.01449759490787983]],\n",
       " [358, [0.0004630575713235885, 0.9966328740119934, 0.0029040600638836622]],\n",
       " [359, [0.0011725904187187552, 0.0015835233498364687, 0.9972438812255859]],\n",
       " [360, [0.009778386913239956, 0.9772327542304993, 0.012988844886422157]],\n",
       " [361, [0.0004907458205707371, 0.9975941777229309, 0.0019150965381413698]],\n",
       " [362, [0.014094117097556591, 0.5804106593132019, 0.40549522638320923]],\n",
       " [363, [0.0019735628738999367, 0.002939193742349744, 0.9950873255729675]],\n",
       " [364, [0.000432067085057497, 0.9958814382553101, 0.0036865537986159325]],\n",
       " [365, [0.0065530696883797646, 0.022579548880457878, 0.9708672761917114]],\n",
       " [366, [0.004941853228956461, 0.05178945139050484, 0.9432686567306519]],\n",
       " [367, [0.9898768067359924, 0.001300451229326427, 0.008822725154459476]],\n",
       " [368, [0.0014918734086677432, 0.9964175224304199, 0.0020906489808112383]],\n",
       " [369, [0.005935331340879202, 0.005276574287563562, 0.9887880682945251]],\n",
       " [370, [0.0003014783433172852, 0.9961147308349609, 0.003583792131394148]],\n",
       " [371, [0.004995249677449465, 0.12757660448551178, 0.867428183555603]],\n",
       " [372, [0.9846840500831604, 0.009771300479769707, 0.005544552579522133]],\n",
       " [373, [0.017658866941928864, 0.0006321691325865686, 0.9817090034484863]],\n",
       " [374, [0.0026015457697212696, 0.0027265511453151703, 0.9946720004081726]],\n",
       " [375, [0.9820582270622253, 0.0023023816756904125, 0.015639346092939377]],\n",
       " [376, [0.9937604069709778, 0.002090537454932928, 0.004149057902395725]],\n",
       " [377, [0.0032884671818464994, 0.005652497988194227, 0.9910590052604675]],\n",
       " [378, [0.8454143404960632, 0.017328744754195213, 0.137256920337677]],\n",
       " [379, [0.020052213221788406, 0.010723015293478966, 0.9692248106002808]],\n",
       " [380, [0.9904449582099915, 0.0017097601667046547, 0.007845329120755196]],\n",
       " [381, [0.0018261534860357642, 0.002495145658031106, 0.995678722858429]],\n",
       " [382, [0.0006444086320698261, 0.9972233772277832, 0.0021321941167116165]],\n",
       " [383, [0.0008872854523360729, 0.003150149015709758, 0.9959626793861389]],\n",
       " [384, [0.9861401319503784, 0.0027149594388902187, 0.011144918389618397]],\n",
       " [385, [0.00858811940997839, 0.05490085482597351, 0.9365110993385315]],\n",
       " [386, [0.984311044216156, 0.0013240538537502289, 0.014364845119416714]],\n",
       " [387, [0.6699008345603943, 0.008632315322756767, 0.321466863155365]],\n",
       " [388, [0.0019708946347236633, 0.00395051296800375, 0.994078516960144]],\n",
       " [389, [0.000556988175958395, 0.9919677376747131, 0.007475306745618582]],\n",
       " [390, [0.0020132518839091063, 0.0016753542004153132, 0.996311366558075]],\n",
       " [391, [0.07304054498672485, 0.0584358349442482, 0.8685235977172852]],\n",
       " [392, [0.00048776870244182646, 0.9973382353782654, 0.002174018183723092]],\n",
       " [393, [0.0011992924846708775, 0.20673403143882751, 0.7920666933059692]],\n",
       " [394, [0.0010663459543138742, 0.9954174757003784, 0.003516132477670908]],\n",
       " [395, [0.0007050657877698541, 0.9272075295448303, 0.07208743691444397]],\n",
       " [396, [0.4254326820373535, 0.03101659193634987, 0.5435506701469421]],\n",
       " [397, [0.30851301550865173, 0.006370356306433678, 0.6851165890693665]],\n",
       " [398, [0.0005766734248027205, 0.9859159588813782, 0.013507306575775146]],\n",
       " [399, [0.015297994017601013, 0.002163846278563142, 0.9825381636619568]],\n",
       " [400, [0.001583737088367343, 0.9906224608421326, 0.0077938297763466835]],\n",
       " [401, [0.014595041051506996, 0.0026141875423491, 0.9827908277511597]],\n",
       " [402, [0.0008870337042026222, 0.9906875491142273, 0.008425449952483177]],\n",
       " [403, [0.00038572028279304504, 0.9955549836158752, 0.004059290513396263]],\n",
       " [404, [0.9798363447189331, 0.002007021103054285, 0.01815658062696457]],\n",
       " [405, [0.0015677318442612886, 0.0013018128229305148, 0.9971304535865784]],\n",
       " [406, [0.005555989686399698, 0.011980582028627396, 0.9824634790420532]],\n",
       " [407, [0.001073776395060122, 0.001841146731749177, 0.9970850348472595]],\n",
       " [408, [0.000583132088650018, 0.9844739437103271, 0.014942909590899944]],\n",
       " [409, [0.004293104633688927, 0.001215329160913825, 0.9944915771484375]],\n",
       " [410, [0.0009943555342033505, 0.9865478873252869, 0.0124577721580863]],\n",
       " [411, [0.0005161942099221051, 0.9967336654663086, 0.0027501489967107773]],\n",
       " [412, [0.0008525103912688792, 0.9973898530006409, 0.0017576271202415228]],\n",
       " [413, [0.0003673892642837018, 0.9972234964370728, 0.0024091508239507675]],\n",
       " [414, [0.002333695301786065, 0.030406828969717026, 0.9672594666481018]],\n",
       " [415, [0.0030514595564454794, 0.992169201374054, 0.00477931834757328]],\n",
       " [416, [0.0005645401543006301, 0.9974552989006042, 0.001980177126824856]],\n",
       " [417, [0.9688320159912109, 0.01883460395038128, 0.012333367019891739]],\n",
       " [418, [0.20222769677639008, 0.029976975172758102, 0.7677952647209167]],\n",
       " [419, [0.0006704836268909276, 0.9882733821868896, 0.011056151241064072]],\n",
       " [420, [0.012130452319979668, 0.0037771076895296574, 0.9840924739837646]],\n",
       " [421, [0.048277534544467926, 0.008862926624715328, 0.9428596496582031]],\n",
       " [422, [0.5315120816230774, 0.003961073234677315, 0.46452683210372925]],\n",
       " [423, [0.0030293387826532125, 0.0009017735137604177, 0.9960689544677734]],\n",
       " [424, [0.9926689863204956, 0.0008831190643832088, 0.006447802763432264]],\n",
       " [425, [0.024438081309199333, 0.002462472766637802, 0.9730993509292603]],\n",
       " [426, [0.04231791943311691, 0.013889405876398087, 0.9437925815582275]],\n",
       " [427, [0.0006184010999277234, 0.9971179962158203, 0.0022636649664491415]],\n",
       " [428, [0.0003543421335052699, 0.9951789379119873, 0.004466703161597252]],\n",
       " [429, [0.0010667385067790747, 0.9582833051681519, 0.040649961680173874]],\n",
       " [430, [0.9928606152534485, 0.0010475537274032831, 0.006091809831559658]],\n",
       " [431, [0.0008567650802433491, 0.022695090621709824, 0.9764482378959656]],\n",
       " [432, [0.003071905579417944, 0.7621937990188599, 0.23473432660102844]],\n",
       " [433, [0.002896434161812067, 0.18624593317508698, 0.8108575940132141]],\n",
       " [434, [0.9822649955749512, 0.008278923109173775, 0.009455962106585503]],\n",
       " [435, [0.0010788425570353866, 0.002064540283754468, 0.9968565702438354]],\n",
       " [436, [0.9817019701004028, 0.0021180608309805393, 0.016179926693439484]],\n",
       " [437, [0.9900087118148804, 0.0010289852507412434, 0.008962246589362621]],\n",
       " [438, [0.8984066247940063, 0.018086818978190422, 0.08350662142038345]],\n",
       " [439, [0.9938116073608398, 0.00245081540197134, 0.00373758003115654]],\n",
       " [440, [0.9916732907295227, 0.0024674199521541595, 0.00585925905033946]],\n",
       " [441, [0.087840236723423, 0.7621551156044006, 0.15000462532043457]],\n",
       " [442, [0.8691438436508179, 0.009348709136247635, 0.12150736153125763]],\n",
       " [443, [0.0016452675918117166, 0.00806030910462141, 0.9902944564819336]],\n",
       " [444, [0.0003861432778649032, 0.9977218508720398, 0.0018919343128800392]],\n",
       " [445, [0.001106296549551189, 0.0015345782740041614, 0.9973590970039368]],\n",
       " [446, [0.0013516225153580308, 0.0018009589985013008, 0.9968474507331848]],\n",
       " [447, [0.4590364098548889, 0.017842372879385948, 0.5231212377548218]],\n",
       " [448, [0.005698425695300102, 0.004208707250654697, 0.990092933177948]],\n",
       " [449, [0.0009004608727991581, 0.7801666855812073, 0.2189328670501709]],\n",
       " [450, [0.0014976896345615387, 0.9887354969978333, 0.009766815230250359]],\n",
       " [451, [0.9913431406021118, 0.003087435383349657, 0.005569512955844402]],\n",
       " [452, [0.9046357870101929, 0.0016564549878239632, 0.09370773285627365]],\n",
       " [453, [0.011001938953995705, 0.846472442150116, 0.14252562820911407]],\n",
       " [454, [0.0004862859786953777, 0.9859479665756226, 0.013565734028816223]],\n",
       " [455, [0.9948680400848389, 0.0013836262514814734, 0.0037482476327568293]],\n",
       " [456, [0.004066874738782644, 0.007392205763608217, 0.9885409474372864]],\n",
       " [457, [0.0029883587267249823, 0.9866632223129272, 0.010348333977162838]],\n",
       " [458, [0.013003512285649776, 0.004980564583092928, 0.9820159673690796]],\n",
       " [459, [0.054413359612226486, 0.76226407289505, 0.18332260847091675]],\n",
       " [460, [0.37386369705200195, 0.5835142731666565, 0.04262203350663185]],\n",
       " [461, [0.9939796924591064, 0.0018567051738500595, 0.0041635846719145775]],\n",
       " [462, [0.0006212047301232815, 0.9975047707557678, 0.00187403685413301]],\n",
       " [463, [0.0573643334209919, 0.18657518923282623, 0.7560604810714722]],\n",
       " [464, [0.06284301728010178, 0.7611961364746094, 0.17596085369586945]],\n",
       " [465, [0.000993602559901774, 0.9632893800735474, 0.03571702539920807]],\n",
       " [466, [0.0006889020442031324, 0.9971528053283691, 0.002158310730010271]],\n",
       " [467, [0.0018307651625946164, 0.0017408886924386024, 0.9964283108711243]],\n",
       " [468, [0.9869678616523743, 0.002122280653566122, 0.010909821838140488]],\n",
       " [469, [0.006426930893212557, 0.009191419929265976, 0.9843816161155701]],\n",
       " [470, [0.0015815041260793805, 0.9904453754425049, 0.007973098196089268]],\n",
       " [471, [0.0011366744292899966, 0.21887366473674774, 0.7799896001815796]],\n",
       " [472, [0.9938656687736511, 0.0016197431832551956, 0.004514661617577076]],\n",
       " [473, [0.10530351102352142, 0.02788189798593521, 0.8668146133422852]],\n",
       " [474, [0.99097740650177, 0.0011060618562623858, 0.00791653897613287]],\n",
       " [475, [0.00407060794532299, 0.0013063608203083277, 0.994623064994812]],\n",
       " [476, [0.989177405834198, 0.001439930172637105, 0.009382658638060093]],\n",
       " [477, [0.0019221467664465308, 0.9770058989524841, 0.02107197232544422]],\n",
       " [478, [0.8342128396034241, 0.09637492895126343, 0.0694122463464737]],\n",
       " [479, [0.0005604065372608602, 0.9963738322257996, 0.003065710887312889]],\n",
       " [480, [0.8778592348098755, 0.0022973010782152414, 0.11984347552061081]],\n",
       " [481, [0.9848663210868835, 0.002570530166849494, 0.012563117779791355]],\n",
       " [482, [0.021713852882385254, 0.9291064143180847, 0.049179721623659134]],\n",
       " [483, [0.9611721634864807, 0.0034572044387459755, 0.03537054359912872]],\n",
       " [484, [0.16667667031288147, 0.005734751932322979, 0.8275885581970215]],\n",
       " [485, [0.6214739084243774, 0.19330474734306335, 0.1852213740348816]],\n",
       " [486, [0.9901537299156189, 0.0030233191791921854, 0.006822960451245308]],\n",
       " [487, [0.0020133941434323788, 0.002947469474747777, 0.995039165019989]],\n",
       " [488, [0.0061910818330943584, 0.979832649230957, 0.013976234942674637]],\n",
       " [489, [0.9828991889953613, 0.0012759295059368014, 0.015825005248188972]],\n",
       " [490, [0.8367259502410889, 0.002482765121385455, 0.16079126298427582]],\n",
       " [491, [0.0017700737807899714, 0.0018949767109006643, 0.9963349103927612]],\n",
       " [492, [0.001593402586877346, 0.0018595242872834206, 0.9965470433235168]],\n",
       " [493, [0.11445052176713943, 0.03535442426800728, 0.8501951098442078]],\n",
       " [494, [0.9793174266815186, 0.0020387584809213877, 0.01864369958639145]],\n",
       " [495, [0.938602864742279, 0.01046814490109682, 0.050929080694913864]],\n",
       " [496, [0.9940037131309509, 0.0011959885014221072, 0.004800368100404739]],\n",
       " [497, [0.003342453623190522, 0.001188424532301724, 0.9954690933227539]],\n",
       " [498, [0.0030617762822657824, 0.0020945603027939796, 0.994843602180481]],\n",
       " [499, [0.9590378403663635, 0.012733455747365952, 0.028228698298335075]],\n",
       " [500, [0.991357684135437, 0.001121125533245504, 0.007521114777773619]],\n",
       " [501, [0.7046170234680176, 0.2789146602153778, 0.016468336805701256]],\n",
       " [502, [0.0012766054132953286, 0.0048863510601222515, 0.9938370585441589]],\n",
       " [503, [0.0010420616017654538, 0.9958848357200623, 0.003073102794587612]],\n",
       " [504, [0.002412838162854314, 0.9409062266349792, 0.05668092519044876]],\n",
       " [505, [0.9814419150352478, 0.0020712383557111025, 0.016486914828419685]],\n",
       " [506, [0.061377499252557755, 0.013870512135326862, 0.9247520565986633]],\n",
       " [507, [0.3477371037006378, 0.6310791373252869, 0.021183809265494347]],\n",
       " [508, [0.8825777769088745, 0.0048398361541330814, 0.11258241534233093]],\n",
       " [509, [0.0021065317559987307, 0.9710268974304199, 0.02686663158237934]],\n",
       " [510, [0.00884406641125679, 0.08007640391588211, 0.9110795259475708]],\n",
       " [511, [0.947965681552887, 0.007582646794617176, 0.044451721012592316]],\n",
       " [512, [0.7966738939285278, 0.024915987625718117, 0.1784101277589798]],\n",
       " [513, [0.9838802218437195, 0.0027713594026863575, 0.013348382897675037]],\n",
       " [514, [0.7788792252540588, 0.1771945059299469, 0.043926190584897995]],\n",
       " [515, [0.0004221709677949548, 0.9957166314125061, 0.0038611728232353926]],\n",
       " [516, [0.3717111647129059, 0.004571157973259687, 0.6237176656723022]],\n",
       " [517, [0.9945545196533203, 0.0013100272044539452, 0.004135471303015947]],\n",
       " [518, [0.00046348758041858673, 0.9918869137763977, 0.007649547420442104]],\n",
       " [519, [0.001362282200716436, 0.9730821847915649, 0.025555528700351715]],\n",
       " [520, [0.0019850130192935467, 0.006779650691896677, 0.9912352561950684]],\n",
       " [521, [0.010521382093429565, 0.45329105854034424, 0.5361875891685486]],\n",
       " [522, [0.23537683486938477, 0.74863201379776, 0.015991145744919777]],\n",
       " [523, [0.0025618223007768393, 0.011564500629901886, 0.9858736991882324]],\n",
       " [524, [0.0014710656832903624, 0.0018836106173694134, 0.9966452717781067]],\n",
       " [525, [0.000891270930878818, 0.9839252233505249, 0.015183458104729652]],\n",
       " [526, [0.9690579175949097, 0.022196821868419647, 0.008745294995605946]],\n",
       " [527, [0.9936493039131165, 0.0013064952800050378, 0.005044201388955116]],\n",
       " [528, [0.09875288605690002, 0.8385890126228333, 0.06265808641910553]],\n",
       " [529, [0.9594337940216064, 0.012462408281862736, 0.028103796765208244]],\n",
       " [530, [0.06277571618556976, 0.06263470649719238, 0.8745896220207214]],\n",
       " [531, [0.03059501387178898, 0.003215608187019825, 0.9661893844604492]],\n",
       " [532, [0.003035890869796276, 0.9899225831031799, 0.007041516713798046]],\n",
       " [533, [0.04126434028148651, 0.0015559325693175197, 0.9571797251701355]],\n",
       " [534, [0.0014491728506982327, 0.002343082567676902, 0.9962077140808105]],\n",
       " [535, [0.0050056856125593185, 0.959709107875824, 0.03528526797890663]],\n",
       " [536, [0.001803410123102367, 0.992345929145813, 0.005850676912814379]],\n",
       " [537, [0.0011234208941459656, 0.8879892230033875, 0.11088735610246658]],\n",
       " [538, [0.013709234073758125, 0.0019379083532840014, 0.9843528866767883]],\n",
       " [539, [0.0011509611504152417, 0.0036410775501281023, 0.9952079653739929]],\n",
       " [540, [0.015294475480914116, 0.001712186960503459, 0.9829933643341064]],\n",
       " [541, [0.00047256419202312827, 0.9973715543746948, 0.002155810361728072]],\n",
       " [542, [0.0006342307897284627, 0.989296019077301, 0.010069702751934528]],\n",
       " [543, [0.9898446798324585, 0.0015990028623491526, 0.00855635292828083]],\n",
       " [544, [0.0012109798844903708, 0.9957679510116577, 0.003021101700142026]],\n",
       " [545, [0.0013190064346417785, 0.002355487085878849, 0.9963255524635315]],\n",
       " [546, [0.00041822256753221154, 0.995040237903595, 0.004541558213531971]],\n",
       " [547, [0.9906174540519714, 0.003206967143341899, 0.00617555808275938]],\n",
       " [548, [0.0012587166856974363, 0.0017177877016365528, 0.9970235228538513]],\n",
       " [549, [0.8665771484375, 0.001899892115034163, 0.1315230429172516]],\n",
       " [550, [0.001809664536267519, 0.0010951561853289604, 0.9970951080322266]],\n",
       " [551, [0.0007321060984395444, 0.994716227054596, 0.004551715217530727]],\n",
       " [552, [0.6346980929374695, 0.057611435651779175, 0.30769041180610657]],\n",
       " [553, [0.9904781579971313, 0.0032182789873331785, 0.00630362331867218]],\n",
       " [554, [0.988281786441803, 0.0017203940078616142, 0.009997806511819363]],\n",
       " [555, [0.0025181930977851152, 0.01983434334397316, 0.9776474237442017]],\n",
       " [556, [0.93648362159729, 0.016298914328217506, 0.04721760004758835]],\n",
       " [557, [0.007921574637293816, 0.06971168518066406, 0.922366738319397]],\n",
       " [558, [0.002073469338938594, 0.0012978625018149614, 0.9966287016868591]],\n",
       " [559, [0.0018505752086639404, 0.6133575439453125, 0.38479191064834595]],\n",
       " [560, [0.8818526268005371, 0.08523145318031311, 0.032915856689214706]],\n",
       " [561, [0.000879535567946732, 0.9959281086921692, 0.003192382864654064]],\n",
       " [562, [0.0012554236454889178, 0.004044385626912117, 0.9947001934051514]],\n",
       " [563, [0.0013976660557091236, 0.0027091619558632374, 0.995893120765686]],\n",
       " [564, [0.20176862180233002, 0.021299412474036217, 0.7769319415092468]],\n",
       " [565, [0.0007712138467468321, 0.002710327971726656, 0.9965184926986694]],\n",
       " [566, [0.9574177265167236, 0.02261136658489704, 0.019970884546637535]],\n",
       " [567, [0.9939314126968384, 0.001550352550111711, 0.004518209490925074]],\n",
       " [568, [0.004339552018791437, 0.001220386242493987, 0.9944400787353516]],\n",
       " [569, [0.08657363802194595, 0.8583964705467224, 0.05502994358539581]],\n",
       " [570, [0.8391387462615967, 0.033234331756830215, 0.1276269555091858]],\n",
       " [571, [0.9826898574829102, 0.01219935156404972, 0.005110808182507753]],\n",
       " [572, [0.8715038299560547, 0.10833515971899033, 0.020160986110568047]],\n",
       " [573, [0.002403955440968275, 0.034503210335969925, 0.9630928635597229]],\n",
       " [574, [0.9725151062011719, 0.00986550934612751, 0.017619354650378227]],\n",
       " [575, [0.0013350144727155566, 0.9952889680862427, 0.0033760250080376863]],\n",
       " [576, [0.9744080901145935, 0.00285930628888309, 0.022732600569725037]],\n",
       " [577, [0.003944918513298035, 0.0018933399114757776, 0.9941616654396057]],\n",
       " [578, [0.0005049818428233266, 0.9964078068733215, 0.003087186487391591]],\n",
       " [579, [0.002753131091594696, 0.591140627861023, 0.40610620379447937]],\n",
       " [580, [0.0031302915886044502, 0.9838348627090454, 0.0130348801612854]],\n",
       " [581, [0.9827432632446289, 0.005170566961169243, 0.012086178176105022]],\n",
       " [582, [0.9827525615692139, 0.0010246132733300328, 0.016222849488258362]],\n",
       " [583, [0.0010468229884281754, 0.010232781991362572, 0.9887203574180603]],\n",
       " [584, [0.9936317801475525, 0.0017474580090492964, 0.004620743915438652]],\n",
       " [585, [0.9942527413368225, 0.0034456944558769464, 0.0023014748003333807]],\n",
       " [586, [0.012859776616096497, 0.006581059657037258, 0.9805592894554138]],\n",
       " [587, [0.9932796359062195, 0.0013101915828883648, 0.0054101720452308655]],\n",
       " [588, [0.02782917581498623, 0.8077741265296936, 0.1643967181444168]],\n",
       " [589, [0.9666446447372437, 0.003530561923980713, 0.029824838042259216]],\n",
       " [590, [0.9928057789802551, 0.0018757518846541643, 0.005318506620824337]],\n",
       " [591, [0.00888682808727026, 0.022378971800208092, 0.9687342643737793]],\n",
       " [592, [0.0023534109350293875, 0.9927109479904175, 0.004935596138238907]],\n",
       " [593, [0.990814745426178, 0.0015223555965349078, 0.007662923540920019]],\n",
       " [594, [0.000478259171359241, 0.9976717829704285, 0.0018498965073376894]],\n",
       " [595, [0.00035912200110033154, 0.9979265928268433, 0.0017142411088570952]],\n",
       " [596, [0.03069409169256687, 0.6027249693870544, 0.3665809631347656]],\n",
       " [597, [0.0018388174939900637, 0.0016235982766374946, 0.9965375661849976]],\n",
       " [598, [0.9802086353302002, 0.0027642673812806606, 0.017027031630277634]],\n",
       " [599, [0.9938574433326721, 0.0010305590694770217, 0.005112010985612869]],\n",
       " [600, [0.028287535533308983, 0.9634060859680176, 0.008306385949254036]],\n",
       " [601, [0.0017000819789245725, 0.7454012632369995, 0.25289860367774963]],\n",
       " [602, [0.0005923210410401225, 0.8972105383872986, 0.10219715535640717]],\n",
       " [603, [0.9884195327758789, 0.003041680436581373, 0.00853885617107153]],\n",
       " [604, [0.006708162371069193, 0.13364408910274506, 0.8596476912498474]],\n",
       " [605, [0.005015855189412832, 0.0009606789099052548, 0.9940235018730164]],\n",
       " [606, [0.00031555790337733924, 0.9978625178337097, 0.0018219337798655033]],\n",
       " [607, [0.00045932503417134285, 0.99785977602005, 0.0016809352673590183]],\n",
       " [608, [0.0039410097524523735, 0.9869197607040405, 0.009139235131442547]],\n",
       " [609, [0.00048783651436679065, 0.9967988729476929, 0.002713270951062441]],\n",
       " [610, [0.2559930682182312, 0.6481063961982727, 0.09590054303407669]],\n",
       " [611, [0.5553200840950012, 0.03632102534174919, 0.4083588719367981]],\n",
       " [612, [0.010968268848955631, 0.005300818011164665, 0.9837309122085571]],\n",
       " [613, [0.9890172481536865, 0.0009895091643556952, 0.00999322161078453]],\n",
       " [614, [0.002723034704104066, 0.9454135298728943, 0.05186348035931587]],\n",
       " [615, [0.0008546791505068541, 0.9963992834091187, 0.0027459836564958096]],\n",
       " [616, [0.00508229760453105, 0.0184085201472044, 0.976509153842926]],\n",
       " [617, [0.001805196749046445, 0.0028239923994988203, 0.9953706860542297]],\n",
       " [618, [0.00046701563405804336, 0.9978976249694824, 0.0016353691462427378]],\n",
       " [619, [0.0011738616740331054, 0.0014828270068392158, 0.9973433613777161]],\n",
       " [620, [0.002013983204960823, 0.9943017959594727, 0.003684277879074216]],\n",
       " [621, [0.0025956963654607534, 0.03399905189871788, 0.9634053111076355]],\n",
       " [622, [0.9892367720603943, 0.0016740974970161915, 0.009089132770895958]],\n",
       " [623, [0.00741034559905529, 0.25291669368743896, 0.7396730184555054]],\n",
       " [624, [0.9362444281578064, 0.03358589857816696, 0.030169596895575523]],\n",
       " [625, [0.0005925907753407955, 0.9793381690979004, 0.020069235935807228]],\n",
       " [626, [0.0011652588145807385, 0.9691599011421204, 0.029674870893359184]],\n",
       " [627, [0.00046361368731595576, 0.9973803162574768, 0.002155998721718788]],\n",
       " [628, [0.005243942141532898, 0.004103835206478834, 0.990652322769165]],\n",
       " [629, [0.9836739301681519, 0.002331174211576581, 0.013994858600199223]],\n",
       " [630, [0.003349142149090767, 0.990312933921814, 0.006337965372949839]],\n",
       " [631, [0.992291271686554, 0.0029510874301195145, 0.004757613409310579]],\n",
       " [632, [0.002986575709655881, 0.009690210223197937, 0.9873232245445251]],\n",
       " [633, [0.9778373837471008, 0.01100565493106842, 0.011156932450830936]],\n",
       " [634, [0.004994145128875971, 0.00679375696927309, 0.9882120490074158]],\n",
       " [635, [0.06487160921096802, 0.7691552042961121, 0.1659732311964035]],\n",
       " [636, [0.0024275186005979776, 0.9944562315940857, 0.003116264473646879]],\n",
       " [637, [0.58253413438797, 0.3807407319545746, 0.03672516718506813]],\n",
       " [638, [0.020834019407629967, 0.0012841668212786317, 0.9778818488121033]],\n",
       " [639, [0.036326002329587936, 0.8713868856430054, 0.09228706359863281]],\n",
       " [640, [0.0013876655139029026, 0.649684727191925, 0.34892764687538147]],\n",
       " [641, [0.9775960445404053, 0.007500994484871626, 0.014902904629707336]],\n",
       " [642, [0.003825453808531165, 0.007758447900414467, 0.9884161949157715]],\n",
       " [643, [0.9922864437103271, 0.001389971817843616, 0.006323514971882105]],\n",
       " [644, [0.0012899527791887522, 0.0012113212142139673, 0.9974986910820007]],\n",
       " [645, [0.9857897162437439, 0.0024842768907546997, 0.011725983582437038]],\n",
       " [646, [0.001640156377106905, 0.01541594322770834, 0.9829439520835876]],\n",
       " [647, [0.00076697749318555, 0.9967111349105835, 0.002521864138543606]],\n",
       " [648, [0.000380584824597463, 0.9945766925811768, 0.005042740609496832]],\n",
       " [649, [0.004993921145796776, 0.0016178220976144075, 0.9933881759643555]],\n",
       " [650, [0.9938687682151794, 0.001247270149178803, 0.004884056281298399]],\n",
       " [651, [0.25107458233833313, 0.5492696166038513, 0.19965583086013794]],\n",
       " [652, [0.0005897348746657372, 0.9969944953918457, 0.0024157289881259203]],\n",
       " [653, [0.005361888557672501, 0.0008402716484852135, 0.9937978386878967]],\n",
       " [654, [0.0019989467691630125, 0.00817165058106184, 0.9898293614387512]],\n",
       " [655, [0.002520275767892599, 0.0010533200111240149, 0.9964264035224915]],\n",
       " [656, [0.016348497942090034, 0.01554526761174202, 0.9681062698364258]],\n",
       " [657, [0.00047045029350556433, 0.9929878115653992, 0.006541761104017496]],\n",
       " [658, [0.9843055009841919, 0.0017029904993250966, 0.013991469517350197]],\n",
       " [659, [0.0006990300607867539, 0.9973940849304199, 0.0019069066038355231]],\n",
       " [660, [0.002003635047003627, 0.00280159804970026, 0.9951947331428528]],\n",
       " [661, [0.019807707518339157, 0.938474178314209, 0.041718099266290665]],\n",
       " [662, [0.00213486491702497, 0.004265503026545048, 0.9935996532440186]],\n",
       " [663, [0.00123665074352175, 0.0027942671440541744, 0.9959690570831299]],\n",
       " [664, [0.13056841492652893, 0.0033510769717395306, 0.8660805225372314]],\n",
       " [665, [0.5694870352745056, 0.3782505393028259, 0.052262477576732635]],\n",
       " [666, [0.020119942724704742, 0.4979870617389679, 0.48189306259155273]],\n",
       " [667, [0.04184327274560928, 0.005552520509809256, 0.9526042342185974]],\n",
       " [668, [0.0007743064197711647, 0.0072060502134263515, 0.9920195937156677]],\n",
       " [669, [0.00088907202007249, 0.00598065136000514, 0.9931302666664124]],\n",
       " [670, [0.0007771209347993135, 0.0030916763935238123, 0.996131181716919]],\n",
       " [671, [0.002255583880469203, 0.03609166666865349, 0.9616526961326599]],\n",
       " [672, [0.0022237550001591444, 0.2533053755760193, 0.7444708943367004]],\n",
       " [673, [0.0003063411277253181, 0.9974812865257263, 0.002212404040619731]],\n",
       " [674, [0.001919998088851571, 0.0017030577873811126, 0.9963769316673279]],\n",
       " [675, [0.9751502275466919, 0.0016103602247312665, 0.023239364847540855]],\n",
       " [676, [0.2841463088989258, 0.022498898208141327, 0.6933547854423523]],\n",
       " [677, [0.0018014274537563324, 0.0016299944836646318, 0.9965686798095703]],\n",
       " [678, [0.0005392921739257872, 0.9968409538269043, 0.00261978548951447]],\n",
       " [679, [0.0016792246606200933, 0.9195467829704285, 0.07877391576766968]],\n",
       " [680, [0.001381355687044561, 0.008539598435163498, 0.9900790452957153]],\n",
       " [681, [0.0007707145414315164, 0.9956658482551575, 0.003563521895557642]],\n",
       " [682, [0.9919140338897705, 0.0022847638465464115, 0.005801181308925152]],\n",
       " [683, [0.0004379836318548769, 0.9978525638580322, 0.001709484145976603]],\n",
       " [684, [0.0032289735972881317, 0.9150482416152954, 0.08172276616096497]],\n",
       " [685, [0.0009377628448419273, 0.9943559765815735, 0.004706182982772589]],\n",
       " [686, [0.8559163212776184, 0.00597345270216465, 0.1381102204322815]],\n",
       " [687, [0.0029511109460145235, 0.0016759746940806508, 0.9953729510307312]],\n",
       " [688, [0.8154059648513794, 0.0809517651796341, 0.1036422923207283]],\n",
       " [689, [0.9924691319465637, 0.002370961243286729, 0.005159907042980194]],\n",
       " [690, [0.004540609661489725, 0.003196173347532749, 0.9922633171081543]],\n",
       " [691, [0.991595447063446, 0.0014924592105671763, 0.006912048440426588]],\n",
       " [692, [0.9535179734230042, 0.04183967784047127, 0.004642277956008911]],\n",
       " [693, [0.00622500479221344, 0.04276924952864647, 0.951005756855011]],\n",
       " [694, [0.9914407730102539, 0.002874471480026841, 0.005684784613549709]],\n",
       " [695, [0.11568986624479294, 0.20400741696357727, 0.6803027391433716]],\n",
       " [696, [0.9739017486572266, 0.00188354158308357, 0.024214738979935646]],\n",
       " [697, [0.049370624125003815, 0.8228346705436707, 0.12779471278190613]],\n",
       " [698, [0.813381016254425, 0.0015665129758417606, 0.18505249917507172]],\n",
       " [699, [0.38567742705345154, 0.019990352913737297, 0.594332218170166]],\n",
       " [700, [0.03127297759056091, 0.07397764176130295, 0.8947493433952332]],\n",
       " [701, [0.9773848652839661, 0.004164690151810646, 0.018450485542416573]],\n",
       " [702, [0.9928807020187378, 0.0023185964673757553, 0.004800730850547552]],\n",
       " [703, [0.009016004391014576, 0.004035222809761763, 0.9869487285614014]],\n",
       " [704, [0.5702130198478699, 0.31552377343177795, 0.11426319181919098]],\n",
       " [705, [0.9837862849235535, 0.0030134734697639942, 0.013200236484408379]],\n",
       " [706, [0.0007933276356197894, 0.9905127882957458, 0.008693897165358067]],\n",
       " [707, [0.0011116520036011934, 0.9914106130599976, 0.00747776310890913]],\n",
       " [708, [0.0009275195188820362, 0.0021193698048591614, 0.9969531297683716]],\n",
       " [709, [0.001808040658943355, 0.9323632121086121, 0.06582878530025482]],\n",
       " [710, [0.004272800404578447, 0.0018586094956845045, 0.9938686490058899]],\n",
       " [711, [0.9854490160942078, 0.0027977372519671917, 0.011753194965422153]],\n",
       " [712, [0.0012073421385139227, 0.0022207002621144056, 0.9965718984603882]],\n",
       " [713, [0.989984393119812, 0.0058950441889464855, 0.00412049749866128]],\n",
       " [714, [0.993497371673584, 0.00349439843557775, 0.0030082601588219404]],\n",
       " [715, [0.09444521367549896, 0.8971589207649231, 0.008395901881158352]],\n",
       " [716, [0.40487349033355713, 0.3002385199069977, 0.2948879897594452]],\n",
       " [717, [0.0008855349151417613, 0.0024703498929739, 0.996644139289856]],\n",
       " [718, [0.00897794496268034, 0.0019721081480383873, 0.989050030708313]],\n",
       " [719, [0.9806640148162842, 0.002264177892357111, 0.01707177795469761]],\n",
       " [720, [0.9474464058876038, 0.0030077151022851467, 0.049545854330062866]],\n",
       " [721, [0.0018909816863015294, 0.0016353888204321265, 0.9964736104011536]],\n",
       " [722, [0.017993347719311714, 0.22466188669204712, 0.7573447823524475]],\n",
       " [723, [0.017833657562732697, 0.7974374294281006, 0.18472892045974731]],\n",
       " [724, [0.7429532408714294, 0.0022683527786284685, 0.25477832555770874]],\n",
       " [725, [0.0003452466335147619, 0.996932864189148, 0.0027219026815146208]],\n",
       " [726, [0.003034701570868492, 0.18188144266605377, 0.8150838017463684]],\n",
       " [727, [0.017641954123973846, 0.9411829113960266, 0.04117514193058014]],\n",
       " [728, [0.002360530896112323, 0.9951000809669495, 0.002539368811994791]],\n",
       " [729, [0.9528326392173767, 0.005550865549594164, 0.04161654785275459]],\n",
       " [730, [0.9685400724411011, 0.02521723136305809, 0.006242615170776844]],\n",
       " [731, [0.002035732613876462, 0.008096862584352493, 0.9898673295974731]],\n",
       " [732, [0.006928448099642992, 0.8707535266876221, 0.12231795489788055]],\n",
       " [733, [0.001842772588133812, 0.0012537415605038404, 0.9969034790992737]],\n",
       " [734, [0.9370583295822144, 0.00322655844502151, 0.05971512570977211]],\n",
       " [735, [0.001666286145336926, 0.0025038705207407475, 0.9958298802375793]],\n",
       " [736, [0.010923892259597778, 0.9779002070426941, 0.011175896972417831]],\n",
       " [737, [0.018152626231312752, 0.18621517717838287, 0.7956321835517883]],\n",
       " [738, [0.5276697278022766, 0.0040781861171126366, 0.4682520627975464]],\n",
       " [739, [0.9637589454650879, 0.007466299459338188, 0.02877480909228325]],\n",
       " [740, [0.4633513391017914, 0.00919587817043066, 0.527452826499939]],\n",
       " [741, [0.041833989322185516, 0.8939862251281738, 0.06417982280254364]],\n",
       " [742, [0.18454307317733765, 0.011351107619702816, 0.804105818271637]],\n",
       " [743, [0.9629909992218018, 0.003925141878426075, 0.03308381885290146]],\n",
       " [744, [0.008426773361861706, 0.40955108404159546, 0.5820221304893494]],\n",
       " [745, [0.02414470538496971, 0.002331826835870743, 0.9735234379768372]],\n",
       " [746, [0.0013517072657123208, 0.0016703776782378554, 0.9969779253005981]],\n",
       " [747, [0.5775676965713501, 0.4108507037162781, 0.01158154010772705]],\n",
       " [748, [0.004147888161242008, 0.00194827641826123, 0.9939038157463074]],\n",
       " [749, [0.0025771588552743196, 0.9823997020721436, 0.015023083426058292]],\n",
       " [750, [0.001503216801211238, 0.0021218364126980305, 0.9963749051094055]],\n",
       " [751, [0.005185804329812527, 0.13471628725528717, 0.8600978255271912]],\n",
       " [752, [0.0020203592721372843, 0.0031482998747378588, 0.994831383228302]],\n",
       " [753, [0.015355844050645828, 0.004696141462773085, 0.9799480438232422]],\n",
       " [754, [0.8645497560501099, 0.11941337585449219, 0.016036804765462875]],\n",
       " [755, [0.0010946833062916994, 0.0024000981356948614, 0.9965052604675293]],\n",
       " [756, [0.05396866798400879, 0.0021068688947707415, 0.9439244270324707]],\n",
       " [757, [0.0005507229943759739, 0.9961560368537903, 0.003293223213404417]],\n",
       " [758, [0.0016075836028903723, 0.002726659644395113, 0.9956658482551575]],\n",
       " [759, [0.0011343745281919837, 0.006051274947822094, 0.9928143620491028]],\n",
       " [760, [0.9940432906150818, 0.0014981288695707917, 0.0044585647992789745]],\n",
       " [761, [0.008159973658621311, 0.0019270407501608133, 0.9899129867553711]],\n",
       " [762, [0.9884238839149475, 0.003232290968298912, 0.008343827910721302]],\n",
       " [763, [0.0010392736876383424, 0.9963188171386719, 0.0026418608613312244]],\n",
       " [764, [0.0007453718571923673, 0.0041692317463457584, 0.9950852990150452]],\n",
       " [765, [0.9772174954414368, 0.0073359664529562, 0.015446504577994347]],\n",
       " [766, [0.004028327763080597, 0.0007749604992568493, 0.9951967597007751]],\n",
       " [767, [0.9945517182350159, 0.0016807004576548934, 0.0037676412612199783]],\n",
       " [768, [0.0005767850088886917, 0.9972635507583618, 0.002159625291824341]],\n",
       " [769, [0.012692597694694996, 0.0339350700378418, 0.9533722400665283]],\n",
       " [770, [0.0010903547517955303, 0.9885718822479248, 0.01033773459494114]],\n",
       " [771, [0.0010040070628747344, 0.00292784976772964, 0.9960681200027466]],\n",
       " [772, [0.08693671226501465, 0.00470747472718358, 0.9083558320999146]],\n",
       " [773, [0.5759932398796082, 0.40619927644729614, 0.017807457596063614]],\n",
       " [774, [0.010322562418878078, 0.004508012905716896, 0.985169529914856]],\n",
       " [775, [0.0032896813936531544, 0.002608331385999918, 0.9941019415855408]],\n",
       " [776, [0.0006722678081132472, 0.9902315735816956, 0.009096117690205574]],\n",
       " [777, [0.7866325378417969, 0.00372781022451818, 0.20963968336582184]],\n",
       " [778, [0.001179243205115199, 0.0034351085778325796, 0.9953857064247131]],\n",
       " [779, [0.0009213178418576717, 0.002070995280519128, 0.9970076680183411]],\n",
       " [780, [0.9760987162590027, 0.0020455163903534412, 0.02185579016804695]],\n",
       " [781, [0.5594795346260071, 0.2131609469652176, 0.22735954821109772]],\n",
       " [782, [0.0003855426621157676, 0.9945202469825745, 0.0050942255184054375]],\n",
       " [783, [0.008219394832849503, 0.01508763525635004, 0.9766928553581238]],\n",
       " [784, [0.6313148140907288, 0.27024203538894653, 0.09844321757555008]],\n",
       " [785, [0.8855563402175903, 0.009233972057700157, 0.10520964115858078]],\n",
       " [786, [0.0005368322599679232, 0.9939174056053162, 0.0055458019487559795]],\n",
       " [787, [0.0007845691288821399, 0.815154492855072, 0.18406100571155548]],\n",
       " [788, [0.9937858581542969, 0.0025378309655934572, 0.003676334163174033]],\n",
       " [789, [0.001126697869040072, 0.8274472951889038, 0.17142599821090698]],\n",
       " [790, [0.9847151041030884, 0.0013460710179060698, 0.01393877249211073]],\n",
       " [791, [0.03367386385798454, 0.017897574231028557, 0.9484285712242126]],\n",
       " [792, [0.9570046663284302, 0.027482379227876663, 0.015513007529079914]],\n",
       " [793, [0.0015006560133770108, 0.002369322581216693, 0.9961299896240234]],\n",
       " [794, [0.0046423571184277534, 0.004544124472886324, 0.9908135533332825]],\n",
       " [795, [0.8749207258224487, 0.0021127453073859215, 0.1229664757847786]],\n",
       " [796, [0.3277190327644348, 0.5255703330039978, 0.146710604429245]],\n",
       " [797, [0.994175374507904, 0.0027253692969679832, 0.0030992813408374786]],\n",
       " [798, [0.9941515326499939, 0.0025680908001959324, 0.0032803574576973915]],\n",
       " [799, [0.0018559865420684218, 0.001209493144415319, 0.9969345331192017]],\n",
       " [800, [0.8514016270637512, 0.0751529410481453, 0.07344543188810349]],\n",
       " [801, [0.0012474815594032407, 0.005367286503314972, 0.9933852553367615]],\n",
       " [802, [0.07148697972297668, 0.0029103723354637623, 0.9256027340888977]],\n",
       " [803, [0.0014585652388632298, 0.001907331752590835, 0.9966340661048889]],\n",
       " [804, [0.0005830335430800915, 0.9962122440338135, 0.0032047824934124947]],\n",
       " [805, [0.0025103893131017685, 0.9496541023254395, 0.04783550649881363]],\n",
       " [806, [0.9667474627494812, 0.011927256360650063, 0.02132527157664299]],\n",
       " [807, [0.42896464467048645, 0.0059418827295303345, 0.565093457698822]],\n",
       " [808, [0.0027582477778196335, 0.08157087117433548, 0.9156708121299744]],\n",
       " [809, [0.0978795513510704, 0.7968471646308899, 0.1052732765674591]],\n",
       " [810, [0.12157716602087021, 0.0225558802485466, 0.8558669686317444]],\n",
       " [811, [0.0002504185540601611, 0.9960583448410034, 0.0036912530194967985]],\n",
       " [812, [0.0014709571842104197, 0.9338736534118652, 0.06465543061494827]],\n",
       " [813, [0.006621232721954584, 0.19289575517177582, 0.800482988357544]],\n",
       " [814, [0.0013103734236210585, 0.007310133893042803, 0.9913794994354248]],\n",
       " [815, [0.0009301727986894548, 0.0029512715991586447, 0.9961185455322266]],\n",
       " [816, [0.7057215571403503, 0.008966874331235886, 0.28531160950660706]],\n",
       " [817, [0.01068829745054245, 0.0032978663221001625, 0.9860137701034546]],\n",
       " [818, [0.0014647042844444513, 0.001485269283875823, 0.9970500469207764]],\n",
       " [819, [0.9935978651046753, 0.001952372258529067, 0.004449756816029549]],\n",
       " [820, [0.0006853343220427632, 0.016760047525167465, 0.9825546145439148]],\n",
       " [821, [0.0038019733037799597, 0.02560323104262352, 0.9705947637557983]],\n",
       " [822, [0.020045224577188492, 0.5097367167472839, 0.4702180325984955]],\n",
       " [823, [0.0011771558783948421, 0.0014688973315060139, 0.9973539113998413]],\n",
       " [824, [0.7450082302093506, 0.001426382688805461, 0.25356537103652954]],\n",
       " [825, [0.006054805126041174, 0.04421747848391533, 0.9497277140617371]],\n",
       " [826, [0.00044562460971064866, 0.9972736239433289, 0.002280776621773839]],\n",
       " [827, [0.0016812386456876993, 0.0014855029294267297, 0.9968332648277283]],\n",
       " [828, [0.00567984813824296, 0.9609352350234985, 0.033384982496500015]],\n",
       " [829, [0.9312431216239929, 0.015253032557666302, 0.053503889590501785]],\n",
       " [830, [0.32777875661849976, 0.009561235085129738, 0.6626599431037903]],\n",
       " [831, [0.0005066608428023756, 0.9900869727134705, 0.00940630491822958]],\n",
       " [832, [0.00033559888834133744, 0.9924023151397705, 0.007262075319886208]],\n",
       " [833, [0.6780815720558167, 0.07956647872924805, 0.2423519343137741]],\n",
       " [834, [0.0019853790290653706, 0.0025635012425482273, 0.9954511523246765]],\n",
       " [835, [0.018145350739359856, 0.8701901435852051, 0.11166444420814514]],\n",
       " [836, [0.9912612438201904, 0.002409393899142742, 0.006329271476715803]],\n",
       " [837, [0.0004973645554855466, 0.9976410865783691, 0.0018616003217175603]],\n",
       " [838, [0.000989025691524148, 0.0026144750881940126, 0.9963964819908142]],\n",
       " [839, [0.0007516019977629185, 0.9954067468643188, 0.0038417247124016285]],\n",
       " [840, [0.06704103201627731, 0.5280123949050903, 0.40494659543037415]],\n",
       " [841, [0.2079966813325882, 0.002042867708951235, 0.7899604439735413]],\n",
       " [842, [0.0007716018008068204, 0.9950202703475952, 0.0042080990970134735]],\n",
       " [843, [0.9928083419799805, 0.0032217090483754873, 0.003970000427216291]],\n",
       " [844, [0.0015144519275054336, 0.002215206390246749, 0.9962702989578247]],\n",
       " [845, [0.0015761118847876787, 0.0018072649836540222, 0.9966166615486145]],\n",
       " [846, [0.0217006616294384, 0.9324023723602295, 0.045896902680397034]],\n",
       " [847, [0.00043044902849942446, 0.9750822186470032, 0.024487346410751343]],\n",
       " [848, [0.9907581806182861, 0.0029684160836040974, 0.006273367907851934]],\n",
       " [849, [0.0009245434775948524, 0.02036016806960106, 0.9787153005599976]],\n",
       " [850, [0.0008834325126372278, 0.0029945464339107275, 0.9961219429969788]],\n",
       " [851, [0.0007672657375223935, 0.9910756349563599, 0.008157055824995041]],\n",
       " [852, [0.9773197174072266, 0.0035186896566301584, 0.01916150189936161]],\n",
       " [853, [0.005278291180729866, 0.0016999050276353955, 0.9930217862129211]],\n",
       " [854, [0.0006862560985609889, 0.9958441853523254, 0.003469508606940508]],\n",
       " [855, [0.9913040399551392, 0.0017592861549928784, 0.006936734542250633]],\n",
       " [856, [0.9846667051315308, 0.0024476395919919014, 0.012885681353509426]],\n",
       " [857, [0.0027575320564210415, 0.0013091900618746877, 0.9959333539009094]],\n",
       " [858, [0.0003809609042946249, 0.9972295165061951, 0.0023895646445453167]],\n",
       " [859, [0.3226848542690277, 0.30425143241882324, 0.37306371331214905]],\n",
       " [860, [0.002585562178865075, 0.9895455241203308, 0.007868913933634758]],\n",
       " [861, [0.01535159070044756, 0.0013803228503093123, 0.9832680821418762]],\n",
       " [862, [0.0006849687779322267, 0.9205346703529358, 0.07878038287162781]],\n",
       " [863, [0.007004799321293831, 0.020331261679530144, 0.972663938999176]],\n",
       " [864, [0.016128089278936386, 0.0060175382532179356, 0.9778543710708618]],\n",
       " [865, [0.9814759492874146, 0.008877492509782314, 0.009646601974964142]],\n",
       " [866, [0.9786561727523804, 0.00292736547999084, 0.018416492268443108]],\n",
       " [867, [0.005549915600568056, 0.004297069739550352, 0.9901530146598816]],\n",
       " [868, [0.0006570067489519715, 0.991709291934967, 0.007633713074028492]],\n",
       " [869, [0.005864514969289303, 0.014630313962697983, 0.979505181312561]],\n",
       " [870, [0.03372102975845337, 0.7501921653747559, 0.21608684957027435]],\n",
       " [871, [0.003351468127220869, 0.018462426960468292, 0.9781860709190369]],\n",
       " [872, [0.9411805868148804, 0.009623033925890923, 0.04919632151722908]],\n",
       " [873, [0.09008437395095825, 0.07851247489452362, 0.8314031958580017]],\n",
       " [874, [0.004427276086062193, 0.016280144453048706, 0.9792925119400024]],\n",
       " [875, [0.017589226365089417, 0.4761432111263275, 0.5062675476074219]],\n",
       " [876, [0.9945255517959595, 0.0016943871742114425, 0.0037800525315105915]],\n",
       " [877, [0.0003659306967165321, 0.9962165951728821, 0.003417415078729391]],\n",
       " [878, [0.0016226684674620628, 0.0038440793287009, 0.9945331811904907]],\n",
       " [879, [0.0021408130414783955, 0.0009399194386787713, 0.9969192743301392]],\n",
       " [880, [0.0014253153931349516, 0.002774597145617008, 0.9958000779151917]],\n",
       " [881, [0.004415514413267374, 0.07054142653942108, 0.9250431060791016]],\n",
       " [882, [0.0696030929684639, 0.9130777716636658, 0.017319103702902794]],\n",
       " [883, [0.9935677647590637, 0.001581961871124804, 0.00485029025003314]],\n",
       " [884, [0.9955018162727356, 0.0017668624641373754, 0.002731385175138712]],\n",
       " [885, [0.012841749005019665, 0.40837374329566956, 0.5787844657897949]],\n",
       " [886, [0.0011782454093918204, 0.0020335272420197725, 0.9967882633209229]],\n",
       " [887, [0.0031065798830240965, 0.010021574795246124, 0.9868718385696411]],\n",
       " [888, [0.9937790036201477, 0.002372933551669121, 0.0038481212686747313]],\n",
       " [889, [0.0017269175732508302, 0.005566117819398642, 0.9927069544792175]],\n",
       " [890, [0.9763143658638, 0.005205472465604544, 0.018480224534869194]],\n",
       " [891, [0.030458679422736168, 0.8359172940254211, 0.13362406194210052]],\n",
       " [892, [0.9898334741592407, 0.0033781477250158787, 0.006788400933146477]],\n",
       " [893, [0.977712869644165, 0.0026944305282086134, 0.0195926520973444]],\n",
       " [894, [0.00048701680498197675, 0.9969596862792969, 0.002553292317315936]],\n",
       " [895, [0.0038312687538564205, 0.0013643949059769511, 0.994804322719574]],\n",
       " [896, [0.9070024490356445, 0.03270407021045685, 0.060293443500995636]],\n",
       " [897, [0.0011420869268476963, 0.00246065529063344, 0.9963973164558411]],\n",
       " [898, [0.9566605091094971, 0.004975771065801382, 0.03836368769407272]],\n",
       " [899, [0.0092538483440876, 0.0013869120739400387, 0.9893592596054077]],\n",
       " [900, [0.0030131840612739325, 0.05789420008659363, 0.9390925765037537]],\n",
       " [901, [0.001493956195190549, 0.9098881483078003, 0.08861791342496872]],\n",
       " [902, [0.9793862700462341, 0.0035744155757129192, 0.01703941635787487]],\n",
       " [903, [0.8908053636550903, 0.0018119515152648091, 0.10738274455070496]],\n",
       " [904, [0.9774332642555237, 0.0036309121642261744, 0.018935739994049072]],\n",
       " [905, [0.0022927874233573675, 0.0020957901142537594, 0.9956114888191223]],\n",
       " [906, [0.0007344505866058171, 0.9957897067070007, 0.0034758856054395437]],\n",
       " [907, [0.0004365206987131387, 0.9929226636886597, 0.006640779320150614]],\n",
       " [908, [0.5201945900917053, 0.24847842752933502, 0.23132699728012085]],\n",
       " [909, [0.39613795280456543, 0.0062877107411623, 0.5975743532180786]],\n",
       " [910, [0.003617836395278573, 0.0014740563929080963, 0.9949080348014832]],\n",
       " [911, [0.017028246074914932, 0.015811465680599213, 0.9671602249145508]],\n",
       " [912, [0.0019189409213140607, 0.0016798898577690125, 0.9964011907577515]],\n",
       " [913, [0.9889456629753113, 0.00158313091378659, 0.009471219964325428]],\n",
       " [914, [0.0010557582136243582, 0.0019557473715394735, 0.9969884753227234]],\n",
       " [915, [0.003807641798630357, 0.0009358846582472324, 0.9952564835548401]],\n",
       " [916, [0.001004438498057425, 0.9964666366577148, 0.0025289044715464115]],\n",
       " [917, [0.0011205719783902168, 0.9949532151222229, 0.003926174249500036]],\n",
       " [918, [0.0009380921837873757, 0.0021810184698551893, 0.9968808889389038]],\n",
       " [919, [0.9738643169403076, 0.020994437858462334, 0.005141343455761671]],\n",
       " [920, [0.007348829880356789, 0.009052824229001999, 0.9835984110832214]],\n",
       " [921, [0.985516369342804, 0.002402229467406869, 0.012081380002200603]],\n",
       " [922, [0.8103237152099609, 0.00481818150728941, 0.18485811352729797]],\n",
       " [923, [0.8459388613700867, 0.0065072267316281796, 0.1475539356470108]],\n",
       " [924, [0.0018677626503631473, 0.01458996906876564, 0.9835423231124878]],\n",
       " [925, [0.0014313225401565433, 0.9860019683837891, 0.012566668912768364]],\n",
       " [926, [0.8841210007667542, 0.014678538776934147, 0.10120044648647308]],\n",
       " [927, [0.9906291365623474, 0.0015886814799159765, 0.00778212072327733]],\n",
       " [928, [0.087006576359272, 0.0059018367901444435, 0.9070916175842285]],\n",
       " [929, [0.9411109089851379, 0.019226958975195885, 0.03966207802295685]],\n",
       " [930, [0.0007312704692594707, 0.008787221275269985, 0.9904815554618835]],\n",
       " [931, [0.9602830410003662, 0.018434925004839897, 0.02128208614885807]],\n",
       " [932, [0.009314688853919506, 0.0019178861984983087, 0.9887674450874329]],\n",
       " [933, [0.001442484324797988, 0.0013676444068551064, 0.9971898198127747]],\n",
       " [934, [0.0004318932769820094, 0.9975416660308838, 0.0020264391787350178]],\n",
       " [935, [0.00047003276995383203, 0.9957681894302368, 0.0037617648486047983]],\n",
       " [936, [0.9957471489906311, 0.0011594102252274752, 0.0030934580136090517]],\n",
       " [937, [0.0875096246600151, 0.009316552430391312, 0.9031738042831421]],\n",
       " [938, [0.9736437797546387, 0.013998831622302532, 0.012357301078736782]],\n",
       " [939, [0.003211443778127432, 0.00942462868988514, 0.9873639941215515]],\n",
       " [940, [0.9908304214477539, 0.001015440677292645, 0.008154110983014107]],\n",
       " [941, [0.9566915035247803, 0.0030373320914804935, 0.040271203964948654]],\n",
       " [942, [0.0005490319454111159, 0.9912285804748535, 0.008222386240959167]],\n",
       " [943, [0.016680527478456497, 0.5900929570198059, 0.3932264745235443]],\n",
       " [944, [0.0037166657857596874, 0.010225764475762844, 0.9860575795173645]],\n",
       " [945, [0.9882321953773499, 0.0014789866982027888, 0.010288863442838192]],\n",
       " [946, [0.9124581217765808, 0.004815906286239624, 0.08272595703601837]],\n",
       " [947, [0.0012470269575715065, 0.0016459689941257238, 0.9971070885658264]],\n",
       " [948, [0.0030775347258895636, 0.0015885931206867099, 0.9953338503837585]],\n",
       " [949, [0.9906736016273499, 0.0026986640878021717, 0.006627757102251053]],\n",
       " [950, [0.0005001652170903981, 0.9952415227890015, 0.004258361179381609]],\n",
       " [951, [0.031246282160282135, 0.19083504378795624, 0.7779186964035034]],\n",
       " [952, [0.0006678957142867148, 0.9954817295074463, 0.003850329667329788]],\n",
       " [953, [0.0002979471755679697, 0.9930764436721802, 0.006625669542700052]],\n",
       " [954, [0.0012517222203314304, 0.9957364797592163, 0.0030117437709122896]],\n",
       " [955, [0.7590901851654053, 0.004630110692232847, 0.2362796515226364]],\n",
       " [956, [0.0028923670761287212, 0.0016338367713615298, 0.9954738020896912]],\n",
       " [957, [0.9956915974617004, 0.0016373781254515052, 0.002670972840860486]],\n",
       " [958, [0.0005814931937493384, 0.9949695467948914, 0.004448923747986555]],\n",
       " [959, [0.004626754205673933, 0.9802194237709045, 0.015153791755437851]],\n",
       " [960, [0.0010966722620651126, 0.0035011747386306524, 0.9954020977020264]],\n",
       " [961, [0.00121595268137753, 0.9938363432884216, 0.004947651643306017]],\n",
       " [962, [0.0006749220774509013, 0.9716250896453857, 0.027699923142790794]],\n",
       " [963, [0.0017519014654681087, 0.9726070165634155, 0.02564113214612007]],\n",
       " [964, [0.298911452293396, 0.010197262279689312, 0.6908913254737854]],\n",
       " [965, [0.7649676203727722, 0.0011812172597274184, 0.23385114967823029]],\n",
       " [966, [0.001933434628881514, 0.003971660975366831, 0.9940949082374573]],\n",
       " [967, [0.9049782156944275, 0.016445958986878395, 0.07857581228017807]],\n",
       " [968, [0.9208407402038574, 0.000946303247474134, 0.07821286469697952]],\n",
       " [969, [0.0004683106380980462, 0.9452213644981384, 0.05431036651134491]],\n",
       " [970, [0.9942319989204407, 0.0014358005719259381, 0.004332208540290594]],\n",
       " [971, [0.9675289988517761, 0.0024867504835128784, 0.029984284192323685]],\n",
       " [972, [0.006553420331329107, 0.001660500536672771, 0.9917860627174377]],\n",
       " [973, [0.0004517776542343199, 0.9957540035247803, 0.0037942861672490835]],\n",
       " [974, [0.005720953457057476, 0.9049563407897949, 0.08932262659072876]],\n",
       " [975, [0.9586780071258545, 0.005917296279221773, 0.03540479391813278]],\n",
       " [976, [0.9706856608390808, 0.01893925853073597, 0.010375097393989563]],\n",
       " [977, [0.0009405697346664965, 0.002421167679131031, 0.9966381788253784]],\n",
       " [978, [0.9925220608711243, 0.001971124904230237, 0.005506785120815039]],\n",
       " [979, [0.9863373637199402, 0.0036555160768330097, 0.010007143951952457]],\n",
       " [980, [0.9912897348403931, 0.0025157914496958256, 0.0061945123597979546]],\n",
       " [981, [0.0022720082197338343, 0.009476998820900917, 0.9882509112358093]],\n",
       " [982, [0.376496821641922, 0.56653892993927, 0.05696422979235649]],\n",
       " [983, [0.0009958631126210093, 0.9179585576057434, 0.08104564249515533]],\n",
       " [984, [0.0014693246921524405, 0.0027510481886565685, 0.9957796335220337]],\n",
       " [985, [0.0018925588810816407, 0.0017680723685771227, 0.9963394403457642]],\n",
       " [986, [0.0005838568322360516, 0.9465493559837341, 0.0528668574988842]],\n",
       " [987, [0.000871720549184829, 0.9952680468559265, 0.0038601604755967855]],\n",
       " [988, [0.0015603613574057817, 0.0014893069164827466, 0.9969504475593567]],\n",
       " [989, [0.0015159896574914455, 0.9955248832702637, 0.0029591303318738937]],\n",
       " [990, [0.9944215416908264, 0.0013538097264245152, 0.004224695265293121]],\n",
       " [991, [0.9838175773620605, 0.008353986777365208, 0.007828484289348125]],\n",
       " [992, [0.0016448497772216797, 0.0013199594104662538, 0.9970351457595825]],\n",
       " [993, [0.0023584242444485426, 0.9901692867279053, 0.007472375873476267]],\n",
       " [994, [0.004481641110032797, 0.004750542342662811, 0.990767776966095]],\n",
       " [995, [0.9866053462028503, 0.002874883823096752, 0.010519775561988354]],\n",
       " [996, [0.0013386344071477652, 0.001828876556828618, 0.996832549571991]],\n",
       " [997, [0.0007792794494889677, 0.9785524010658264, 0.0206683911383152]],\n",
       " [998, [0.9852230548858643, 0.004809132311493158, 0.009967818856239319]],\n",
       " [999, [0.9887440204620361, 0.0022415833082050085, 0.009014338254928589]],\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'contradiction'], [1, 'neutral'], [2, 'neutral'], [3, 'contradiction'], [4, 'contradiction'], [5, 'contradiction'], [6, 'neutral'], [7, 'contradiction'], [8, 'entailment'], [9, 'contradiction'], [10, 'contradiction'], [11, 'entailment'], [12, 'contradiction'], [13, 'entailment'], [14, 'neutral'], [15, 'neutral'], [16, 'entailment'], [17, 'neutral'], [18, 'contradiction'], [19, 'neutral'], [20, 'contradiction'], [21, 'neutral'], [22, 'entailment'], [23, 'entailment'], [24, 'contradiction'], [25, 'neutral'], [26, 'neutral'], [27, 'entailment'], [28, 'entailment'], [29, 'entailment'], [30, 'contradiction'], [31, 'entailment'], [32, 'contradiction'], [33, 'neutral'], [34, 'neutral'], [35, 'neutral'], [36, 'neutral'], [37, 'contradiction'], [38, 'entailment'], [39, 'contradiction'], [40, 'neutral'], [41, 'neutral'], [42, 'neutral'], [43, 'neutral'], [44, 'neutral'], [45, 'contradiction'], [46, 'neutral'], [47, 'entailment'], [48, 'contradiction'], [49, 'entailment'], [50, 'neutral'], [51, 'contradiction'], [52, 'contradiction'], [53, 'neutral'], [54, 'neutral'], [55, 'entailment'], [56, 'neutral'], [57, 'neutral'], [58, 'neutral'], [59, 'neutral'], [60, 'entailment'], [61, 'neutral'], [62, 'neutral'], [63, 'neutral'], [64, 'neutral'], [65, 'contradiction'], [66, 'neutral'], [67, 'neutral'], [68, 'neutral'], [69, 'contradiction'], [70, 'entailment'], [71, 'neutral'], [72, 'entailment'], [73, 'contradiction'], [74, 'neutral'], [75, 'neutral'], [76, 'entailment'], [77, 'neutral'], [78, 'neutral'], [79, 'contradiction'], [80, 'neutral'], [81, 'neutral'], [82, 'contradiction'], [83, 'contradiction'], [84, 'entailment'], [85, 'contradiction'], [86, 'neutral'], [87, 'contradiction'], [88, 'entailment'], [89, 'neutral'], [90, 'contradiction'], [91, 'neutral'], [92, 'entailment'], [93, 'contradiction'], [94, 'entailment'], [95, 'entailment'], [96, 'contradiction'], [97, 'neutral'], [98, 'entailment'], [99, 'neutral'], [100, 'neutral'], [101, 'entailment'], [102, 'neutral'], [103, 'entailment'], [104, 'neutral'], [105, 'entailment'], [106, 'neutral'], [107, 'neutral'], [108, 'contradiction'], [109, 'entailment'], [110, 'contradiction'], [111, 'neutral'], [112, 'contradiction'], [113, 'entailment'], [114, 'neutral'], [115, 'entailment'], [116, 'entailment'], [117, 'contradiction'], [118, 'contradiction'], [119, 'contradiction'], [120, 'contradiction'], [121, 'neutral'], [122, 'contradiction'], [123, 'neutral'], [124, 'neutral'], [125, 'neutral'], [126, 'entailment'], [127, 'contradiction'], [128, 'contradiction'], [129, 'neutral'], [130, 'contradiction'], [131, 'neutral'], [132, 'contradiction'], [133, 'entailment'], [134, 'neutral'], [135, 'entailment'], [136, 'entailment'], [137, 'neutral'], [138, 'contradiction'], [139, 'contradiction'], [140, 'neutral'], [141, 'neutral'], [142, 'neutral'], [143, 'entailment'], [144, 'neutral'], [145, 'neutral'], [146, 'entailment'], [147, 'contradiction'], [148, 'neutral'], [149, 'neutral'], [150, 'contradiction'], [151, 'entailment'], [152, 'contradiction'], [153, 'neutral'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'contradiction'], [158, 'neutral'], [159, 'contradiction'], [160, 'neutral'], [161, 'entailment'], [162, 'neutral'], [163, 'entailment'], [164, 'neutral'], [165, 'neutral'], [166, 'neutral'], [167, 'entailment'], [168, 'neutral'], [169, 'entailment'], [170, 'neutral'], [171, 'neutral'], [172, 'neutral'], [173, 'neutral'], [174, 'neutral'], [175, 'neutral'], [176, 'neutral'], [177, 'neutral'], [178, 'contradiction'], [179, 'neutral'], [180, 'contradiction'], [181, 'neutral'], [182, 'neutral'], [183, 'neutral'], [184, 'neutral'], [185, 'neutral'], [186, 'contradiction'], [187, 'neutral'], [188, 'entailment'], [189, 'contradiction'], [190, 'neutral'], [191, 'entailment'], [192, 'contradiction'], [193, 'neutral'], [194, 'neutral'], [195, 'entailment'], [196, 'neutral'], [197, 'neutral'], [198, 'entailment'], [199, 'neutral'], [200, 'neutral'], [201, 'neutral'], [202, 'entailment'], [203, 'contradiction'], [204, 'contradiction'], [205, 'entailment'], [206, 'entailment'], [207, 'neutral'], [208, 'entailment'], [209, 'neutral'], [210, 'contradiction'], [211, 'contradiction'], [212, 'contradiction'], [213, 'neutral'], [214, 'contradiction'], [215, 'contradiction'], [216, 'contradiction'], [217, 'entailment'], [218, 'contradiction'], [219, 'contradiction'], [220, 'neutral'], [221, 'neutral'], [222, 'entailment'], [223, 'contradiction'], [224, 'neutral'], [225, 'contradiction'], [226, 'contradiction'], [227, 'neutral'], [228, 'contradiction'], [229, 'neutral'], [230, 'entailment'], [231, 'neutral'], [232, 'entailment'], [233, 'entailment'], [234, 'entailment'], [235, 'neutral'], [236, 'neutral'], [237, 'neutral'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'contradiction'], [242, 'neutral'], [243, 'neutral'], [244, 'neutral'], [245, 'entailment'], [246, 'neutral'], [247, 'neutral'], [248, 'neutral'], [249, 'contradiction'], [250, 'entailment'], [251, 'contradiction'], [252, 'neutral'], [253, 'entailment'], [254, 'neutral'], [255, 'neutral'], [256, 'neutral'], [257, 'contradiction'], [258, 'entailment'], [259, 'entailment'], [260, 'entailment'], [261, 'entailment'], [262, 'neutral'], [263, 'neutral'], [264, 'neutral'], [265, 'neutral'], [266, 'entailment'], [267, 'entailment'], [268, 'neutral'], [269, 'entailment'], [270, 'neutral'], [271, 'neutral'], [272, 'entailment'], [273, 'entailment'], [274, 'neutral'], [275, 'contradiction'], [276, 'contradiction'], [277, 'contradiction'], [278, 'neutral'], [279, 'neutral'], [280, 'neutral'], [281, 'entailment'], [282, 'neutral'], [283, 'entailment'], [284, 'contradiction'], [285, 'entailment'], [286, 'neutral'], [287, 'contradiction'], [288, 'entailment'], [289, 'neutral'], [290, 'entailment'], [291, 'contradiction'], [292, 'entailment'], [293, 'neutral'], [294, 'entailment'], [295, 'contradiction'], [296, 'contradiction'], [297, 'contradiction'], [298, 'neutral'], [299, 'neutral'], [300, 'neutral'], [301, 'entailment'], [302, 'neutral'], [303, 'entailment'], [304, 'entailment'], [305, 'entailment'], [306, 'entailment'], [307, 'contradiction'], [308, 'entailment'], [309, 'entailment'], [310, 'neutral'], [311, 'contradiction'], [312, 'neutral'], [313, 'neutral'], [314, 'neutral'], [315, 'neutral'], [316, 'neutral'], [317, 'neutral'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'neutral'], [322, 'neutral'], [323, 'neutral'], [324, 'contradiction'], [325, 'entailment'], [326, 'contradiction'], [327, 'neutral'], [328, 'contradiction'], [329, 'contradiction'], [330, 'neutral'], [331, 'entailment'], [332, 'entailment'], [333, 'contradiction'], [334, 'contradiction'], [335, 'contradiction'], [336, 'entailment'], [337, 'contradiction'], [338, 'contradiction'], [339, 'neutral'], [340, 'contradiction'], [341, 'neutral'], [342, 'contradiction'], [343, 'contradiction'], [344, 'neutral'], [345, 'entailment'], [346, 'contradiction'], [347, 'contradiction'], [348, 'contradiction'], [349, 'neutral'], [350, 'contradiction'], [351, 'neutral'], [352, 'contradiction'], [353, 'neutral'], [354, 'neutral'], [355, 'neutral'], [356, 'neutral'], [357, 'entailment'], [358, 'contradiction'], [359, 'neutral'], [360, 'contradiction'], [361, 'contradiction'], [362, 'contradiction'], [363, 'neutral'], [364, 'contradiction'], [365, 'neutral'], [366, 'neutral'], [367, 'entailment'], [368, 'contradiction'], [369, 'neutral'], [370, 'contradiction'], [371, 'neutral'], [372, 'entailment'], [373, 'neutral'], [374, 'neutral'], [375, 'entailment'], [376, 'entailment'], [377, 'neutral'], [378, 'entailment'], [379, 'neutral'], [380, 'entailment'], [381, 'neutral'], [382, 'contradiction'], [383, 'neutral'], [384, 'entailment'], [385, 'neutral'], [386, 'entailment'], [387, 'entailment'], [388, 'neutral'], [389, 'contradiction'], [390, 'neutral'], [391, 'neutral'], [392, 'contradiction'], [393, 'neutral'], [394, 'contradiction'], [395, 'contradiction'], [396, 'neutral'], [397, 'neutral'], [398, 'contradiction'], [399, 'neutral'], [400, 'contradiction'], [401, 'neutral'], [402, 'contradiction'], [403, 'contradiction'], [404, 'entailment'], [405, 'neutral'], [406, 'neutral'], [407, 'neutral'], [408, 'contradiction'], [409, 'neutral'], [410, 'contradiction'], [411, 'contradiction'], [412, 'contradiction'], [413, 'contradiction'], [414, 'neutral'], [415, 'contradiction'], [416, 'contradiction'], [417, 'entailment'], [418, 'neutral'], [419, 'contradiction'], [420, 'neutral'], [421, 'neutral'], [422, 'entailment'], [423, 'neutral'], [424, 'entailment'], [425, 'neutral'], [426, 'neutral'], [427, 'contradiction'], [428, 'contradiction'], [429, 'contradiction'], [430, 'entailment'], [431, 'neutral'], [432, 'contradiction'], [433, 'neutral'], [434, 'entailment'], [435, 'neutral'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'contradiction'], [442, 'entailment'], [443, 'neutral'], [444, 'contradiction'], [445, 'neutral'], [446, 'neutral'], [447, 'neutral'], [448, 'neutral'], [449, 'contradiction'], [450, 'contradiction'], [451, 'entailment'], [452, 'entailment'], [453, 'contradiction'], [454, 'contradiction'], [455, 'entailment'], [456, 'neutral'], [457, 'contradiction'], [458, 'neutral'], [459, 'contradiction'], [460, 'contradiction'], [461, 'entailment'], [462, 'contradiction'], [463, 'neutral'], [464, 'contradiction'], [465, 'contradiction'], [466, 'contradiction'], [467, 'neutral'], [468, 'entailment'], [469, 'neutral'], [470, 'contradiction'], [471, 'neutral'], [472, 'entailment'], [473, 'neutral'], [474, 'entailment'], [475, 'neutral'], [476, 'entailment'], [477, 'contradiction'], [478, 'entailment'], [479, 'contradiction'], [480, 'entailment'], [481, 'entailment'], [482, 'contradiction'], [483, 'entailment'], [484, 'neutral'], [485, 'entailment'], [486, 'entailment'], [487, 'neutral'], [488, 'contradiction'], [489, 'entailment'], [490, 'entailment'], [491, 'neutral'], [492, 'neutral'], [493, 'neutral'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'neutral'], [498, 'neutral'], [499, 'entailment'], [500, 'entailment'], [501, 'entailment'], [502, 'neutral'], [503, 'contradiction'], [504, 'contradiction'], [505, 'entailment'], [506, 'neutral'], [507, 'contradiction'], [508, 'entailment'], [509, 'contradiction'], [510, 'neutral'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'entailment'], [515, 'contradiction'], [516, 'neutral'], [517, 'entailment'], [518, 'contradiction'], [519, 'contradiction'], [520, 'neutral'], [521, 'neutral'], [522, 'contradiction'], [523, 'neutral'], [524, 'neutral'], [525, 'contradiction'], [526, 'entailment'], [527, 'entailment'], [528, 'contradiction'], [529, 'entailment'], [530, 'neutral'], [531, 'neutral'], [532, 'contradiction'], [533, 'neutral'], [534, 'neutral'], [535, 'contradiction'], [536, 'contradiction'], [537, 'contradiction'], [538, 'neutral'], [539, 'neutral'], [540, 'neutral'], [541, 'contradiction'], [542, 'contradiction'], [543, 'entailment'], [544, 'contradiction'], [545, 'neutral'], [546, 'contradiction'], [547, 'entailment'], [548, 'neutral'], [549, 'entailment'], [550, 'neutral'], [551, 'contradiction'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'neutral'], [556, 'entailment'], [557, 'neutral'], [558, 'neutral'], [559, 'contradiction'], [560, 'entailment'], [561, 'contradiction'], [562, 'neutral'], [563, 'neutral'], [564, 'neutral'], [565, 'neutral'], [566, 'entailment'], [567, 'entailment'], [568, 'neutral'], [569, 'contradiction'], [570, 'entailment'], [571, 'entailment'], [572, 'entailment'], [573, 'neutral'], [574, 'entailment'], [575, 'contradiction'], [576, 'entailment'], [577, 'neutral'], [578, 'contradiction'], [579, 'contradiction'], [580, 'contradiction'], [581, 'entailment'], [582, 'entailment'], [583, 'neutral'], [584, 'entailment'], [585, 'entailment'], [586, 'neutral'], [587, 'entailment'], [588, 'contradiction'], [589, 'entailment'], [590, 'entailment'], [591, 'neutral'], [592, 'contradiction'], [593, 'entailment'], [594, 'contradiction'], [595, 'contradiction'], [596, 'contradiction'], [597, 'neutral'], [598, 'entailment'], [599, 'entailment'], [600, 'contradiction'], [601, 'contradiction'], [602, 'contradiction'], [603, 'entailment'], [604, 'neutral'], [605, 'neutral'], [606, 'contradiction'], [607, 'contradiction'], [608, 'contradiction'], [609, 'contradiction'], [610, 'contradiction'], [611, 'entailment'], [612, 'neutral'], [613, 'entailment'], [614, 'contradiction'], [615, 'contradiction'], [616, 'neutral'], [617, 'neutral'], [618, 'contradiction'], [619, 'neutral'], [620, 'contradiction'], [621, 'neutral'], [622, 'entailment'], [623, 'neutral'], [624, 'entailment'], [625, 'contradiction'], [626, 'contradiction'], [627, 'contradiction'], [628, 'neutral'], [629, 'entailment'], [630, 'contradiction'], [631, 'entailment'], [632, 'neutral'], [633, 'entailment'], [634, 'neutral'], [635, 'contradiction'], [636, 'contradiction'], [637, 'entailment'], [638, 'neutral'], [639, 'contradiction'], [640, 'contradiction'], [641, 'entailment'], [642, 'neutral'], [643, 'entailment'], [644, 'neutral'], [645, 'entailment'], [646, 'neutral'], [647, 'contradiction'], [648, 'contradiction'], [649, 'neutral'], [650, 'entailment'], [651, 'contradiction'], [652, 'contradiction'], [653, 'neutral'], [654, 'neutral'], [655, 'neutral'], [656, 'neutral'], [657, 'contradiction'], [658, 'entailment'], [659, 'contradiction'], [660, 'neutral'], [661, 'contradiction'], [662, 'neutral'], [663, 'neutral'], [664, 'neutral'], [665, 'entailment'], [666, 'contradiction'], [667, 'neutral'], [668, 'neutral'], [669, 'neutral'], [670, 'neutral'], [671, 'neutral'], [672, 'neutral'], [673, 'contradiction'], [674, 'neutral'], [675, 'entailment'], [676, 'neutral'], [677, 'neutral'], [678, 'contradiction'], [679, 'contradiction'], [680, 'neutral'], [681, 'contradiction'], [682, 'entailment'], [683, 'contradiction'], [684, 'contradiction'], [685, 'contradiction'], [686, 'entailment'], [687, 'neutral'], [688, 'entailment'], [689, 'entailment'], [690, 'neutral'], [691, 'entailment'], [692, 'entailment'], [693, 'neutral'], [694, 'entailment'], [695, 'neutral'], [696, 'entailment'], [697, 'contradiction'], [698, 'entailment'], [699, 'neutral'], [700, 'neutral'], [701, 'entailment'], [702, 'entailment'], [703, 'neutral'], [704, 'entailment'], [705, 'entailment'], [706, 'contradiction'], [707, 'contradiction'], [708, 'neutral'], [709, 'contradiction'], [710, 'neutral'], [711, 'entailment'], [712, 'neutral'], [713, 'entailment'], [714, 'entailment'], [715, 'contradiction'], [716, 'entailment'], [717, 'neutral'], [718, 'neutral'], [719, 'entailment'], [720, 'entailment'], [721, 'neutral'], [722, 'neutral'], [723, 'contradiction'], [724, 'entailment'], [725, 'contradiction'], [726, 'neutral'], [727, 'contradiction'], [728, 'contradiction'], [729, 'entailment'], [730, 'entailment'], [731, 'neutral'], [732, 'contradiction'], [733, 'neutral'], [734, 'entailment'], [735, 'neutral'], [736, 'contradiction'], [737, 'neutral'], [738, 'entailment'], [739, 'entailment'], [740, 'neutral'], [741, 'contradiction'], [742, 'neutral'], [743, 'entailment'], [744, 'neutral'], [745, 'neutral'], [746, 'neutral'], [747, 'entailment'], [748, 'neutral'], [749, 'contradiction'], [750, 'neutral'], [751, 'neutral'], [752, 'neutral'], [753, 'neutral'], [754, 'entailment'], [755, 'neutral'], [756, 'neutral'], [757, 'contradiction'], [758, 'neutral'], [759, 'neutral'], [760, 'entailment'], [761, 'neutral'], [762, 'entailment'], [763, 'contradiction'], [764, 'neutral'], [765, 'entailment'], [766, 'neutral'], [767, 'entailment'], [768, 'contradiction'], [769, 'neutral'], [770, 'contradiction'], [771, 'neutral'], [772, 'neutral'], [773, 'entailment'], [774, 'neutral'], [775, 'neutral'], [776, 'contradiction'], [777, 'entailment'], [778, 'neutral'], [779, 'neutral'], [780, 'entailment'], [781, 'entailment'], [782, 'contradiction'], [783, 'neutral'], [784, 'entailment'], [785, 'entailment'], [786, 'contradiction'], [787, 'contradiction'], [788, 'entailment'], [789, 'contradiction'], [790, 'entailment'], [791, 'neutral'], [792, 'entailment'], [793, 'neutral'], [794, 'neutral'], [795, 'entailment'], [796, 'contradiction'], [797, 'entailment'], [798, 'entailment'], [799, 'neutral'], [800, 'entailment'], [801, 'neutral'], [802, 'neutral'], [803, 'neutral'], [804, 'contradiction'], [805, 'contradiction'], [806, 'entailment'], [807, 'neutral'], [808, 'neutral'], [809, 'contradiction'], [810, 'neutral'], [811, 'contradiction'], [812, 'contradiction'], [813, 'neutral'], [814, 'neutral'], [815, 'neutral'], [816, 'entailment'], [817, 'neutral'], [818, 'neutral'], [819, 'entailment'], [820, 'neutral'], [821, 'neutral'], [822, 'contradiction'], [823, 'neutral'], [824, 'entailment'], [825, 'neutral'], [826, 'contradiction'], [827, 'neutral'], [828, 'contradiction'], [829, 'entailment'], [830, 'neutral'], [831, 'contradiction'], [832, 'contradiction'], [833, 'entailment'], [834, 'neutral'], [835, 'contradiction'], [836, 'entailment'], [837, 'contradiction'], [838, 'neutral'], [839, 'contradiction'], [840, 'contradiction'], [841, 'neutral'], [842, 'contradiction'], [843, 'entailment'], [844, 'neutral'], [845, 'neutral'], [846, 'contradiction'], [847, 'contradiction'], [848, 'entailment'], [849, 'neutral'], [850, 'neutral'], [851, 'contradiction'], [852, 'entailment'], [853, 'neutral'], [854, 'contradiction'], [855, 'entailment'], [856, 'entailment'], [857, 'neutral'], [858, 'contradiction'], [859, 'neutral'], [860, 'contradiction'], [861, 'neutral'], [862, 'contradiction'], [863, 'neutral'], [864, 'neutral'], [865, 'entailment'], [866, 'entailment'], [867, 'neutral'], [868, 'contradiction'], [869, 'neutral'], [870, 'contradiction'], [871, 'neutral'], [872, 'entailment'], [873, 'neutral'], [874, 'neutral'], [875, 'neutral'], [876, 'entailment'], [877, 'contradiction'], [878, 'neutral'], [879, 'neutral'], [880, 'neutral'], [881, 'neutral'], [882, 'contradiction'], [883, 'entailment'], [884, 'entailment'], [885, 'neutral'], [886, 'neutral'], [887, 'neutral'], [888, 'entailment'], [889, 'neutral'], [890, 'entailment'], [891, 'contradiction'], [892, 'entailment'], [893, 'entailment'], [894, 'contradiction'], [895, 'neutral'], [896, 'entailment'], [897, 'neutral'], [898, 'entailment'], [899, 'neutral'], [900, 'neutral'], [901, 'contradiction'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'neutral'], [906, 'contradiction'], [907, 'contradiction'], [908, 'entailment'], [909, 'neutral'], [910, 'neutral'], [911, 'neutral'], [912, 'neutral'], [913, 'entailment'], [914, 'neutral'], [915, 'neutral'], [916, 'contradiction'], [917, 'contradiction'], [918, 'neutral'], [919, 'entailment'], [920, 'neutral'], [921, 'entailment'], [922, 'entailment'], [923, 'entailment'], [924, 'neutral'], [925, 'contradiction'], [926, 'entailment'], [927, 'entailment'], [928, 'neutral'], [929, 'entailment'], [930, 'neutral'], [931, 'entailment'], [932, 'neutral'], [933, 'neutral'], [934, 'contradiction'], [935, 'contradiction'], [936, 'entailment'], [937, 'neutral'], [938, 'entailment'], [939, 'neutral'], [940, 'entailment'], [941, 'entailment'], [942, 'contradiction'], [943, 'contradiction'], [944, 'neutral'], [945, 'entailment'], [946, 'entailment'], [947, 'neutral'], [948, 'neutral'], [949, 'entailment'], [950, 'contradiction'], [951, 'neutral'], [952, 'contradiction'], [953, 'contradiction'], [954, 'contradiction'], [955, 'entailment'], [956, 'neutral'], [957, 'entailment'], [958, 'contradiction'], [959, 'contradiction'], [960, 'neutral'], [961, 'contradiction'], [962, 'contradiction'], [963, 'contradiction'], [964, 'neutral'], [965, 'entailment'], [966, 'neutral'], [967, 'entailment'], [968, 'entailment'], [969, 'contradiction'], [970, 'entailment'], [971, 'entailment'], [972, 'neutral'], [973, 'contradiction'], [974, 'contradiction'], [975, 'entailment'], [976, 'entailment'], [977, 'neutral'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'neutral'], [982, 'contradiction'], [983, 'contradiction'], [984, 'neutral'], [985, 'neutral'], [986, 'contradiction'], [987, 'contradiction'], [988, 'neutral'], [989, 'contradiction'], [990, 'entailment'], [991, 'entailment'], [992, 'neutral'], [993, 'contradiction'], [994, 'neutral'], [995, 'entailment'], [996, 'neutral'], [997, 'contradiction'], [998, 'entailment'], [999, 'entailment'], [1000, 'entailment'], [1001, 'entailment'], [1002, 'entailment'], [1003, 'neutral'], [1004, 'neutral'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'neutral'], [1009, 'neutral'], [1010, 'neutral'], [1011, 'entailment'], [1012, 'neutral'], [1013, 'contradiction'], [1014, 'neutral'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'neutral'], [1019, 'contradiction'], [1020, 'entailment'], [1021, 'neutral'], [1022, 'neutral'], [1023, 'neutral'], [1024, 'entailment'], [1025, 'neutral'], [1026, 'neutral'], [1027, 'neutral'], [1028, 'contradiction'], [1029, 'contradiction'], [1030, 'entailment'], [1031, 'neutral'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'neutral'], [1035, 'contradiction'], [1036, 'neutral'], [1037, 'contradiction'], [1038, 'neutral'], [1039, 'contradiction'], [1040, 'entailment'], [1041, 'neutral'], [1042, 'contradiction'], [1043, 'entailment'], [1044, 'neutral'], [1045, 'neutral'], [1046, 'neutral'], [1047, 'contradiction'], [1048, 'contradiction'], [1049, 'contradiction'], [1050, 'entailment'], [1051, 'contradiction'], [1052, 'entailment'], [1053, 'contradiction'], [1054, 'neutral'], [1055, 'entailment'], [1056, 'neutral'], [1057, 'neutral'], [1058, 'entailment'], [1059, 'neutral'], [1060, 'contradiction'], [1061, 'contradiction'], [1062, 'contradiction'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'neutral'], [1066, 'contradiction'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'neutral'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'neutral'], [1073, 'neutral'], [1074, 'entailment'], [1075, 'neutral'], [1076, 'entailment'], [1077, 'neutral'], [1078, 'contradiction'], [1079, 'entailment'], [1080, 'neutral'], [1081, 'neutral'], [1082, 'neutral'], [1083, 'contradiction'], [1084, 'neutral'], [1085, 'contradiction'], [1086, 'neutral'], [1087, 'entailment'], [1088, 'contradiction'], [1089, 'neutral'], [1090, 'contradiction'], [1091, 'neutral'], [1092, 'contradiction'], [1093, 'contradiction'], [1094, 'neutral'], [1095, 'neutral'], [1096, 'entailment'], [1097, 'neutral'], [1098, 'neutral'], [1099, 'contradiction'], [1100, 'entailment'], [1101, 'contradiction'], [1102, 'neutral'], [1103, 'contradiction'], [1104, 'contradiction'], [1105, 'entailment'], [1106, 'contradiction'], [1107, 'contradiction'], [1108, 'entailment'], [1109, 'entailment'], [1110, 'contradiction'], [1111, 'contradiction'], [1112, 'contradiction'], [1113, 'contradiction'], [1114, 'neutral'], [1115, 'neutral'], [1116, 'neutral'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'contradiction'], [1120, 'contradiction'], [1121, 'neutral'], [1122, 'neutral'], [1123, 'neutral'], [1124, 'neutral'], [1125, 'contradiction'], [1126, 'entailment'], [1127, 'entailment'], [1128, 'entailment'], [1129, 'contradiction'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'neutral'], [1133, 'contradiction'], [1134, 'contradiction'], [1135, 'contradiction'], [1136, 'contradiction'], [1137, 'contradiction'], [1138, 'contradiction'], [1139, 'entailment'], [1140, 'neutral'], [1141, 'neutral'], [1142, 'contradiction'], [1143, 'contradiction'], [1144, 'entailment'], [1145, 'neutral'], [1146, 'entailment'], [1147, 'contradiction'], [1148, 'entailment'], [1149, 'contradiction'], [1150, 'entailment'], [1151, 'contradiction'], [1152, 'neutral'], [1153, 'entailment'], [1154, 'neutral'], [1155, 'neutral'], [1156, 'neutral'], [1157, 'entailment'], [1158, 'neutral'], [1159, 'neutral'], [1160, 'entailment'], [1161, 'contradiction'], [1162, 'contradiction'], [1163, 'entailment'], [1164, 'neutral'], [1165, 'entailment'], [1166, 'neutral'], [1167, 'entailment'], [1168, 'neutral'], [1169, 'neutral'], [1170, 'contradiction'], [1171, 'neutral'], [1172, 'contradiction'], [1173, 'neutral'], [1174, 'neutral'], [1175, 'entailment'], [1176, 'neutral'], [1177, 'entailment'], [1178, 'neutral'], [1179, 'contradiction'], [1180, 'neutral'], [1181, 'entailment'], [1182, 'contradiction'], [1183, 'neutral'], [1184, 'neutral'], [1185, 'neutral'], [1186, 'neutral'], [1187, 'contradiction'], [1188, 'neutral'], [1189, 'contradiction'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'entailment'], [1193, 'neutral'], [1194, 'entailment'], [1195, 'neutral'], [1196, 'contradiction'], [1197, 'neutral'], [1198, 'contradiction'], [1199, 'contradiction'], [1200, 'neutral'], [1201, 'neutral'], [1202, 'entailment'], [1203, 'neutral'], [1204, 'neutral'], [1205, 'neutral'], [1206, 'contradiction'], [1207, 'contradiction'], [1208, 'entailment'], [1209, 'contradiction'], [1210, 'neutral'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'contradiction'], [1214, 'neutral'], [1215, 'contradiction'], [1216, 'neutral'], [1217, 'entailment'], [1218, 'neutral'], [1219, 'neutral'], [1220, 'neutral'], [1221, 'contradiction'], [1222, 'contradiction'], [1223, 'neutral'], [1224, 'entailment'], [1225, 'contradiction'], [1226, 'contradiction'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'neutral'], [1230, 'contradiction'], [1231, 'contradiction'], [1232, 'entailment'], [1233, 'contradiction'], [1234, 'neutral'], [1235, 'neutral'], [1236, 'neutral'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'neutral'], [1240, 'contradiction'], [1241, 'neutral'], [1242, 'neutral'], [1243, 'neutral'], [1244, 'entailment'], [1245, 'contradiction'], [1246, 'contradiction'], [1247, 'neutral'], [1248, 'neutral'], [1249, 'entailment'], [1250, 'neutral'], [1251, 'entailment'], [1252, 'neutral'], [1253, 'contradiction'], [1254, 'neutral'], [1255, 'contradiction'], [1256, 'entailment'], [1257, 'neutral'], [1258, 'contradiction'], [1259, 'entailment'], [1260, 'neutral'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'neutral'], [1264, 'neutral'], [1265, 'neutral'], [1266, 'entailment'], [1267, 'contradiction'], [1268, 'contradiction'], [1269, 'contradiction'], [1270, 'contradiction'], [1271, 'entailment'], [1272, 'contradiction'], [1273, 'entailment'], [1274, 'contradiction'], [1275, 'neutral'], [1276, 'neutral'], [1277, 'entailment'], [1278, 'contradiction'], [1279, 'entailment'], [1280, 'contradiction'], [1281, 'entailment'], [1282, 'contradiction'], [1283, 'entailment'], [1284, 'neutral'], [1285, 'entailment'], [1286, 'neutral'], [1287, 'neutral'], [1288, 'entailment'], [1289, 'neutral'], [1290, 'neutral'], [1291, 'neutral'], [1292, 'neutral'], [1293, 'neutral'], [1294, 'entailment'], [1295, 'neutral'], [1296, 'contradiction'], [1297, 'neutral'], [1298, 'contradiction'], [1299, 'neutral'], [1300, 'contradiction'], [1301, 'entailment'], [1302, 'entailment'], [1303, 'neutral'], [1304, 'neutral'], [1305, 'neutral'], [1306, 'contradiction'], [1307, 'neutral'], [1308, 'neutral'], [1309, 'contradiction'], [1310, 'neutral'], [1311, 'contradiction'], [1312, 'contradiction'], [1313, 'contradiction'], [1314, 'entailment'], [1315, 'neutral'], [1316, 'neutral'], [1317, 'entailment'], [1318, 'neutral'], [1319, 'entailment'], [1320, 'contradiction'], [1321, 'entailment'], [1322, 'neutral'], [1323, 'contradiction'], [1324, 'entailment'], [1325, 'neutral'], [1326, 'contradiction'], [1327, 'neutral'], [1328, 'neutral'], [1329, 'contradiction'], [1330, 'neutral'], [1331, 'neutral'], [1332, 'contradiction'], [1333, 'neutral'], [1334, 'contradiction'], [1335, 'neutral'], [1336, 'neutral'], [1337, 'neutral'], [1338, 'entailment'], [1339, 'neutral'], [1340, 'entailment'], [1341, 'contradiction'], [1342, 'entailment'], [1343, 'neutral'], [1344, 'entailment'], [1345, 'contradiction'], [1346, 'contradiction'], [1347, 'entailment'], [1348, 'contradiction'], [1349, 'neutral'], [1350, 'neutral'], [1351, 'neutral'], [1352, 'neutral'], [1353, 'entailment'], [1354, 'entailment'], [1355, 'contradiction'], [1356, 'contradiction'], [1357, 'contradiction'], [1358, 'entailment'], [1359, 'neutral'], [1360, 'neutral'], [1361, 'contradiction'], [1362, 'contradiction'], [1363, 'neutral'], [1364, 'neutral'], [1365, 'neutral'], [1366, 'contradiction'], [1367, 'contradiction'], [1368, 'entailment'], [1369, 'contradiction'], [1370, 'neutral'], [1371, 'contradiction'], [1372, 'neutral'], [1373, 'contradiction'], [1374, 'neutral'], [1375, 'neutral'], [1376, 'neutral'], [1377, 'contradiction'], [1378, 'entailment'], [1379, 'entailment'], [1380, 'contradiction'], [1381, 'neutral'], [1382, 'neutral'], [1383, 'entailment'], [1384, 'contradiction'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'contradiction'], [1388, 'neutral'], [1389, 'contradiction'], [1390, 'neutral'], [1391, 'neutral'], [1392, 'neutral'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'neutral'], [1396, 'entailment'], [1397, 'neutral'], [1398, 'entailment'], [1399, 'neutral'], [1400, 'neutral'], [1401, 'neutral'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'contradiction'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'contradiction'], [1409, 'contradiction'], [1410, 'contradiction'], [1411, 'neutral'], [1412, 'neutral'], [1413, 'entailment'], [1414, 'neutral'], [1415, 'neutral'], [1416, 'neutral'], [1417, 'contradiction'], [1418, 'entailment'], [1419, 'entailment'], [1420, 'neutral'], [1421, 'contradiction'], [1422, 'contradiction'], [1423, 'entailment'], [1424, 'neutral'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'contradiction'], [1428, 'neutral'], [1429, 'neutral'], [1430, 'entailment'], [1431, 'neutral'], [1432, 'neutral'], [1433, 'entailment'], [1434, 'neutral'], [1435, 'neutral'], [1436, 'contradiction'], [1437, 'neutral'], [1438, 'neutral'], [1439, 'contradiction'], [1440, 'contradiction'], [1441, 'entailment'], [1442, 'contradiction'], [1443, 'entailment'], [1444, 'neutral'], [1445, 'contradiction'], [1446, 'contradiction'], [1447, 'neutral'], [1448, 'contradiction'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'neutral'], [1452, 'entailment'], [1453, 'neutral'], [1454, 'neutral'], [1455, 'contradiction'], [1456, 'contradiction'], [1457, 'neutral'], [1458, 'neutral'], [1459, 'neutral'], [1460, 'neutral'], [1461, 'neutral'], [1462, 'contradiction'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'contradiction'], [1466, 'contradiction'], [1467, 'neutral'], [1468, 'neutral'], [1469, 'neutral'], [1470, 'entailment'], [1471, 'contradiction'], [1472, 'neutral'], [1473, 'contradiction'], [1474, 'contradiction'], [1475, 'neutral'], [1476, 'neutral'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'contradiction'], [1480, 'contradiction'], [1481, 'contradiction'], [1482, 'contradiction'], [1483, 'neutral'], [1484, 'entailment'], [1485, 'neutral'], [1486, 'neutral'], [1487, 'contradiction'], [1488, 'contradiction'], [1489, 'entailment'], [1490, 'neutral'], [1491, 'entailment'], [1492, 'neutral'], [1493, 'entailment'], [1494, 'neutral'], [1495, 'entailment'], [1496, 'contradiction'], [1497, 'contradiction'], [1498, 'entailment'], [1499, 'contradiction'], [1500, 'neutral'], [1501, 'neutral'], [1502, 'contradiction'], [1503, 'entailment'], [1504, 'neutral'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'neutral'], [1508, 'neutral'], [1509, 'entailment'], [1510, 'entailment'], [1511, 'contradiction'], [1512, 'contradiction'], [1513, 'neutral'], [1514, 'contradiction'], [1515, 'contradiction'], [1516, 'entailment'], [1517, 'neutral'], [1518, 'neutral'], [1519, 'contradiction'], [1520, 'entailment'], [1521, 'contradiction'], [1522, 'neutral'], [1523, 'entailment'], [1524, 'contradiction'], [1525, 'neutral'], [1526, 'neutral'], [1527, 'neutral'], [1528, 'neutral'], [1529, 'entailment'], [1530, 'neutral'], [1531, 'entailment'], [1532, 'contradiction'], [1533, 'contradiction'], [1534, 'neutral'], [1535, 'contradiction'], [1536, 'neutral'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'neutral'], [1540, 'contradiction'], [1541, 'entailment'], [1542, 'neutral'], [1543, 'neutral'], [1544, 'entailment'], [1545, 'contradiction'], [1546, 'neutral'], [1547, 'neutral'], [1548, 'neutral'], [1549, 'neutral'], [1550, 'contradiction'], [1551, 'entailment'], [1552, 'neutral'], [1553, 'entailment'], [1554, 'neutral'], [1555, 'neutral'], [1556, 'entailment'], [1557, 'neutral'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'neutral'], [1561, 'entailment'], [1562, 'neutral'], [1563, 'neutral'], [1564, 'contradiction'], [1565, 'entailment'], [1566, 'contradiction'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'contradiction'], [1570, 'neutral'], [1571, 'contradiction'], [1572, 'entailment'], [1573, 'contradiction'], [1574, 'contradiction'], [1575, 'contradiction'], [1576, 'neutral'], [1577, 'contradiction'], [1578, 'contradiction'], [1579, 'entailment'], [1580, 'neutral'], [1581, 'contradiction'], [1582, 'contradiction'], [1583, 'entailment'], [1584, 'neutral'], [1585, 'neutral'], [1586, 'neutral'], [1587, 'neutral'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'entailment'], [1591, 'entailment'], [1592, 'neutral'], [1593, 'neutral'], [1594, 'neutral'], [1595, 'neutral'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'neutral'], [1599, 'neutral'], [1600, 'contradiction'], [1601, 'entailment'], [1602, 'contradiction'], [1603, 'neutral'], [1604, 'entailment'], [1605, 'neutral'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'contradiction'], [1609, 'entailment'], [1610, 'neutral'], [1611, 'neutral'], [1612, 'entailment'], [1613, 'neutral'], [1614, 'entailment'], [1615, 'contradiction'], [1616, 'neutral'], [1617, 'neutral'], [1618, 'neutral'], [1619, 'contradiction'], [1620, 'neutral'], [1621, 'contradiction'], [1622, 'contradiction'], [1623, 'neutral'], [1624, 'contradiction'], [1625, 'neutral'], [1626, 'neutral'], [1627, 'entailment'], [1628, 'contradiction'], [1629, 'neutral'], [1630, 'contradiction'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'neutral'], [1634, 'neutral'], [1635, 'neutral'], [1636, 'entailment'], [1637, 'contradiction'], [1638, 'contradiction'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'entailment'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'contradiction'], [1645, 'neutral'], [1646, 'contradiction'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'contradiction'], [1650, 'contradiction'], [1651, 'entailment'], [1652, 'neutral'], [1653, 'contradiction'], [1654, 'contradiction'], [1655, 'entailment'], [1656, 'neutral'], [1657, 'contradiction'], [1658, 'neutral'], [1659, 'entailment'], [1660, 'entailment'], [1661, 'neutral'], [1662, 'neutral'], [1663, 'neutral'], [1664, 'neutral'], [1665, 'neutral']]\n"
     ]
    }
   ],
   "source": [
    "def num_to_label(label):\n",
    "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
    "    str_label = []\n",
    "\n",
    "    for i, v in enumerate(label):\n",
    "        str_label.append([i,label_dict[v]])\n",
    "    \n",
    "    return str_label\n",
    "\n",
    "answer = num_to_label(pred_answer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index          label\n",
      "0         0  contradiction\n",
      "1         1        neutral\n",
      "2         2        neutral\n",
      "3         3  contradiction\n",
      "4         4  contradiction\n",
      "...     ...            ...\n",
      "1661   1661        neutral\n",
      "1662   1662        neutral\n",
      "1663   1663        neutral\n",
      "1664   1664        neutral\n",
      "1665   1665        neutral\n",
      "\n",
      "[1666 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
    "\n",
    "df.to_csv('electra_hyperparameter_tune.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "094f33ed2071450d91c60f15b0331e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "095be4a6f89d4603b8a0b314727bd7a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1e6ccdaaa224d05be7928a5aafaab64",
      "max": 751504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5a393fdf1044e6298a258d4bb8fcd84",
      "value": 751504
     }
    },
    "0bbfd5f0ec2d4436a06bb502f8131f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cde98b9a09144b6b25b121ab70b4ff4",
      "placeholder": "​",
      "style": "IPY_MODEL_21f45f4a718446cea0a2ae70c743ba61",
      "value": "Downloading: 100%"
     }
    },
    "0cde98b9a09144b6b25b121ab70b4ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c3fbc303704c62957bd8c329b8024e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fe9d0f2a6924eba82b3502d43030b61",
       "IPY_MODEL_8902ff1c00df45c78d5b02464ee50756",
       "IPY_MODEL_8fdfe2b3e6e64012ac265a462fbcf328"
      ],
      "layout": "IPY_MODEL_ddd8542cdb7c4844b19cb62fa5e5e146"
     }
    },
    "16cd5a8125f64e618585d262ed0dcc39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1809bf6050194337a8a1efd347bf1f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a91d489ae164c8ca4243d06894962fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c5b91e6ae4d46d0b2f099cd1d4c15cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bbfd5f0ec2d4436a06bb502f8131f49",
       "IPY_MODEL_2613deb06698404396c37a2cc26f5dc4",
       "IPY_MODEL_daa90c709c4b46439770068ba936d25f"
      ],
      "layout": "IPY_MODEL_d66d726b5a104734a7bcfa4d5bfd53b2"
     }
    },
    "1ced7dcc914c47788ca51353a2245f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25ef02ee9d634d79b632eb0a5ad0f6fa",
       "IPY_MODEL_095be4a6f89d4603b8a0b314727bd7a4",
       "IPY_MODEL_c3e047157c734a5fbf6a6c8dc27c5913"
      ],
      "layout": "IPY_MODEL_16cd5a8125f64e618585d262ed0dcc39"
     }
    },
    "1d38cc6507084d34a2d41ada6a37b83e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f45f4a718446cea0a2ae70c743ba61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25ef02ee9d634d79b632eb0a5ad0f6fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3560910251ab4451ba5df9bf0953e999",
      "placeholder": "​",
      "style": "IPY_MODEL_c0ef75dc157d4b2a9c881661aa39347c",
      "value": "Downloading: 100%"
     }
    },
    "2613deb06698404396c37a2cc26f5dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3882a8be8ec44b9fb9595d4239c46930",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6e6cbbc9d0e443ca58cdcfe2c44f49e",
      "value": 375
     }
    },
    "27848cf6c21243f99f6421c294e2844f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c17f7168c24bcfbfb6cacf9d8a2b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd3c31a170a431ca04bbeeb641f6590": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341d1f2f2ec34446bcc1049dafda1c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3560910251ab4451ba5df9bf0953e999": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3882a8be8ec44b9fb9595d4239c46930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa68625b6364fdcb47c203b43277941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bebe6d4ba11479c8d6b952c786d5393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f4bd07499745d09d398568221a49aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a046ee54d1d485e84835c858f31be0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c07c3365e984f3596c00edb9cd2c184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cdf8336d32747629b01a6550240c6fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d26fc2e49c4bfaa89415d44a0606ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b541face9d74d2eae19066c55320567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afd8616825be40a8a52b1df11d73c64d",
      "placeholder": "​",
      "style": "IPY_MODEL_341d1f2f2ec34446bcc1049dafda1c82",
      "value": "Downloading: 100%"
     }
    },
    "5fe9d0f2a6924eba82b3502d43030b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3f1a17e1bd642e9b17fa94aff662eda",
      "placeholder": "​",
      "style": "IPY_MODEL_6c7eed7e50f34a1584a9639f26c277fe",
      "value": "Downloading: 100%"
     }
    },
    "683388a3551c4cfc922c56cba867d04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6860bf24436f4e098c668a285fd06f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b541face9d74d2eae19066c55320567",
       "IPY_MODEL_fbabe1a9a00a419b8c5f54375e80d952",
       "IPY_MODEL_f207ba49d03d4d11abd8a50c624eb7c8"
      ],
      "layout": "IPY_MODEL_3aa68625b6364fdcb47c203b43277941"
     }
    },
    "6be5e8971a294d58b173245f74bf1975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cd3c31a170a431ca04bbeeb641f6590",
      "placeholder": "​",
      "style": "IPY_MODEL_77abc577d69e4ca69ff1afe8c3a37d43",
      "value": "Downloading: 100%"
     }
    },
    "6c7eed7e50f34a1584a9639f26c277fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "704b74d3a9a040e9a11e57234af566ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73c789717a3745a9b431931ce845432b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77abc577d69e4ca69ff1afe8c3a37d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7af67cc2ae4b4c3abb9e7a208ecc9fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cb35513245c4927858d1ad05062340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8242b29066ed4717b957c897adba8533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8437c6dcd988498fb32f3d0557bb2385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_accc4b1e20d149aab8385df3109eb92f",
       "IPY_MODEL_9579ee57512f4bfbae9eeaac961ef7cb",
       "IPY_MODEL_a3591cd1d9f04511b42b45cde368fbc7"
      ],
      "layout": "IPY_MODEL_1d38cc6507084d34a2d41ada6a37b83e"
     }
    },
    "86daa3417a4147c4acc5b2cb0aff4935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6be5e8971a294d58b173245f74bf1975",
       "IPY_MODEL_ebdfb09f0319470db6ef22d68916b111",
       "IPY_MODEL_c0c048b2bc734c2a9a05a3195b29b136"
      ],
      "layout": "IPY_MODEL_f2b21dab53e944a58572bbdd6c9c94b0"
     }
    },
    "8902ff1c00df45c78d5b02464ee50756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c17f7168c24bcfbfb6cacf9d8a2b24",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1809bf6050194337a8a1efd347bf1f88",
      "value": 173
     }
    },
    "8fdfe2b3e6e64012ac265a462fbcf328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c40ba97a8a66488cb7b62cf85aead2b5",
      "placeholder": "​",
      "style": "IPY_MODEL_e8da32862f9049ceb6796662fcd4444f",
      "value": " 173/173 [00:00&lt;00:00, 3.16kB/s]"
     }
    },
    "9251c8da568641daacabf3e198c79290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9579ee57512f4bfbae9eeaac961ef7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_094f33ed2071450d91c60f15b0331e8c",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cb35513245c4927858d1ad05062340d",
      "value": 248477
     }
    },
    "a3591cd1d9f04511b42b45cde368fbc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f4bd07499745d09d398568221a49aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e03141fe0ca24aa888dc4ce1734ef897",
      "value": " 248k/248k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "accc4b1e20d149aab8385df3109eb92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c07c3365e984f3596c00edb9cd2c184",
      "placeholder": "​",
      "style": "IPY_MODEL_b18b9e54b8bb47a7ac0d5d4db9cc0946",
      "value": "Downloading: 100%"
     }
    },
    "afd8616825be40a8a52b1df11d73c64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18b9e54b8bb47a7ac0d5d4db9cc0946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1e6ccdaaa224d05be7928a5aafaab64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0c048b2bc734c2a9a05a3195b29b136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9251c8da568641daacabf3e198c79290",
      "placeholder": "​",
      "style": "IPY_MODEL_1a91d489ae164c8ca4243d06894962fa",
      "value": " 1.35G/1.35G [00:20&lt;00:00, 73.7MB/s]"
     }
    },
    "c0ef75dc157d4b2a9c881661aa39347c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3e047157c734a5fbf6a6c8dc27c5913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a046ee54d1d485e84835c858f31be0c",
      "placeholder": "​",
      "style": "IPY_MODEL_57d26fc2e49c4bfaa89415d44a0606ec",
      "value": " 752k/752k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "c40ba97a8a66488cb7b62cf85aead2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a393fdf1044e6298a258d4bb8fcd84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d66d726b5a104734a7bcfa4d5bfd53b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa90c709c4b46439770068ba936d25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cdf8336d32747629b01a6550240c6fe",
      "placeholder": "​",
      "style": "IPY_MODEL_8242b29066ed4717b957c897adba8533",
      "value": " 375/375 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "ddd8542cdb7c4844b19cb62fa5e5e146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e03141fe0ca24aa888dc4ce1734ef897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8da32862f9049ceb6796662fcd4444f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebdfb09f0319470db6ef22d68916b111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c789717a3745a9b431931ce845432b",
      "max": 1346930258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_704b74d3a9a040e9a11e57234af566ea",
      "value": 1346930258
     }
    },
    "f207ba49d03d4d11abd8a50c624eb7c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bebe6d4ba11479c8d6b952c786d5393",
      "placeholder": "​",
      "style": "IPY_MODEL_683388a3551c4cfc922c56cba867d04c",
      "value": " 547/547 [00:00&lt;00:00, 9.70kB/s]"
     }
    },
    "f2b21dab53e944a58572bbdd6c9c94b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f1a17e1bd642e9b17fa94aff662eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6e6cbbc9d0e443ca58cdcfe2c44f49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbabe1a9a00a419b8c5f54375e80d952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27848cf6c21243f99f6421c294e2844f",
      "max": 547,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7af67cc2ae4b4c3abb9e7a208ecc9fd5",
      "value": 547
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
